---
title: 机器学习-正则化-L1L2
date: 2018-07-19 09:39:40
tags: [机器学习]
---

机器学习-正则化-L1L2

<!--more-->


---
样本数据量大：经验⻛风险最⼩小化

样本数据量小：结构⻛风险最⼩小化==正则化

---

经验风险最⼩小化（empirical risk minimization）认为经验⻛风险最⼩小的模型是最优的模型，即求解最优化问题
$$ minf ∈ F(1/N)\sum_{i=1}^NL(y_i,f(x_i))$$

样本容量量⾜足够⼤大的时候，经验⻛风险最⼩小化学习效果良好

---
结构⻛风险=经验⻛风险+模型复杂度的正则化项（regularizer）或罚项（penalty term）
$$ minf ∈ F(1/N)\sum_{i=1}^NL(y_i,f(x_i))+\lambda{J(f)}$$

$J(f)$是模型的复杂度，模型$f$越复杂，复杂度$J(f)$越大。
$\lambda ≥ 0$是系数，⽤用以权衡经验⻛风险和模型复杂度。
>结构⻛风险⼩需要1、经验⻛风险和2、模型复杂度同时⼩

---
### 范数
因为非负性：可以做损失函数，正则项
>损失函数通常是⼀个有下确界的函数

常用范数：
L0

L1:绝对值
$$||x||=\sum_{i=1}^{d}{|x_i|}$$

L2；平方再开根号
$$||x||_2=(\sum_{i=1}^{d}{|x_i^2|})^{1/2}$$

Lp
$$||x||_2=(\sum_{i=1}^{d}{|x_i^p|})^{1/p}$$

p=1,曼哈顿距离，L1范数，表示某个向量量中所有元素绝对值的和<br>
p=2,欧式距离，L2范数

---


