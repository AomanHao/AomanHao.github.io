---
title: 机器学习_最优化_损失函数
date: 2018-07-16 09:39:40
tags: [机器学习, 最优化]
---

机器学习_最优化_损失函数

<!--more-->
通常机器学习每一个算法中都会有一个目标函数，算法的求解过程是通过对这个目标函数优化的过程。

在分类或者回归问题中，通常使用**损失函数（代价函数）**作为其目标函数。损失函数用来评价模型的预测值和真实值不一样的程度，损失函数越好，通常模型的性能越好。不同的算法使用的损失函数不一样。 

### 0-1损失函数和绝对值损失函数 
原理：预测值和目标值不相等为1，否则为0。<br>绝对值损失函数为：<br>
$$ L(Y,f(X))=1, if Y≠f(X)$$
$$ L(Y,f(X))=0, if Y=f(X)$$

感知机就是用的这种损失函数<br>
改进：Y-f(X)<阈值T判断相等
绝对值损失函数为： 
$$ L(Y,f(X)=|Y−f(X)| $$

---
### log对数损失函数
原理：假设样本服从伯努利分布（0-1）分布，然后求得满足该分布的似然函数，接着用对数求极值。<br>
log损失函数的标准形式： <br>
$$ L(Y,P(Y|X))=−logP(Y|X) $$

---
### 平方损失函数 
最小二乘法是线性回归的一种方法，它将回归的问题转化为了凸优化的问题。最小二乘法的基本原则是：最优拟合曲线应该使得所有点到回归直线的距离和最小。通常用欧几里得距离进行距离的度量。<br>平方损失的损失函数为： <br>
$$ L(Y|f(X))=∑N(Y−f(X))^2 $$

---

[参考文章](https://blog.csdn.net/weixin_37933986/article/details/68488339)