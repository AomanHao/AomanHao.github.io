<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hexo博客使用valine评论系统无效果及终极解决方案]]></title>
    <url>%2F2019%2F02%2F20%2Fhexo_valine%2F</url>
    <content type="text"><![CDATA[Hexo博客使用valine评论系统无效果及终极解决方案 注意事项有一些博主valine评论系统无效果，有一些原因： 1、很大程度是因为next的版本升级导致某些参数设置不同2、valine评论是基于LeanCloud，还有一个文章阅读次数功能也是用LeanCloud，两者会有一点冲突 之后会给出一些解决方案 评论系统选择Hexo可用的评论系统有很多，如下： 来必力：https://livere.com （需要邮箱注册，加载慢，较卡顿） 畅言： http://changyan.kuaizhan.com （安装需要备案号） Gitment： https://github.com/imsun/gitment （加载慢，有Bug） Valine: https://github.com/xCss/Valine (简约，实用，使用Leancloud作为线上数据库） 评论系统配置过程next 集成了 leancloud 。可以在leancloud进行账号注册。 1、注册LeanCloud注册地址 https://leancloud.cn/ 2、配置LeanCloud创建一个新的应用 随便取个名字，自己看着取吧 应用创建完成，点开配置按钮 点击设置 &gt; 应用Key 复制App ID 和 App Key 点击设置 &gt; 安全中心 把自己博客网址添加到安全中心，保证数据的调用安全。 修改配置文件在主题themes目录下有第三方提供的主题配置文件\themes\next\_config.yml打开主题配置文件 添加appid 和appkey: 12345678910111213# Valine# You can get your appid and appkey from https://leancloud.cn# More info available at https://valine.js.orgvaline: enable: true # When enable is set to be true, leancloud_visitors is recommended to be closed for the re-initialization problem within different leancloud adk version. appid: 粘贴id appkey: 粘贴key notify: false # mail notifier, See: https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: 欢迎交流讨论... # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size 阅读次数功能配置过程创建阅读次数Class类在应用里面创建名称为Counter的Class，名称必须为Counter 创建完成，效果如下： 修改配置文件1234leancloud_visitors: enable: true appid: 粘贴id appkey: 粘贴key 评论系统无效原因及解决方案1、next的版本不同导致某些参数设置不同next为5.X版本的时候，配置文件themes\next\_config.yml的valine的id和key的书写方式为appid和appkey 123valine: appid: 粘贴id appkey: 粘贴key next为6.X版本的时候，配置文件themes\next\_config.yml的valine的id和key的书写方式为app_id和app_key123valine: app_id: 粘贴id app_key: 粘贴key 而Valine文件themes\next\layout\_third-party\comments\valine.swig内调用函数依旧为appid和appkey12appId: &apos;&#123;&#123; theme.valine.appid &#125;&#125;&apos;, appKey: &apos;&#123;&#123; theme.valine.appkey &#125;&#125;&apos;, 参数设置不同解决方案配置文件themes\next\_config.yml的valine的id和key的书写方式统一为为appid和appkey 2、valine评论和文章阅读次数功能均基于LeanCloud，两者有冲突valine评论和文章阅读次数功能均基于LeanCloud，在配置文件themes\next\_config.yml中，valine的配置项和文章阅读次数的配置项均需要填写LeanCloud的id和key123456789valine: enable: true app_id: 粘贴id app_key: 粘贴keyleancloud_visitors: enable: true appid: 粘贴id appkey: 粘贴key 即valine评论和文章阅读功能不能同时为true，只能单选一个功能。 功能冲突解决方案valine作者已经给出了方案，一个两种合一的配置 1234valine: ... visitor: true # leancloud-counter-security is not supported for now. When visitor is set to be true, appid and appkey are recommended to be the same as leancloud_visitors&apos; for counter compatibility. Article reading statistic https://valine.js.org/visitor.html comment_count: true # if false, comment count will only be displayed in post page, not in home page 相比之前的配置项多了visitor和comment_count两项参数。即要想拥有Valine评论与文章阅读次数可见，设置Valine:为true，leancloud_visitors:为false，配置如下： 123456789101112131415161718# Valine# You can get your appid and appkey from https://leancloud.cn# More info available at https://valine.js.orgvaline: enable: true # When enable is set to be true, leancloud_visitors is recommended to be closed for the re-initialization problem within different leancloud adk version. appid: 粘贴id appkey: 粘贴key notify: false # mail notifier, See: https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: 欢迎交流讨论... # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size visitor: true # leancloud-counter-security is not supported for now. When visitor is set to be true, appid and appkey are recommended to be the same as leancloud_visitors&apos; for counter compatibility. Article reading statistic https://valine.js.org/visitor.html comment_count: true # if false, comment count will only be displayed in post page, not in home pageleancloud_visitors: enable: false Valine的CDN修改官方自带的CDN加载慢，建议将CDN改成第三方CDNvaline:，修改如下 123456# valine # See: https://github.com/xCss/Valine # Example: # valine: //cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js #valine: //cdnjs.cloudflare.com/ajax/libs/valine/1.3.4/Valine.min.js valine: //cdn.jsdelivr.net/npm/valine@1.3.4/dist/Valine.min.js 以上内容完成Valine评论的配置相关，都是自己踩的坑，合并了文章阅读次数的功能。 我的个人博客文章地址，欢迎访问 我的CSDN文章地址，欢迎访问 我的简书文章地址，欢迎访问 我的GitHub主页，欢迎访问]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字数统计和阅读时长(网站底部/文章内)]]></title>
    <url>%2F2019%2F01%2F30%2Fhexo_next_wordcount%2F</url>
    <content type="text"><![CDATA[字数统计和阅读时长（旧版本新版本）插件地址：https://github.com/theme-next/hexo-symbols-count-time安装插件 1npm install hexo-symbols-count-time --save 修改 站点配置文件1234567symbols_count_time: #文章内是否显示 symbols: true time: true # 网页底部是否显示 total_symbols: true total_time: true 修改 主题配置文件123456789101112# Post wordcount display settings# Dependencies: https://github.com/theme-next/hexo-symbols-count-timesymbols_count_time: separated_meta: true #文章中的显示是否显示文字（本文字数|阅读时长） item_text_post: true #网页底部的显示是否显示文字（站点总字数|站点阅读时长） item_text_total: false # Average Word Length (chars count in word) awl: 4 # Words Per Minute wpm: 275]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客Next主题阅读次数热度不能读取的问题，报错Counter not initialized! More info at console err msg.]]></title>
    <url>%2F2019%2F01%2F30%2Ftheme_next_leancloud%2F</url>
    <content type="text"><![CDATA[Hexo博客Next主题阅读次数热度不能读取的问题 加入valine在线评论设置效果： 设置方法：首先要先去LeanCloud注册一个帐号.然后再创建一个应用. 拿到appid和appkey之后，打开themes/next/_config.yml主题配置文件，查找valine，填入appid和 appkey我的配置: 1234567891011121314# You can get your appid and appkey from https://leancloud.cn# More info available at https://valine.js.orgvaline: enable: true # When enable is set to be true, leancloud_visitors is recommended to be closed for the re-initialization problem within different leancloud adk version. appid: appkey: notify: true # mail notifier, See: https://github.com/xCss/Valine/wiki verify: true # Verification code placeholder: 欢迎交流讨论... # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size visitor: false # leancloud-counter-security is not supported for now. When visitor is set to be true, appid and appkey are recommended to be the same as leancloud_visitors&apos; for counter compatibility. Article reading statistic https://valine.js.org/visitor.html comment_count: true # if false, comment count will only be displayed in post page, not in home page Hexo添加阅读次数next 集成了 leancloud 。可以在leancloud进行账号注册。创建一个新的应用。点击应用进入。创建名称为Counter的Class，名称必须为Counter 点击设置 &gt; 应用Key 复制App ID 和 App Key 修改配置文件在主题themes目录下有第三方提供的主题配置文件\themes\next_config.yml打开主题配置文件 添加app_id 和app_key:1234567891011# Show number of visitors to each article.# You can visit https://leancloud.cn get AppID and AppKey.文章热度leancloud_visitors: enable: true app_id: llBsNPTabKsl2d4aU3OvrmSz-gzGzoHsz app_key: gzSQowSIzhnuc5eYPj4k7c7z # Dependencies: https://github.com/theme-next/hexo-leancloud-counter-security # If you don&apos;t care about security in leancloud counter and just want to use it directly # (without hexo-leancloud-counter-security plugin), set `security` to `false`. security: false betterPerformance: false 修改统计设置打开主题配置文件 定位到 post_wordcount12345678# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true wordcount: true min2read: true totalcount: false separated_meta: true Web安全性为了保证应用的统计计数功能仅应用于自己的博客，你可以在应用 &gt; 设置 &gt; 安全中心的Web安全域名中加入自己的博客域名，保证数据的调用安全。 显示文章热度首先要先去LeanCloud注册一个帐号.然后再创建一个应用. 设置方法：next主题集成leanCloud，打开themes/next/layout/_macro/post.swig,准备添加℃ 1234567891011121314&#123;# LeanCloud PageView #&#125;&#123;% if theme.leancloud_visitors.enable or (theme.valine.enable and theme.valine.appid and theme.valine.appkey and theme.valine.visitor) %&#125; &lt;span id=&quot;&#123;&#123; url_for(post.path) &#125;&#125;&quot; class=&quot;leancloud_visitors&quot; data-flag-title=&quot;&#123;&#123; post.title &#125;&#125;&quot;&gt; &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; &lt;/span&gt; &#123;% if theme.post_meta.item_text %&#125; &lt;span class=&quot;post-meta-item-text&quot;&gt;&#123;&#123; __(&apos;post.views&apos;) + __(&apos;symbol.colon&apos;) &#125;&#125;&lt;/span&gt; &#123;% endif %&#125; &lt;span class=&quot;leancloud-visitors-count&quot;&gt;&lt;/span&gt; &lt;span&gt;℃&lt;/span&gt; &lt;/span&gt;&#123;% endif %&#125; 插入摄氏度到倒数第三句，如下：1&lt;span&gt;℃&lt;/span&gt; 打开，themes/next/languages/zh-CN.yml,将views后的文字描述改为热度.1views: 热度 有的版本不一样，打开，themes/next/languages/zh-Hans.yml，将以下 1visitors: 热度 然后打开themes/next/_config.yml找到leancloud_visitors,将enable:改成true,再填上自己LeanCloud的app_id和app_key。1234567891011# Show number of visitors to each article.# You can visit https://leancloud.cn get AppID and AppKey.文章热度leancloud_visitors: enable: true app_id: 你自己的id app_key: 你自己的key # Dependencies: https://github.com/theme-next/hexo-leancloud-counter-security # If you don&apos;t care about security in leancloud counter and just want to use it directly # (without hexo-leancloud-counter-security plugin), set `security` to `false`. security: true betterPerformance: false 报错Counter not initialized! More info at console err msg.]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客Next主题站内搜索模块相关，解决搜索无效、一直loading的问题]]></title>
    <url>%2F2019%2F01%2F30%2Fhexo_theme_next_search%2F</url>
    <content type="text"><![CDATA[Hexo博客Next主题站内搜索模块相关，解决搜索无效、一直loading的问题 站内搜索配置设置方法：首先安装hexo-generator-searchdb插件 1npm install hexo-generator-searchdb --save 编辑博客根目录下的博客本地目录/_config.yml站点配置文件，新增以下内容到任意位置，search顶格放否则可能没效果： 12345search: path: search.xml field: post format: html limit: 10000 编辑博客本地目录/themes/next/_config.yml 主题配置文件，启用本地搜索功能,将local_search:下面的enable:的值，改成true，local_search顶格放置。 123456789local_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 # unescape html strings to the readable one unescape: false 可以输入以下命令，先清理缓存，然后本地部署调试12hexo cleanhexo s 命令输入完成，提示：Hexo is running at http://localhost:4000/，可以把网址复制到浏览器上，查看本地生成的博客搜索功能 搜索无效、一直loading的问题根据以上配置出的搜索框有可能出现无法加载，搜索无效，动画一直loading的问题，如下图： 按F12可以查看请求命令的状态，状态码200表示请求成功。但是搜索动画还是一直在转。 解决方案为了解决以上问题，也是花了很多时间在寻找办法，找个几个办法，终于解决了我的问题。 国光的博客地址 Linchao的博客地址 现给出比较详细的解决方法，如果搜索不成功，可能是以下原因之一 1、搜索插件没有配置好配置就按照文章前面配置的步骤走就行了 2、文章中包含特殊字符，文件编码时出错一般情况下，博客部署到网上想要进行本地调试，输入以下命令12hexo cleanhexo s 报错先不用管，命令输入完成，提示：Hexo is running at http://localhost:4000/。可以把网址复制到浏览器上，查看本地生成的博客，体验跟网站版的差不多，不出所料搜索框的动画还是会一直loading。 现在就要检查search.xml 文件，复制以下网址到浏览器，查看search.xml文件内容，是否报错。1localhost:4000/search.xml 效果图如下： 可以看到，有报错，报错内容就是说search.xml 文件有一些不能读取的内容，因为xml文件是有特殊符号不能使用。如果报错，浏览器右侧滑条拉到底，看看是哪里的文章出现问题。 效果图如下： 从最后的文字中找到一些信息，打开博客根目录下的search.xml文件 打开search.xml文件，找到包含那一些信息的那篇文章，最好是能开MarkDown在线编辑，也可以把有问题的.md文件拿出来，重新部署博客。 修改完成后，照平时那样部署博客就行。如果还有错，继续排查。 我的个人博客主页，欢迎访问我的CSDN主页，欢迎访问我的简书主页，欢迎访问我的GitHub主页，欢迎访问]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo主题Next配置algolia站内搜索]]></title>
    <url>%2F2019%2F01%2F30%2Fhexo_theme_next_algolia%2F</url>
    <content type="text"><![CDATA[Hexo主题Next配置algolia站内搜索 Algolia是一家为网站与移动应用提供托管式搜索API的初创企业，成立于2012年，总部位于旧金山，曾参加过去年的YC训练营。网站或移动应用只需嵌入简单代码数分钟即可实现搜索功能。 实现的效果如下 search 注册Algolia打开Algolia进行注册。可直接使用github账号进行注册。 创建index点击 NEW INDEX创建一个新的index。Index Name 后面会使用到。如图所示：INDEX 编辑KEY点击侧边栏API Keys可以看到 Application ID、 Search-Only API Key 、 Admin API Key。后面我们需要用到。 点击 ALL API KEYS，编辑KEY。如图所示。INDEX 安装hexo-algoliasearch插件在Hexo的根目录下执行1$ npm install hexo-algoliasearch --save 配置站点信息打开 站点配置文件，添加algolia配置信息。123456algolia: applicationID: apiKey: adminApiKey: indexName: #创建index使用的Index Name chunkSize: 5000 打开 主题配置文件，添加algolia配置信息。123456789# Algolia Searchalgolia_search: enable: true hits: per_page: 10 labels: input_placeholder: Search for Posts hits_empty: &quot;We didn&apos;t find any results for the search: $&#123;query&#125;&quot; hits_stats: &quot;$&#123;hits&#125; results found in $&#123;time&#125; ms&quot; 在环境变量中添加 HEXO_ALGOLIA_INDEXING_KEY， 在Hexo的根目录执行1$ export HEXO_ALGOLIA_INDEXING_KEY=粘贴上一步复制的 API KEY 再次执行12$ hexo clean$ hexo algolia 至此，我们的工作就完成了。 参考： Hexo+next 添加搜索功能 Hexo+Next集成Algolia搜索]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo主题Next配置]]></title>
    <url>%2F2019%2F01%2F20%2Ftheme_next%2F</url>
    <content type="text"><![CDATA[Hexo主题Next配置 新建404界面在站点根目录下，输入hexo new page 404，在默认Hexo站点下/source/404/index.md打开新建的404界面，编辑属于自己的404界面，可以显示腾讯公益404界面，代码如下： 123456789101112131415161718&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8;&quot;/&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge,chrome=1&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;all&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;index,follow&quot;/&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://qzone.qq.com/gy/404/style/404style.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script type=&quot;text/plain&quot; src=&quot;http://www.qq.com/404/search_children.js&quot; charset=&quot;utf-8&quot; homePageUrl=&quot;/&quot; homePageName=&quot;回到我的主页&quot;&gt; &lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/data.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/page.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 静态资源压缩静态资源压缩 在站点目录下安装插件： 1$ npm install gulp -g 12345npm install gulp-minify-css --savenpm install gulp-uglify --savenpm install gulp-htmlmin --savenpm install gulp-htmlclean --savenpm install gulp-imagemin --save 在Hexo站点下添加gulpfile.js文件，文件内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445var gulp = require(&apos;gulp&apos;);var minifycss = require(&apos;gulp-minify-css&apos;);var uglify = require(&apos;gulp-uglify&apos;);var htmlmin = require(&apos;gulp-htmlmin&apos;);var htmlclean = require(&apos;gulp-htmlclean&apos;);var imagemin = require(&apos;gulp-imagemin&apos;);// 压缩css文件gulp.task(&apos;minify-css&apos;, function() &#123; return gulp.src(&apos;./public/**/*.css&apos;) .pipe(minifycss()) .pipe(gulp.dest(&apos;./public&apos;));&#125;);// 压缩html文件gulp.task(&apos;minify-html&apos;, function() &#123; return gulp.src(&apos;./public/**/*.html&apos;) .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest(&apos;./public&apos;))&#125;);// 压缩js文件gulp.task(&apos;minify-js&apos;, function() &#123; return gulp.src([&apos;./public/**/.js&apos;,&apos;!./public/js/**/*min.js&apos;]) .pipe(uglify()) .pipe(gulp.dest(&apos;./public&apos;));&#125;);// 压缩 public/demo 目录内图片gulp.task(&apos;minify-images&apos;, function() &#123; gulp.src(&apos;./public/demo/**/*.*&apos;) .pipe(imagemin(&#123; optimizationLevel: 5, //类型：Number 默认：3 取值范围：0-7（优化等级） progressive: true, //类型：Boolean 默认：false 无损压缩jpg图片 interlaced: false, //类型：Boolean 默认：false 隔行扫描gif进行渲染 multipass: false, //类型：Boolean 默认：false 多次优化svg直到完全优化 &#125;)) .pipe(gulp.dest(&apos;./public/uploads&apos;));&#125;);// 默认任务gulp.task(&apos;default&apos;, [ &apos;minify-html&apos;,&apos;minify-css&apos;,&apos;minify-js&apos;,&apos;minify-images&apos;]); 需要只在每次执行generate命令后执行gulp就可以实现对静态资源的压缩，完成压缩后执行deploy命令同步到服务器： 123hexo ggulphexo d 隐藏网页底部powered By Hexo / 强力驱动打开themes/next/layout/_partials/footer.swig,使用&lt;!--与--&gt;隐藏之间的代码即可，或者直接删除。位置如图： 各版块透明度修改内容板块透明根博客目录themes\next\source\css\_schemes\Pisces\_layout.styl文件.content-wrap标签下background: white修改为：1background: rgba(255,255,255,0.7); //0.7是透明度 菜单栏背景根博客目录themes\next\source\css\_schemes\Pisces\_layout.styl文件.header-inner标签下background: white修改为：1background: rgba(255,255,255,0.7); //0.7是透明度 站点概况背景根博客目录themes\next\source\css\_schemes\Pisces\_sidebar.styl文件.sidebar-inner标签下background: white修改为：1background: rgba(255,255,255,0.7); //0.7是透明度 修改然后根博客目录themes\next\source\css\_schemes\Pisces\_layout.styl文件.sidebar标签下background: $body-bg-color修改为：1background: rgba(255,255,255,0.7); //0.7是透明度 网站底部字数统计具体方法实现 切换到根目录下，然后运行如下代码1npm install hexo-wordcount --save 然后在/themes/next/layout/_partials/footer.swig文件尾部加上：1234&lt;div class=&quot;theme-info&quot;&gt; &lt;div class=&quot;powered-by&quot;&gt;&lt;/div&gt; &lt;span class=&quot;post-count&quot;&gt;博客全站共&#123;&#123; totalcount(site) &#125;&#125;字&lt;/span&gt;&lt;/div&gt; 添加侧栏推荐阅读编辑主题配置文件，如下配置即可：12345678# Blog rollslinks_icon: linklinks_title: 推荐阅读#links_layout: blocklinks_layout: inlinelinks: Swift 4: https://developer.apple.com/swift/ Objective-C: https://developer.apple.com/documentation/objectivec 博文置顶修改hexo-generator-index插件，把node_modules/hexo-generator-index/lib/generator.js中代码替换为：12345678910111213141516171819202122232425262728&apos;use strict&apos;;var pagination = require(&apos;hexo-pagination&apos;);module.exports = function(locals)&#123; var config = this.config; var posts = locals.posts; posts.data = posts.data.sort(function(a, b) &#123; if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义 if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照top值降序排 &#125; else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233） return -1; &#125; else if(!a.top &amp;&amp; b.top) &#123; return 1; &#125; else return b.date - a.date; // 都没定义按照文章日期降序排 &#125;); var paginationDir = config.pagination_dir || &apos;page&apos;; return pagination(&apos;&apos;, posts, &#123; perPage: config.index_generator.per_page, layout: [&apos;index&apos;, &apos;archive&apos;], format: paginationDir + &apos;/%d/&apos;, data: &#123; __index: true &#125; &#125;);&#125;; 文章添加Top值，值越大，越靠前：123456789---title: Hexo-NexT主题配置date: 2018-01-20 20:41:08categories: Hexotags:- Hexo- NexTtop: 100--- 网页底部信息隐藏网页底默认最新一次使用，需要取消since注释，设定年份 1234567891011121314151617footer: # Specify the date when the site was setup. # If not defined, current year will be used. since: 2017 # Icon between year and copyright info. icon: # Icon name in fontawesome, see: https://fontawesome.com/v4.7.0/icons/ # `heart` is recommended with animation in red (#ff0000). name: user #设置图标，想修改图标从https://fontawesome.com/v4.7.0/icons获取 # If you want to animate the icon, set it to true. animated: false # Change the color of icon, using Hex Code. color: &quot;#808080&quot; # If not defined, `author` from Hexo main config will be used. copyright: by AomanHao #版权 显示文章阅读进度百分比设置方法：打开themes/next/_config.yml主题配置文件,找到# Scroll percent label in b2t button将scrollpercent:的值,改成true 12# Scroll percent label in b2t button scrollpercent: true 浏览页面的时候显示当前浏览进度如果想把top按钮放在侧边栏,打开themes/next下的_config.yml,搜索关键字b2t,把false改为true 12345# Back to top in sidebar b2t: true # Scroll percent label in b2t button scrollpercent: true 加入valine在线评论设置效果： 设置方法：首先要先去LeanCloud注册一个帐号.然后再创建一个应用. 拿到appid和appkey之后，打开themes/next/_config.yml主题配置文件，查找valine，填入appid和 appkey我的配置: 1234567891011121314# You can get your appid and appkey from https://leancloud.cn# More info available at https://valine.js.orgvaline: enable: true # When enable is set to be true, leancloud_visitors is recommended to be closed for the re-initialization problem within different leancloud adk version. appid: appkey: notify: true # mail notifier, See: https://github.com/xCss/Valine/wiki verify: true # Verification code placeholder: 欢迎交流讨论... # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size visitor: false # leancloud-counter-security is not supported for now. When visitor is set to be true, appid and appkey are recommended to be the same as leancloud_visitors&apos; for counter compatibility. Article reading statistic https://valine.js.org/visitor.html comment_count: true # if false, comment count will only be displayed in post page, not in home page Hexo添加阅读次数next 集成了 leancloud 。可以在leancloud进行账号注册。创建一个新的应用。点击应用进入。创建名称为Counter的Class，名称必须为Counter 点击设置 &gt; 应用Key 复制App ID 和 App Key 修改配置文件在主题themes目录下有第三方提供的主题配置文件\themes\next_config.yml打开主题配置文件 添加app_id 和app_key:1234567891011# Show number of visitors to each article.# You can visit https://leancloud.cn get AppID and AppKey.文章热度leancloud_visitors: enable: true app_id: app_key: # Dependencies: https://github.com/theme-next/hexo-leancloud-counter-security # If you don&apos;t care about security in leancloud counter and just want to use it directly # (without hexo-leancloud-counter-security plugin), set `security` to `false`. security: false betterPerformance: false Web安全性为了保证应用的统计计数功能仅应用于自己的博客，你可以在应用 &gt; 设置 &gt; 安全中心的Web安全域名中加入自己的博客域名，保证数据的调用安全。 显示文章热度首先要先去LeanCloud注册一个帐号.然后再创建一个应用. 设置方法：next主题集成leanCloud，打开themes/next/layout/_macro/post.swig,准备添加℃ 1234567891011121314&#123;# LeanCloud PageView #&#125;&#123;% if theme.leancloud_visitors.enable or (theme.valine.enable and theme.valine.appid and theme.valine.appkey and theme.valine.visitor) %&#125; &lt;span id=&quot;&#123;&#123; url_for(post.path) &#125;&#125;&quot; class=&quot;leancloud_visitors&quot; data-flag-title=&quot;&#123;&#123; post.title &#125;&#125;&quot;&gt; &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; &lt;/span&gt; &#123;% if theme.post_meta.item_text %&#125; &lt;span class=&quot;post-meta-item-text&quot;&gt;&#123;&#123; __(&apos;post.views&apos;) + __(&apos;symbol.colon&apos;) &#125;&#125;&lt;/span&gt; &#123;% endif %&#125; &lt;span class=&quot;leancloud-visitors-count&quot;&gt;&lt;/span&gt; &lt;span&gt;℃&lt;/span&gt; &lt;/span&gt;&#123;% endif %&#125; 插入摄氏度到倒数第三句，如下：1&lt;span&gt;℃&lt;/span&gt; 打开，themes/next/languages/zh-CN.yml,将views后的文字描述改为热度.1views: 热度 有的版本不一样，打开，themes/next/languages/zh-Hans.yml，将以下 1visitors: 热度 然后打开themes/next/_config.yml找到leancloud_visitors,将enable:改成true,再填上自己LeanCloud的app_id和app_key。1234567891011# Show number of visitors to each article.# You can visit https://leancloud.cn get AppID and AppKey.文章热度leancloud_visitors: enable: true app_id: 你自己的id app_key: 你自己的key # Dependencies: https://github.com/theme-next/hexo-leancloud-counter-security # If you don&apos;t care about security in leancloud counter and just want to use it directly # (without hexo-leancloud-counter-security plugin), set `security` to `false`. security: true betterPerformance: false 添加网站已运行时间在themes/layout/_parrials/footer.swing后添加 1234567891011121314151617&lt;span id=&quot;timeDate&quot;&gt;载入天数...&lt;/span&gt;&lt;span id=&quot;times&quot;&gt;载入时分秒...&lt;/span&gt;&lt;script&gt; var now = new Date(); function createtime() &#123; var grt= new Date(&quot;11/27/2017 12:00:00&quot;);//在此处修改你的建站时间 now.setTime(now.getTime()+250); days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 )&#123;hnum = &quot;0&quot; + hnum;&#125; minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 )&#123;mnum = &quot;0&quot; + mnum;&#125; seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 )&#123;snum = &quot;0&quot; + snum;&#125; document.getElementById(&quot;timeDate&quot;).innerHTML = &quot; Runing &quot;+dnum+&quot; D &quot;; document.getElementById(&quot;times&quot;).innerHTML = hnum + &quot; H &quot; + mnum + &quot; M &quot; + snum + &quot; S&quot;; &#125; setInterval(&quot;createtime()&quot;,250);&lt;/script&gt; 添加头像打开themes/next下的_config.yml文件，搜索 Avatar关键字，修改url的参数1234567891011avatar: # in theme directory(source/images): /images/avatar.gif # in site directory(source/uploads): /uploads/avatar.gif # You can also use other linking images. url: /images/avatar.gif # If true, the avatar would be dispalyed in circle. rounded: true # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar. opacity: 1 # If true, the avatar would be rotated with the cursor. rotated: false url链接默认是themes/next/source/images下的avatar.gif文件,有两种方法修改连接 1、本地连接，不建议用比较大的图片（大于1M文件），加载图片需要时间12345url: /images/avatar.gif或者url: /images/xx.jpg等类型图片 2、图床外链，建议使用1url: http://example.com/avatar.png 添加站内搜索设置效果： 设置方法：安装hexo-generator-searchdb插件1npm install hexo-generator-searchdb --save 编辑_config.yml站点配置文件，新增以下内容到任意位置：12345search: path: search.xml field: post format: html limit: 10000 编辑themes/next/_config.yml主题配置文件，启用本地搜索功能,将local_search:下面的enable:的值，改成true 123# Local searchlocal_search: enable: true 底部跳动图标实现注意点：需要到next\layout_partials下的footer.swig文件中，在你所需要调动的图标所对应的span中增加对应的ID去到主体的css文件（next\source\css_variables\custom.styl，增加以下代码即可 123456789101112131415//底部爱心小图标跳动keyframes heartAnimate &#123; 0%,100%&#123;transform:scale(1);&#125; 10%,30%&#123;transform:scale(0.9);&#125; 20%,40%,60%,80%&#123;transform:scale(1.1);&#125; 50%,70%&#123;transform:scale(1.1);&#125;&#125;//图标所对应的span中的ID#heart &#123; animation: heartAnimate 1.33s ease-in-out infinite;&#125;.with-love &#123; color: rgb(255, 113, 113);&#125; 实现统计功能具体实现方法:在根目录下安装 hexo-wordcount,运行：1npm install hexo-wordcount --save 然后在主题的配置文件中，配置如下：123456# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true wordcount: true min2read: true]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理_噪声检测]]></title>
    <url>%2F2018%2F12%2F25%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86_%E5%99%AA%E5%A3%B0%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[噪声检测 噪声检测方法将噪声和信号区分开来是影响去噪效果好坏的重要因素之一。近年来，学者们提出了诸多噪声判断方法，其中较经典的方法包括：开关阈值法、极值法、两级门限法，下面对这三种方法进行介绍，并进行对比。1.1 常见的噪声检测方法（1）开关阈值法开关阈值判断法[1]基本思想是：该方法通过一定的规则将噪声点和信号点进行判断，区分成两种类别来控制开关单元。若该像素点被判断为噪声点，则开关单元与滤波器相连接，即该点经过滤波后输出；若该像素点被判断为信号点，则开关单元对该点保持原像素值输出。开关阈值法的重点在于噪声检测器的设置，其中较为常见的一种开关阈值判断法表示如下： X_(i,j=)\begin{cases} S,|f(i,j)-average(W[x_(i,j)])|]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理_图像噪声]]></title>
    <url>%2F2018%2F10%2F25%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86_%E5%9B%BE%E5%83%8F%E5%99%AA%E5%A3%B0%2F</url>
    <content type="text"><![CDATA[图像噪声 噪声加性噪声一般指热噪声、散弹噪声等，它们与信号的关系是相加，不管有没有信号，噪声都存在。 高斯白噪声包括热噪声和散粒噪声。在通信信道测试和建模中，高斯噪声被用作加性白噪声以产生加性白高斯噪声。 加性高斯白噪声只是白噪声的一种，另有泊松白噪声等,加性高斯白噪声在通信领域中指的是一种各频谱分量服从均匀分布（即白噪声），且幅度服从高斯分布的噪声信号。因其可加性、幅度服从高斯分布且为白噪声的一种而得名。 而乘性噪声一般由信道不理想引起，它们与信号的关系是相乘，信号在它在，信号不在他也就不在。 一般通信中把加性随机性看成是系统的背景噪声； 而乘性随机性看成系统的时变性（如衰落或者多普勒）或者非线性所造成的。 椒盐噪声定义：椒盐噪声又称为双极脉冲噪声，这种噪声表现的特点是噪声像素的灰度值与邻域像素有着明显差异，而其余像素的灰度值保持不变，因此在图像中造成过亮或过暗的像素点。椒盐噪声严重影响图像的视觉质量，给图像的边缘检测、纹理或者特征点提取等造成困难。 去椒盐噪声办法1234567891、中值滤波2、开关中值滤波器 SMF（Switching Median Filter）[参考文献](Detail - preserving median based filters in image rocessing)3、自适应中值滤波器 AMF（Adaptive Median Filter）[参考文献](Adaptive median filters : New algorithms and results)4、自适应中心加权中值滤波器 ACWMF（Adaptive Center Weighted Median Filter） [参考文献](adaptive impulse detection using center Weighted median filter)5、基于决策的算法ＤＢＡ ( Decision Based Algorithm) [参考文献](A new fast and efficient decision Based algorithm for removal of high density impulse noises) 一般会选择先检测再滤波的思路，通过开关机制抑制噪声，上述方法对低噪声水平的椒盐噪声处理效果良好，噪声水平过高无法得到理想的结果。因为基于中值的滤波方法仅考虑图像局部区域像素点的顺序阶信息，没有充分利用像素点之间的相关性或相似性。噪声像素点的估计值可能与真实值有较大偏差，很难保持图像的细节信息。 高斯噪声高斯噪声是指概率密度函数服从高斯分布（即正态分布）的一类噪声。如果一个噪声，它的幅度服从高斯分布，而它的功率谱密度又是分布均匀的，则称它为高斯白噪声。高斯白噪声的二阶矩不想关，一阶矩为常数，是指先后信号在时间上的相关性。高斯白噪声包括热噪声和散粒噪声。高斯噪声完全由其时变平均值和两瞬时的协方差函数来确定，若噪声为平稳的，则平均值与时间无关，而协方差函数则变成仅和所考虑的两瞬时之方差有关的相关函数，它在意义上等效于功率谱密度。高斯噪声可以由大量独立的脉冲产生，从而在任何有限时间间隔内，这些脉冲中的每一个脉冲值与所有脉冲值的总和相比都可以忽略不计]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理_DCT（占坑）]]></title>
    <url>%2F2018%2F10%2F25%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86_DCT%2F</url>
    <content type="text"><![CDATA[DCT]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo添加相册]]></title>
    <url>%2F2018%2F09%2F23%2FHexo%E7%9B%B8%E5%86%8C%2F</url>
    <content type="text"><![CDATA[相册 实现思路1.在主页上必须有一个可供点击的相册连接2.要用 hexo 生成一个 photos.html 文件3.photos.html 中的图片数据来源?因为这是一个静态页面所有要有一个 json 文件4.json 文件中有含有信息,图片的文件名.5.图片要有一个完整的路径,用github的空间6.Python脚本剪裁、压缩、上传图片到自定义的github备份仓库中不多说废话了,顺着思路逐一解决问题吧 操作步骤1.在主页上必须有一个可供点击的连接BLOG\source目录下创建一个photos目录，目的是存放利用脚本生成的json 文件和渲染文件。 配置 Yilia 主题让其显示出来.yourBlog/themes/yilia/_config.yml文件添加相册 1相册: /photos/ 2.如何生成 photos.html 文件来在github上新建一个仓库，主要用于存储图片，可以通过url访问到，也方便管理，备份图片和其他东西 git clone 到本地，模仿作者的文件目录结构 source文件夹是备份图片，theme是备份yilia配置文件等 min_photos是缩略图文件夹，photos是原图文件夹，blog_photos_copy是渲染文件备份，最后再弄 备份渲染文件，最后再弄 ejs 文件是以后要hexo 文件渲染的文件. ins.js 文件设置自己的东西. 3.修改 ejs 模板文件3.1 index.ejs文件可以不用修改3.2 修改 ins.js 文件的 render()函数.这个函数是用来渲染数据的修改图片的路径地址.minSrc 小图的路径. src 大图的路径.修改为自己的图片路径(github的路径). 12var minSrc = &apos;https://raw.githubusercontent.com/AomanHao/Blog-Back-Up/master/source/min_photos/&apos; + data.link[i];var src = &apos;https://raw.githubusercontent.com/AomanHao/Blog-Back-Up/master/source/photos/&apos; + data.link[i]; 这个链接不是直接的图片url，是需要点“下载”才能看到的url。 github仓库上传的图片文件 下载选项，看网址 黄色画出了链接网址，路径地址.minSrc 小图的路径. src 大图的路径 我的路径有source/min_photos/和source/photos，分别是缩略图（压缩的图快速加载预览）和原图（点击查看图片） 3.3生成 json 文件.这一步是关键的一步,也是最后一步.先用脚本把图片处理成一套大图和一套小图,然后上传的七牛或者 github 上再回头生成这个 json文件.每次更新图片都要执行脚本重新生成 json 文件.这个json 文件会出现在yourBlog/source/photos/data.json 4.处理图片处理脚本试用python语言写的，运行环境也是python python脚本文件原作者GitHub地址：https://github.com/lawlite19/Blog-Back-Up 下载python2或者3，在cmd运行窗口运行python tool.py tool.py是运行主函数，ImageProcess图像处理功能函数，包括裁剪、压缩等 git_operation()方法: 如果你把图片上传到你的 github上这个方法就不用更改了.但是要确保在可以push到github的文件夹里，按照之前操作兴建了博客文件备份仓库 handlephoto()方法:注意: 该脚本对图片的命名规则有要求.最前面是日期，然后用进行分隔；后面是图片的描述信息，注意不要包含_和.符号 5.注意事项5.1最前面是日期，然后用进行分隔；后面是图片的描述信息，注意不要包含和.符号 图片应该这样命名: 2016-10-12_xxx.jpg/png；存放在photos中，然后脚本运行会生成压缩图片，放置在min_photos文件夹中。 5.2 tool.py文件中open里面的设置的是本地博客路径 如D:/GitHub/AomanHao.github.io/source/photos/data.json D:/GitHub/AomanHao.github.io/是你的博客在本地的路径，data.json是图片信息文件 5.3点开图片可以显示，缩略图不显示 下载empty图，下载地址，直接右键另存，保存为“empty.png”。 在你博客的本地仓库source下新建一个文件夹命名为assets,再在assets下新建一个文件夹命名为img。最后把empty.png放到img里面。 我的目录如下： 结尾：在github上新建一个仓库，主要用于存储图片，可以通过url访问到，也方便管理将要放到相册的图片处理成json格式的数据，然后进行访问，这里json的格式需要配合要使用的样式，所以需要处理成特定格式的json数据，下面会给出图片裁剪，因为相册显示的样式最好是正方形的的图片，这里使用脚本处理一下图片压缩，相册显示的图片是压缩后的图片，提高加载的速度，打开后的图片是原图。 问题：当我用中文作为相册名字的时候，无法生成data.json文件，很纳闷，报错 UTF8的编码错误 算了，暂时找不改正的方法，科恩你是python是2.多的原因吧，我的相片都是用了英文命名 参考文章1参考文章2参考文章3]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VScode配置]]></title>
    <url>%2F2018%2F09%2F19%2FVScode%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[VScode配置 VScode插件Git History（装完输入 git log有惊喜) Git Lens（让本就集成了 git 的 VSC 更加强大 Markdown Preview Enhanced(markdown 预览) Emoji Code Dracula Official 吸血鬼主题，暗黑风格 Code Runner —- 支持多种语言例如： C，C++，Java，JavaSript，PHP，Python，Perl，Perl6 等 Bracket Pair Colorizer 和 Indent Rainbow，这两个插件可以让不同缩减的括号显示不同的颜色。 Auto Close Tag 和 Auto Rename Tag 插件，自动补全标签和联动重名标签 Studio Icons 图标展示，丰富界面 VScode设置中文界面123456781、按f1，搜索 Configore Display Language 设置 zh-cn 关闭软件重启。2、如果重启菜单等还是英文的，在商店查看已安装的插件，把中文插件重新安装一遍，然后重启软件。应用商店搜索插件-chinese(simplified) 参考文章]]></content>
      <tags>
        <tag>VScode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git配置]]></title>
    <url>%2F2018%2F09%2F19%2FGit%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Git配置 右键菜单配置 Git Bash Here 功能键运行regedit.exe进入注册表，在HKEY_CLASSES_ROOT\Directory\Background\shell中进行设置。 1.新建项Git Bush Here，此时你可以看到在桌面右键会出现“Git Bush Here”菜单。 2.添加Git Bush Icon，在第一步的新建项Git Bush Here下，新建字符串值Icon，然后编辑该值为“C:\Program Files\Git\mingw64\share\git\git-for-windows.ico”，你需要根据你安装的Git 目录进行配置修改。完成此步后，你会发现右键菜单“Git Bush Here”会多出一个Icon。 3.添加Command项。在“Git Bush Here”下再新建项“Command”，将其默认值改为“C:\Program Files\Git\bin\bash.exe —login -i”，这样，你就可以通过右键菜单的方式快速进入Git命令行工具，进行代码版本管理。 git 命令1.git config 该命令允许你获得和设置配置变量；这些变量可以控制Git的外观和操作的各个方面。123使用方法: git config –global user.name “[name]”使用方法: git config –global user.email “[email address]” 2.git init git init命令创建一个空的Git仓库或重新初始化一个现有仓库。1使用方法：git init [repository name] 3.git clone git clone命令将存储库克隆到新目录中。1使用方法：git clone [url] 4.git add git add命令将文件内容添加到索引(将修改添加到暂存区)。也就是将要提交的文件的信息添加到索引库中。1使用方法: git add [file] ; 5.git commit该命令用于将更改记录(提交)到存储库。将索引的当前内容与描述更改的用户和日志消息一起存储在新的提交中。 123使用方法: git commit -m “[ Type in the commit message]”使用方法：git commit -a 在修改文件后,需要使用gitadd把文件加入暂存区,这样gitcommit时才能把已经修改的信息加入版本库,而使用gitcommit-a可以不用再git add。 6.git diff 该命令用于显示提交和工作树等之间的更改。此命令比较的是工作目录中当前文件和暂存区域快照之间的差异，也就是修改之后还没有暂存起来的变化内容。123使用方法: git diff使用方法：git diff –staged gitdiff—staged显示的是暂存区和版本库差异 1使用方法：git diff [first branch] [second branch] 命令显示两个分支之间的差异。 7.git resetgit reset命令用于将当前HEAD复位到指定状态。一般用于撤消之前的一些操作(如:git add,git commit等)。123使用方法: git reset [file]使用方法: git reset [commit] 撤消指定提交后的所有提交，并在本地保留更改。 1使用方法：git reset –hard [commit] 丢弃所有历史记录并返回到指定的提交。 8.git status该命令用于显示工作目录和暂存区的状态。1使用方法: git status 9.git rm该命令用于从工作区和索引中删除文件。1使用方法: git rm [file] 10.git log该命令用于显示提交日志信息。123使用方法: git log使用方法：git log –follow[file] 列出文件的版本历史记录，包括文件的重命名。 11.git show该命令用于显示各种类型的对象。1使用方法: git show [commit] 12.git tag该命令用于创建,列出,删除或验证使用GPG签名的标签对象。1使用方法: git tag [commitID] 13.git branch 该命令列出当前存储库中的所有本地分支。123使用方法: git branch使用方法：git branch [branch name] 创建一个新分支。 1使用方法：git branch -d [branch name] 删除分支 14.git checkout 该命令命令用于从一个分支切换到另一个分支。 使用方法：git checkout [branch name] 使用方法: git checkout -b [branch name] 该命令创建一个新分支并切换过去。 15.git merge该命令用于将两个或两个以上的开发历史加入(合并)一起。 使用方法: git merge [branch name] 16.git remote该命令管理一组跟踪的存储库。 使用方法: git remote add [variable name] [Remote Server Link] 17.git push该命令用于将本地分支的更新,推送到远程主机。 使用方法: git push [variable name] master 使用方法：git push [variable name] [branch] 将分支提交到远程存储库。 使用方法：git push –all [variable name] 将所有分支推送到远程存储库。 使用方法: git push [variable name] :[branch name] 删除远程存储库上的分支。 18.git pull该命令用于从另一个存储库或本地分支获取并集成(整合)。 使用方法: git pull [Repository Link] 19.git stash该命令临时存储所有已修改的跟踪文件。。 使用方法: git stash save 使用方法：git stash pop 可恢复最近隐藏的文件。 使用方法：git stash list 列出所有存储的更改集。 使用方法：git stash drop 移除stash]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理_灰度变换_直方图]]></title>
    <url>%2F2018%2F09%2F07%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86_%E7%81%B0%E5%BA%A6%E5%8F%98%E6%8D%A2_%E7%9B%B4%E6%96%B9%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[图像处理灰度变换直方图 直方图均衡化 Histogram Equalization假如图像的灰度分布不均匀，其灰度分布集中在较窄的范围内，使图像的细节不够清晰，对比度较低。通常采用直方图均衡化及直方图规定化两种变换，使图像的灰度范围拉开或使灰度均匀分布，从而增大反差，使图像细节清晰，以达到增强的目的。直方图均衡化，对图像进行非线性拉伸，重新分配图像的灰度值，使一定范围内图像的灰度值大致相等。这样，原来直方图中间的峰值部分对比度得到增强，而两侧的谷底部分对比度降低，输出图像的直方图是一个较为平坦的直方图。 均衡化算法直方图的均衡化实际也是一种灰度的变换过程，将当前的灰度分布通过一个变换函数，变换为范围更宽、灰度分布更均匀的图像。也就是将原图像的直方图修改为在整个灰度区间内大致均匀分布，因此扩大了图像的动态范围，增强图像的对比度。通常均衡化选择的变换函数是灰度的累积概率，直方图均衡化算法的步骤： 1、计算原图像的灰度直方图 P(Sk)=nkn，其中n为像素总数，nk为灰度级Sk的像素个数 2、计算原始图像的累积直方图 CDF(Sk)=∑i=0knin=∑i=0kPs(Si)Dj=L⋅CDF(Si)，其中 Dj是目的图像的像素，CDF(Si)是源图像灰度为i的累积分布，L是图像中最大灰度级（灰度图为255）直接应用该方法得到图像的灰度直方图 3\将灰度直方图进行归一化，计算灰度的累积概率；创建灰度变化的查找表应用查找表，将原图像变换为灰度均衡的图像 均衡化过程中，必须要保证两个条件 1、像素无论怎么映射，一定要保证原来的大小关系不变，较亮的区域，依旧是较亮的，较暗依旧暗，只是对比度增大，绝对不能明暗颠倒；2、如果是八位图像，那么像素映射函数的值域应在0和255之间的，不能越界。 综合以上两个条件，累积分布函数是个好的选择，因为累积分布函数是单调增函数（控制大小关系），并且值域是0到1（控制越界问题），所以直方图均衡化中使用的是累积分布函数。 累积分布函数累积分布函数具有一些好的性质，那么如何运用累积分布函数使得直方图均衡化？比较概率分布函数和累积分布函数，前者的二维图像是参差不齐的，后者是单调递增的。直方图均衡化过程中，映射方法是 S_k = \sum_{j=0}^k\frac{n_j}{n} . k=0,1...,L-1$n$是图像素总和，$n_k$是当前灰度级的像素个数，$L$是图像中灰度级总数 操作步骤有: 直方图规定化直方图规定化，就是对原始图像做变换，使得变换后的图像的直方图跟我们规定的一样。 具体步骤如下： 1、首先对原始图像做直方图均衡化，得到每个像素s和累积分布T(s); 2、根据需要的规定化直方图，求累积分布G(Z)； 3、显然，如果累积直方图中有0值，那么是不会分配像素值的，因为0乘以255还是零。 4、对于每一个T（s）（假设其像素值为ss）,找到在G（Z）中与其差值最小的那个G（z）值（假设对应的像素值为zz），那么规定化后就把ss变换为zz。 直方图规定化流程下图： 1、计算原图像的累积直方图 2、计算规定直方图的累积直方图 3、计算两累积直方图的差值的绝对值 4、根据累积直方图差值建立灰度级的映射 局部直方图处理&amp;直方图统计Opencv代码灰度直方图均衡123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128// HistogramGrayEqualizeHist.cpp : 定义控制台应用程序的入口点。//#include &quot;stdafx.h&quot;#include &lt;iostream&gt;#include &lt;opencv2/core/core.hpp&gt; //cvGetSize cvCreateImage#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/opencv.hpp&gt; //cvResize cvInitMatHeader cvGetMinMaxHistValue cvCvtColor#include &lt;opencv2/imgproc/imgproc.hpp&gt;#ifdef _DEBUG#pragma comment(lib, &quot;opencv_core244d&quot;)#pragma comment(lib, &quot;opencv_highgui244d&quot;)#pragma comment(lib, &quot;opencv_imgproc244d&quot;) //cvResize#else#pragma comment(lib, &quot;opencv_core244d&quot;)#pragma comment(lib, &quot;opencv_highgui244d&quot;)#pragma comment(lib, &quot;opencv_imgproc244d&quot;) //cvResize#endif#define cvQueryHistValue_1D(hist,idx0) ((float)cvGetReal1D( (hist)-&gt;bins, (idx0)))using namespace std; #pragma comment(linker, &quot;/subsystem:\&quot;windows\&quot; /entry:\&quot;mainCRTStartup\&quot;&quot;) void FillWhite(IplImage *pImage) &#123; cvRectangle(pImage, cvPoint(0, 0), cvPoint(pImage-&gt;width, pImage-&gt;height), CV_RGB(255, 255, 255), CV_FILLED); &#125; // 创建灰度图像的直方图 CvHistogram* CreateGrayImageHist(IplImage **ppImage) &#123; int nHistSize = 256; float fRange[] = &#123;0, 255&#125;; //灰度级的范围 float *pfRanges[] = &#123;fRange&#125;; CvHistogram *pcvHistogram = cvCreateHist(1, &amp;nHistSize, CV_HIST_ARRAY, pfRanges); cvCalcHist(ppImage, pcvHistogram); return pcvHistogram; &#125; // 根据直方图创建直方图图像 IplImage* CreateHisogramImage(int nImageWidth, int nScale, int nImageHeight, CvHistogram *pcvHistogram) &#123; IplImage *pHistImage = cvCreateImage(cvSize(nImageWidth * nScale, nImageHeight), IPL_DEPTH_8U, 1); FillWhite(pHistImage); //统计直方图中的最大直方块 float fMaxHistValue = 0; cvGetMinMaxHistValue(pcvHistogram, NULL, &amp;fMaxHistValue, NULL, NULL); //分别将每个直方块的值绘制到图中 int i; for(i = 0; i &lt; nImageWidth; i++) &#123; float fHistValue = cvQueryHistValue_1D(pcvHistogram, i); //像素为i的直方块大小 int nRealHeight = cvRound((fHistValue / fMaxHistValue) * nImageHeight); //要绘制的高度 cvRectangle(pHistImage, cvPoint(i * nScale, nImageHeight - 1), cvPoint((i + 1) * nScale - 1, nImageHeight - nRealHeight), cvScalar(i, 0, 0, 0), CV_FILLED ); &#125; return pHistImage; &#125; int main( int argc, char** argv ) &#123; const char *pstrWindowsSrcTitle = &quot;原图&quot;; const char *pstrWindowsGrayTitle = &quot;灰度图&quot;; const char *pstrWindowsHistTitle = &quot;直方图&quot;; const char *pstrWindowsGrayEqualizeTitle = &quot;灰度图-均衡化后&quot;; const char *pstrWindowsHistEqualizeTitle = &quot;直方图-均衡化后&quot;; // 从文件中加载原图 // IplImage *pSrcImage = cvLoadImage(&quot;./images/yangmi.jpg&quot;, CV_LOAD_IMAGE_UNCHANGED); IplImage *pSrcImage = cvLoadImage(&quot;./images/beauty.png&quot;, CV_LOAD_IMAGE_UNCHANGED); IplImage *pGrayImage = cvCreateImage(cvGetSize(pSrcImage), IPL_DEPTH_8U, 1); IplImage *pGrayEqualizeImage = cvCreateImage(cvGetSize(pSrcImage), IPL_DEPTH_8U, 1); // 灰度图 cvCvtColor(pSrcImage, pGrayImage, CV_BGR2GRAY); // 直方图图像数据 int nHistImageWidth = 255; int nHistImageHeight = 150; int nScale = 2; // 灰度直方图及直方图图像 CvHistogram *pcvHistogram = CreateGrayImageHist(&amp;pGrayImage); IplImage *pHistImage = CreateHisogramImage(nHistImageWidth, nScale, nHistImageHeight, pcvHistogram); // 均衡化 //函数功能：直方图均衡化，该函数能归一化图像亮度和增强对比度 //第一个参数表示输入图像，必须为灰度图（8位，单通道图） //第二个参数表示输出图像 //该函数采用如下法则对输入图像进行直方图均衡化： //1：计算输入图像的直方图H。 //2：直方图归一化，因此直方块和为255。 //3：计算直方图积分，H&apos;(i) = Sum(H(j)) (0&lt;=j&lt;=i)。 //4：采用H&apos;作为查询表：dst(x, y) = H&apos;(src(x, y))进行图像变换。 cvEqualizeHist(pGrayImage, pGrayEqualizeImage); // 均衡化后的灰度直方图及直方图图像 CvHistogram *pcvHistogramEqualize = CreateGrayImageHist(&amp;pGrayEqualizeImage); IplImage *pHistEqualizeImage = CreateHisogramImage(nHistImageWidth, nScale, nHistImageHeight, pcvHistogramEqualize); // 显示 cvNamedWindow(pstrWindowsSrcTitle); cvNamedWindow(pstrWindowsGrayTitle); cvNamedWindow(pstrWindowsGrayEqualizeTitle); cvNamedWindow(pstrWindowsHistTitle); cvNamedWindow(pstrWindowsHistEqualizeTitle); cvShowImage(pstrWindowsSrcTitle,pSrcImage); cvShowImage(pstrWindowsGrayTitle,pGrayImage); cvShowImage(pstrWindowsGrayEqualizeTitle,pGrayEqualizeImage); cvShowImage(pstrWindowsHistTitle,pHistImage); cvShowImage(pstrWindowsHistEqualizeTitle,pHistEqualizeImage); cvWaitKey(0); //回收资源代码… cvDestroyWindow(pstrWindowsSrcTitle); cvDestroyWindow(pstrWindowsGrayTitle); cvDestroyWindow(pstrWindowsGrayEqualizeTitle); cvDestroyWindow(pstrWindowsHistTitle); cvDestroyWindow(pstrWindowsHistEqualizeTitle); cvReleaseImage(&amp;pSrcImage); cvReleaseImage(&amp;pGrayImage); cvReleaseImage(&amp;pGrayEqualizeImage); cvReleaseImage(&amp;pHistImage); cvReleaseImage(&amp;pHistEqualizeImage); return 0; &#125; 直方图规定化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556void hist_specify(const Mat &amp;src, const Mat &amp;dst,Mat &amp;result)&#123; Histogram1D hist1D; MatND src_hist = hist1D.getHistogram(src); MatND dst_hist = hist1D.getHistogram(dst); float src_cdf[256] = &#123; 0 &#125;; float dst_cdf[256] = &#123; 0 &#125;; // 源图像和目标图像的大小不一样，要将得到的直方图进行归一化处理 src_hist /= (src.rows * src.cols); dst_hist /= (dst.rows * dst.cols); // 计算原始直方图和规定直方图的累积概率 for (int i = 0; i &lt; 256; i++) &#123; if (i == 0) &#123; src_cdf[i] = src_hist.at&lt;float&gt;(i); dst_cdf[i] = dst_hist.at&lt;float&gt;(i); &#125; else &#123; src_cdf[i] = src_cdf[i - 1] + src_hist.at&lt;float&gt;(i); dst_cdf[i] = dst_cdf[i - 1] + dst_hist.at&lt;float&gt;(i); &#125; &#125; // 累积概率的差值 float diff_cdf[256][256]; for (int i = 0; i &lt; 256; i++) for (int j = 0; j &lt; 256; j++) diff_cdf[i][j] = fabs(src_cdf[i] - dst_cdf[j]); // 构建灰度级映射表 Mat lut(1, 256, CV_8U); for (int i = 0; i &lt; 256; i++) &#123; // 查找源灰度级为ｉ的映射灰度 // 和ｉ的累积概率差值最小的规定化灰度 float min = diff_cdf[i][0]; int index = 0; for (int j = 1; j &lt; 256; j++) &#123; if (min &gt; diff_cdf[i][j]) &#123; min = diff_cdf[i][j]; index = j; &#125; &#125; lut.at&lt;uchar&gt;(i) = static_cast&lt;uchar&gt;(index); &#125; // 应用查找表，做直方图规定化 LUT(src, lut, result);&#125;]]></content>
      <tags>
        <tag>Opencv</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习面试]]></title>
    <url>%2F2018%2F09%2F04%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E7%B2%BE%E5%8D%8E%2F</url>
    <content type="text"><![CDATA[机器学习面试 SVM： 简单介绍SVM（详细原理）：从分类平面，到求两类间的最大间隔，到转化为求间隔分之一，等优化问题，然后就是优化问题的解决办法，首先是用拉格拉日乘子把约束优化转化为无约束优化，对各个变量求导令其为零，得到的式子带入拉格朗日式子从而转化为对偶问题， 最后再利用SMO（序列最小优化）来解决这个对偶问题。svm里面的c有啥用 SVM的推导，解释原问题和对偶问题，SVM原问题和对偶问题的关系，KKT限制条件，KKT条件用哪些，完整描述；软间隔问题，解释支持向量、核函数（哪个地方引入、画图解释高维映射，高斯核可以升到多少维，如何选择核函数），引入拉格朗日的优化方法的原因，最大的特点，损失函数解释， SVM与LR最大区别，LR和SVM对于outlier的敏感程度分析，逻辑回归与SVM的区别 为什么要把原问题转换为对偶问题？因为原问题是凸二次规划问题，转换为对偶问题更加高效。为什么求解对偶问题更加高效？因为只用求解alpha系数，而alpha系数只有支持向量才非0，其他全部为0.alpha系数有多少个？样本点的个数 加大训练数据量一定能提高SVM准确率吗？ 与感知器的联系和优缺点比较 如何解决多分类问题、可以做回归吗，怎么做 它与其他分类器对比的优缺点，它的速度 机器学习有很多关于核函数的说法，核函数的定义和作用是什么？https://www.zhihu.com/question/24627666 支持向量机(SVM)是否适合大规模数据？https://www.zhihu.com/question/19591450 SVM和逻辑斯特回归对同一样本A进行训练，如果某类中增加一些数据点，那么原来的决策边界分别会怎么变化？https://www.zhihu.com/question/30123068 各种机器学习的应用场景分别是什么？例如，k近邻,贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。https://www.zhihu.com/question/26726794 Linear SVM 和 LR 有什么异同？https://www.zhihu.com/question/26768865 1VM转化为对偶问题后，分类只需要计算与少数几个支持向量的距离，这个在进行复杂核函数计算时优势很明显，能够大大简化模型和计算量。 LR LR推导（伯努利过程，极大似然，损失函数，梯度下降）有没有最优解？ LR可以用核么？可以怎么用？l1和l2正则项是啥？lr加l1还是l2好？加哪个可以用核（加l2正则项，和svm类似，加l2正则项可以用核方便处理） LR可以用来处理非线性问题么？（还是lr啊 只不过是加了核的lr 这里加核是显式地把特征映射到高维 然后再做lr）怎么做？可以像SVM那样么？为什么？ 为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好，为什么把特征组合之后还能提升，反正这些基本都是增强了特征的表达能力，或者说更容易线性可分吧 美团技术团队《Logistic Regression 模型简介》https://tech.meituan.com/intro_to_logistic_regression.html SVM和logistic回归分别在什么情况下使用？https://www.zhihu.com/question/21704547 1234567891011121314151617两种方法都是常见的分类算法，svm-统计的方法 LR-几何的方法 区别在于1、（损失函数的目的都是增加对分类影响较大的数据点的权重）逻辑回归采用的是logistical losssvm采用的是hinge loss2、LR~不带核函数的svm特征少，样本数量适中--用svm算法特征多，样本数量少 --用LR或者不带核函数的svm 特征少，样本数量很多--先增加更多的feature，再使用LR算法或者不带核函数的SVM 3、svm对异常点敏感LR对异常点不敏感 逻辑斯蒂回归能否解决非线性分类问题？https://www.zhihu.com/question/29385169 12对特征做非线性变换 比如kernel，最后一层看成是lr 前面看成是提特征。lr的应用场景主要是特征很多的情况LR用kernel容易过拟合，svm不容易过拟合 为什么LR可以用来做CTR预估？https://www.zhihu.com/question/23652394 逻辑回归估计参数时的目标函数 （就是极大似然估计那部分），逻辑回归估计参数时的目标函数 （呵呵，第二次） 逻辑回归估计参数时的目标函数 如果加上一个先验的服从高斯分布的假设，会是什么样（天啦。我不知道，其实就是在后面乘一个东西，取log后就变成加一个东西，实际就变成一个正则项） 逻辑回归估计参数时的目标函数逻辑回归的值表示概率吗？（值越大可能性越高，但不能说是概率） 手推逻辑回归目标函数，正类是1，反类是-1，这里挖了个小坑，一般都是正例是1，反例是0的，他写的时候我就注意到这个坑了，然而写的太快又给忘了，衰，后来他提醒了一下，改了过来，就是极大似然函数的指数不一样，然后说我这里的面试就到这了。 看没看过scikit-learn源码LR的实现？（回头看了一下是调用的liblinear，囧） 为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好，为什么把特征组合之后还能提升，反正这些基本都是增强了特征的表达能力，或者说更容易线性可分吧naive bayes和logistic regression的区别http://m.blog.csdn.net/blog/muye5/19409615 LR为什么用sigmoid函数。这个函数有什么优点和缺点？为什么不用其他函数？sigmoid函数由那个指数族分布，加上二项分布导出来的。损失函数是由最大似然估计求出的。了解其他的分类模型吗，问LR缺点，LR怎么推导（当时我真没准备好，写不出来）写LR目标函数，目标函数怎么求最优解（也不会）讲讲LR的梯度下降，梯度下降有哪几种，逻辑函数是啥 12 L1和L212345678910111213L2正则化，为什么L2正则化可以防止过拟合？L1正则化是啥？深度学习里面怎么防止过拟合？（data aug；dropout；multi-task learning）如何防止过拟合，我跟他列举了4中主要防止过拟合方法：Early Stopping、数据集扩充、正则化法以及dropout，还详细跟他说了每种方法原理及使用的场景，并解释我在哪些项目里具体用到了这些方法，机器学习中使用「正则化来防止过拟合」到底是一个什么原理？为什么正则化项就可以防止过拟合？https://www.zhihu.com/question/20700829机器学习中常常提到的正则化到底是什么意思？https://www.zhihu.com/question/20924039什么是正则项，L1范式，L2范式区别是什么，各自用在什么地方？L1 与 L2 的区别以及如何解决 L1 求导困难；L1正则为什么能让系数变为0？L1正则怎么处理0点不可导的情形？（这个谁会？近端梯度下降）L0，L1，L2正则化(如果能推导绝对是加分项，一般人最多能画个等高线，L0是NP问题)其实上面的这些问题基本都能在《李航：统计学习方法》《周志华：机器学习》里面找到，能翻个4，5遍基本就无压力了避免过拟合策略、如何提高模型泛化能力、L1与L2正则区别，优缺点、生成式，判别式模型、深度学习这块了解多少、如何克服过拟合，欠拟合L1 与 L2 的区别以及如何解决 L1 求导困难；L1正则为什么可以把系数压缩成0，坐标下降法的具体实现细节为什么L1正则可以实现参数稀疏，而L2正则不可以？为什么L1很多系数可以被压缩为0，L2是被压缩至接近于0？树模型 决策树：1234567891011121314151617181920212223242526rf ， gbdt 的区别； gbdt ， xgboost 的区别（烂大街的问题最好从底层原理去分析回答）介绍决策树，谈了3种决策树及其区别和适应场景决策树处理连续值的方法；简单介绍决策树几种算法，有什么区别？决策树基本模型介绍？决策树算法中缺失值怎么处理？决策树算法在应用中有什么值得注意的地方。SVM、LR、决策树的对比？GBDT 和 决策森林 的区别？决策树的特性？（3 ）决策树处理连续值的方法；解释下随机森林和gbdt的区别。gbdt的boosting体现在哪里。解释下随机森林节点的分裂策略，以及它和gbdt做分类有什么区别？哪个效果更好些？为什么？哪个更容易过拟合？为什么？ 问了随机森林的损失函数，和lr的优缺点对比， adaboost和随机森林的比较，为了防止随机森林过拟合可以怎么做，是否用过随机森林，怎么用的。随机森林和GBDT的区别？CART（回归树用平方误差最小化准则，分类树用基尼指数最小化准则）GBDT（利用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值，拟合一个回归树）随机森林（Bagging+CART）SVM与随机森林比较改变随机森林的训练样本数据量，是否会影响到随机森林学习到的模型的复杂度Logistics与随机森林比较GBDT与随机森林比较随机森林的学习过程；随机森林中的每一棵树是如何学习的；随机森林学习算法中CART树的基尼指数是什么？RF 与 GBDT 区别，原理优缺点适用场景分析，哪个具备交叉验证功能等接着写一下信息增益的公式。之后就是问机器学习相关算法，说了一下bagging跟boosting，之后问了GBDT（没做过，只能说说大体思路）。（2 ） rf ， gbdt 的区别； gbdt ， xgboost 的区别；说说xgboost、gbdt区别、Tree-based Model如何处理连续型特征。让我把一个完整的数据挖掘流程讲一下，从预处理，特征工程，到模型融合。介绍常用的算法，gbdt和xgboost区别，具体怎么做预处理，特征工程，模型融合常用方式，融合一定会提升吗？gbdt树根据什么分裂（瞎扯的梯度近似残差、梯度下降方向，其实还是信息增益这种东西）gbdt怎么并发（特征选择层面，树层面不能并发）介绍LR、RF、GBDT ，分析它们的优缺点，是否写过它们的分布式代码XGB和GBDT区别与联系也会经常问到：https://www.zhihu.com/question/41354392/answer/128008021?group_id=773629156532445184CART（回归树用平方误差最小化准则，分类树用基尼指数最小化准则）、Logistics（推导）、GBDT（利用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值，拟合一个回归树）在面试过程中主动引导面试官提问，比如面试官让你讲解 gbdt 原理时，这会你可以跟他说，一般说起 gbdt ，我们都会跟 rf 以及 xgboost 一块讲，然后你就可以主动地向面试官输出你的知识；面试并不是死板地你问我答，而是一种沟通交流，所以尽可能地把面试转化成聊天式的对话，多输出自己一些有价值的观点而不是仅仅为了回答面试官的问题；几种树模型的原理和对比，特征选取怎么选？ 为什么信息增益可以用来选特征？信息熵和基尼指数的关系(信息熵在x=1处一阶泰勒展开就是基尼指数)介绍xgboost一下。写下xgboost目标函数。（因为我提到xgboost在目标函数里显式地加入了正则项..血雪崩）怎么调整XGB参数；xgboost原理 K-means1234567891011k-means 聚类的原理以及缺点及对应的改进；kmeans 算法的优缺点。。。。kmeans 的原理，优缺点以及改进；em 与 kmeans 的关系；kmeans 代码；说说 Kmeans 算法， Kmeans 算法 K 怎么设置、适用什么样数据集、怎么评价 Kmeans 聚类结果、 Kmeans 有什么优缺点？你的项目中使用 Kmeans 遇到哪些问题，怎么解决的 ?用 EM 算法推导解释 Kmeans。KMeans的算法伪代码如何判断自己实现的 LR、Kmeans 算法是否正确？如何优化kmeans算法如何用hadoop实现k-means手写k-means的伪代码（就6行） 集成学习123456bagging和boosting是怎么做的和他们的比较详细讨论了样本采样和bagging的问题聊的比较多的是如何知道一个特征的重要性，如何做ensemble哪些方法比较好。聊了聊计算广告方面FM，embedding。常见融合框架原理，优缺点，bagging，stacking，boosting，为什么融合能提升效果是否了解线性加权、bagging、boosting、cascade等模型融合方式K-means起始点http://www.cnki.com.cn/Article/CJFDTotal-DNZS200832067.htm 贝叶斯12345朴素贝叶斯分类器原理以及公式，出现估计概率值为 0 怎么处理（拉普拉斯平滑），缺点；解释贝叶斯公式和朴素贝叶斯分类。贝叶斯分类，这是一类分类方法，主要代表是朴素贝叶斯，朴素贝叶斯的原理，重点在假设各个属性类条件独立。然后能根据贝叶斯公式具体推导。考察给你一个问题，如何利用朴素贝叶斯分类去分类，比如：给你一个人的特征，判断是男是女，比如身高，体重，头发长度等特征的的数据，那么你要能推到这个过程。给出最后的分类器公式。那你说说贝叶斯怎么分类啊？比如说看看今天天气怎么样？我：blabla，，，利用天气的历史数据，可以知道天气类型的先验分布，以及每种类型下特征数据（比如天气数据的特征：温度啊，湿度啊）的条件分布，这样我们根据贝叶斯公式就能求得天气类型的后验分布了。。。。面试官：en（估计也比较满意吧）那你了解关于求解模型的优化方法吗？一般用什么优化方法来解？贝叶斯分类器的优化和特殊情况的处理 深度学习12345678910111213141516解释一下CNN、介绍CNN、卷积公式，以及特点，假设面试官什么都不懂，详细解释 CNN 的原理；问CNN的细节特点，哪些特点使得CNN这么好用，哪些场景用CNN可以，抽象一下这些场景的特征，可以降采样但仍能保持主要信息；局部连接可以保证获取局部信息；权值共享保证高效，DNN和CNN相比有哪些区别，用过RNN么？画一下RNN的图，你在深度学习过程中遇到过哪些问题？如果出现过拟合你怎么办？dropout是什么？它有什么用？你会怎么用它？当全连接跟dropout连着用需要注意什么？你之前过拟合怎么解决的？如果本身training loss就很大你怎么办？如果数据不变，怎么调整网络结构解决这个问题？（batch normalization）梯度消失知道么？为什么会出现梯度消失？dnn和rnn中的梯度消失原理一样么？dnn中是哪个部分导致梯度消失？（激活层如sigmoid）rnn中怎么解决梯度消失问题？（lstm的结构相对普通RNN多了加和，为避免梯度消散提供了可能。线性自连接的memory是关键。）讲一下CNN吧，有哪些重要的特点？CNN可以处理哪些场景？为什么CNN要用权值共享？（每个卷积核相当于一个特征提取器，它的任务是匹配局部图像中的特征，权值共享后，匹配的特征方式都是一样的，提取若干特征后就知道学习的是啥了）CNN里面哪些层？讲一下卷积。卷积的形式是啥样？给定一个输入，算输出的feature map大小。卷积有啥用？池化有啥用？有哪些池化方式？池化除了降采样还有啥用？（就不知道了）还有哪些层你用过？讲讲dropout。dropout内部是怎么实现只让部分信号通过并不更新其余部分对于输入的权值的？讲讲BN（BatchNormalization）为什么好？全连接有什么用处？知道RNN么？讲讲RNN大致的实现思路。知道梯度消失么？为什么会出现梯度消失？RNN里的梯度消失一般怎么处理？细讲下lstm的结构，这样设计为什么好？（门关闭，当前信息不需要，只有历史依赖；门打开，历史和当前加权平均）你觉得梯度消失靠引入一些新的激活层可以完全解决么？为什么？问了做的比赛里面使用tensorflow的细节，LSTM里调参的细节用过哪些库或者工具，mkl，cuda这些会用吗？有一个弱分类器和大量未被标记过的图像数据，如何人工标记图像来对分类器进行提升介绍下RNN和它的优缺点让我推导BP反向传播、随机梯度下降法权重更新公式卷积神经网络结构特点、各参数对模型结果影响、项目进展遇到的难题、推导BP神经网络参数更新方式、随机梯度下降法（SGD）优化函数存在的缺点以及拟牛顿法在优化函数使用上更有优势、修改Caffe开源框架、开源社区代码贡献量就跟我聊了很多行业发展趋势及问题，知道目前深度学习的一个趋势，也了解到最新行业发展动态，改进相机智能化程度，也聊到了美颜相机美颜效果以及小米相机人脸分类、年龄检测等等不足之处，了解到新兴行业大佬商汤科技和旷视科技（face++脸草）在研究的热门方向看到有deep learning相关的项目，就问了deep learning 相关问题：如何减少参数（权值共享、VGG的感受野、GoogLeNet的inception ），激活函数的选择（sigmoid-&gt;ReLu-&gt;LReLU-&gt;PReLU ），为什么之前没有深度网络出现（数据量不够+机器性能），由数据引申到数据不平衡怎么处理（10W正例，1W负例，牛客上有原题），后面问了下DNN原理，应用，瞎扯一通……你了解神经网络吗？我：了解一些，讲感知机，然后是BP网络。简单讲了一下原理。图像处理题：如何找相似图片。我说用感知哈希算法，计算汉明距离，他说这种方法精度不行；我说那就用SIFT算法吧，他说SIFT效果还可以，但计算有点繁重，有没有轻量级的方法？我想起来去年在美图秀秀实习时，曾经做过一种图像滤波算法，有一步是把像素点用K-means聚类。我就说先把图片灰度化，然后用K-means聚类，把聚类后的各个中心点作为一张图片的特征向量如果两张图片的特征向量相近则说明这两张图片相似。貌似我这个答案有点出乎他的意料，他意味深长地说了个“行吧~~~~”（个人觉得颜色直方图匹配是个他期待的常规回答）介绍卷积神经网络，和 DBN 有什么区别？Deep CNN, Deep RNN, RBM的典型应用与局限，看Hinton讲义和Paper去吧神经网络,plsi的推导验证码图片的去噪和提取字符有限状态自动机,然后要我画状态转移图. 聚类12用过哪些聚类算法，解释密度聚类算法。聚类算法中的距离度量有哪些？ 优化12345678梯度下降的优缺点；主要问最优化方面的知识，梯度下降法的原理以及各个变种（批量梯度下降，随机梯度下降法， mini 梯度下降法），以及这几个方法会不会有局部最优问题，牛顿法原理和适用场景，有什么缺点，如何改进（拟牛顿法）常用优化算法：1.梯度下降法：又有随机梯度下降和负梯度下降，2.牛顿法 主要是问了各自的优缺点，速度，能不能得到全局最优解，牛顿法的二次收敛等问你如果有若干个极小值点，如何避免陷入局部最优解。它们间的牛顿学习法、SGD如何训练，如何判断函数凸或非凸？线性回归的梯度下降和牛顿法求解公式的推导最速下降法和共轭梯度法 wolfe条件 最速下降法和共轭梯度法的收敛速度如何判断深刻理解常用的优化方法：梯度下降、牛顿法、各种随机搜索算法（基因、蚁群等等），深刻理解的意思是你要知道梯度下降是用平面来逼近局部，牛顿法是用曲面逼近局部等等。 推荐系统12345678910介绍SVD、SVD++推荐系统的冷启动问题如何解决深度学习在推荐系统上可能有怎样的发挥？推荐系统的算法中最近邻和矩阵分解各自适用场景白板写SVD/SVD++公式，SGD迭代更新p，q矩阵公式，SVD/SVD++优化方法对推荐算法的未来看法；用过什么算法？最好是在项目/实习的大数据场景里用过，比如推荐里用过 CF、LR，我面的推荐，问了各类协同过滤的好与坏。问了一个很有意思的问题，现实应用中的Top-N推荐问题和学术研究中的评分预测问题之间有什么不同。问我ItemCF的工程实现，面对大数据如何实现，又追问了有没有什么工程优化算法。这个问题我没答好，一开始我说了一个MapReduce模型，他问能不能更快一点，我就卡那了。。。最后面试官告诉我，不能只从算法角度分析，要从系统设计分析，利用内存来减小MapReduce的吞吐量。（当然也许从MapReduce那一刻开始我就输了也不一定）推荐系统的算法中最近邻和矩阵分解各自适用场景http://www.doc88.com/p-3961053026557.html PCA12那你对pca了解吗？我：了解啊，面试官：那讲一下pca是用来干嘛的？我：pca啊，可以用来分析主方向啊，降维啊，特征筛选啊，具体方法是用svd分解得到特征值矩阵和特征向量矩阵，然后根据不同的任务对选择特征值或向量进行计算。 EM1采用 EM 算法求解的模型有哪些，为什么不用牛顿法或梯度下降法？ NLP12345用过哪些 NLP 算法项目中用过哪些机器学习算法。海量的 item 算文本相似度的优化方法；解释 word2vec 的原理以及哈夫曼树的改进；word2vec的原理二面面试官主要跟我聊简历上的几个项目，他好像不能理解词向量的形式，反复解释了很多遍，问的问题都比较简单，有TF-IDF,余弦相似度，分词工具等等。然后我说我做过LDA，问我，Dirichlet Distribution的定义和性质，并问我，为什么它和multinomial distribution是共轭的，顺便问了我啥叫共轭分布。 关联分析：1项目中涉及到频繁模式挖掘，于是问了一下如何实现的？ 用的是 Apriori算法，描述他的原理过程，关键字眼：支持度，支持度计数，k项候选频繁项集，怎么从k项到k+1项等，连接剪枝过程。 hadoop12345678简单介绍 MapReduce 原理，有没有看过源码，说说 Map 阶段怎么实现的,MapReduce 实现统计出现次数最多的前 100 个访问 IP.MapReduce 实现统计不重复用户 ID,MapReduce 实现两个数据集求交集。HBase 行健怎么设计,spark 性能一般优化方法,spark streaming 和 storm 区别.给了一张笔试题， 10 道选择，一道大题。选择题是 java 基础知识，大题一个有三问：根据场景写出 Hive 建表语句； Hsql 从表中查询；用MapReduce写好友推荐，在一堆单词里面找出现次数最多的k个用分布式的方法做采样怎么保证采样结果完全符合预期？后面又问了Hadoop,Spark,storm下面的产品，原理，适用场景，写一个 Hadoop 版本的 wordcount。 HMM1234567891011121314151617181920212223242526272829实现 hmm 的状态转移代码；机器学习理论讲机器学习中常用的损失函数有哪些？交叉熵有什么好处？（凸优化问题）判别模型与生成模型的本质区别是什么分类模型和回归模型的区别，分类模型可以做回归分析吗？反过来可以吗？（我回答是分类不可以做回归，回归倒是可以做分类，不知道对不对）k折交叉验证 中k取值多少有什么关系 （我不知道，随便答，然后面试官后面问我知道bias和variance吗？估计是和这两个东西有关， 知乎上有个问题讨论了k值大小与bias和variance的关系）解释局部相关性特征选择的方法；在模型的训练迭代中，怎么评估效果；特征选择方法有哪些(能说出来10种以上加分)，之后和面试官仔细聊了一下特征选择的问题，我介绍了了解的几种基本的特征选择思路（错误率选择、基于熵的选择、类内类间距离的选择）；有没有接触过机器学习的前沿，深度学习看过paper没有？（并没有）如何用尽可能少的样本训练模型同时又保证模型的性能；你读哪些期刊会议的论文？你遇到的比较有意思的算法？生成模型，判别模型线性分类和非线性分类各有哪些模型比较各个模型的Loss function，设计一个结构存取稀疏矩阵 （面试官最后告诉我了一个极度压缩的存法，相同行或列存偏差，我当时没听懂，还不懂装懂，最后还是没记住）PageRank原理，怎么用模型来查找异常用户，我讲了一大堆我的理解，然后面试官一句你怎么不用规则把我噎到了……无监督和有监督算法的区别？经典算法推导(加分项)，原理，各个损失函数之间区别，使用场景，如何并行化，有哪些关键参数什么叫判别模型什么叫生成模型。先针对项目十分细致地询问了各种细节，然后就问我如何处理数据中的噪声点、数据清洗算法（正好自己做了一个算法）、如何选择特征等。校招TST内推，面过了2面，还是跟之前那个有点类似的游戏开发的安全部门，因为我也玩LOL，又问到怎么来判断玩家有没有作弊之类的问题，这次我小心翼翼的说用模型怎么做，用规则怎么做，感觉这次聊的都挺开心的。是否了解A/B Test以及A/B Test结果的置信度特征工程经验是否了解mutual infomation、chi-square、LR前后向、树模型等特征选择方式深刻理解各种算法对应采用的数据结构和对应的搜索方法。比如KNN对应的KD树、如何给图结构设计数据结构？如何将算法map-red化矩阵的各种变换，尤其是特征值相关的知识。分布式的矩阵向量乘的算法线性分类器与非线性分类器的区别及优劣；特征比数据量还大时，选择什么样的分类器？对于维度很高的特征，你是选择线性还是非线性分类器？对于维度极低的特征，你是选择线性还是非线性分类器？如何解决过拟合问题？L1和L2正则的区别，如何选择L1和L2正则？项目中的数据是否会归一化处理，哪个机器学习算法不需要归一化处理并行计算、压缩算法LDA http://www.doc88.com/p-1621945750499.html]]></content>
      <tags>
        <tag>笔面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matlab背景颜色修改]]></title>
    <url>%2F2018%2F09%2F01%2Fmatlab_%E8%83%8C%E6%99%AF%2F</url>
    <content type="text"><![CDATA[Matlab背景颜色修改 背景将修改内容添加到matlab的matlab.prf文件中，文件路径为在matlab中运行prefdir的结果,直接添加这些内容保存就好。 操作1， 在matlab命令行中运行prefdir， 获取matlab.prf文件所在路径 2， 打开matlab.prf所在路径， 找到matlab.prf文件， 作备份 3， 在新的matlab.prf中修改与color有关的属性 4，重启matlab，修改主题就完成了 主题选择黑色主题123456789101112131415161718192021Editor.VariableHighlighting.Color=C-6931898ColorsText=C-460558Colors_M_SystemCommands=C-448910Editorhighlight-lines=C-11974594Colors_M_Warnings=C-27648Colors_M_Strings=C-1647756Editor.NonlocalVariableHighlighting.TextColor=C-5471745Colors_HTML_HTMLLinks=C-16732805Colors_M_Comments=C-8355712Colors_M_Errors=C-65536Colors_M_UnterminatedStrings=C-5111808ColorsBackground=C-14211038Colors_M_Keywords=C-10036753Color_CmdWinWarnings=C-39936ColorsMLintAutoFixBackground=C-7973573Colors_M_Keywords=C-10036753Editorhighlight-lines=C-13553108Editorhighlight-caret-row-boolean-color=C-2167080ColorsUseSystem=Bfalse 暖色主题123456789101112131415161718Color_CmdWinErrors=C-1703936Color_CmdWinWarnings=C-39936ColorsBackground=C-198941ColorsMLintAutoFixBackground=C-1121868ColorsText=C-16304574ColorsUseMLintAutoFixBackground=BtrueColorsUseSystem=BfalseColors_HTML_HTMLLinks=C-2935166Colors_M_Comments=C-7167583Colors_M_Errors=C-65536Colors_M_Keywords=C-8021760Colors_M_Strings=C-13983336Colors_M_SystemCommands=C-3454186Colors_M_UnterminatedStrings=C-5111808Colors_M_Warnings=C-27648Editor.NonlocalVariableHighlighting.TextColor=C-32640Editor.VariableHighlighting.Color=C-7167583EditorRightTextLimitLineColor=C-3355444 darkmate123456789101112131415161718192021222324252627ColorsUseSystem=BfalseColorsUseMLintAutoFixBackground=BtrueEditor.VariableHighlighting.Automatic=BtrueEditor.NonlocalVariableHighlighting=BtrueEditorCodepadHighVisible=BtrueEditorCodeBlockDividers=BtrueEditorhighlight-caret-row-boolean=BtrueEditorRightTextLineVisible=BtrueEditorRightTextLimitLineWidth=I4 # slightly widerColorsText=C-1118482 # whiteColorsBackground=C-14474461 # carbonColors_M_Keywords=C-26368 # ambraColors_M_Comments=C-10920873 # asfaltoColors_M_Strings=C-6881536 # limeColors_M_UnterminatedStrings=C-202417 # yellowColors_M_SystemCommands=C-16725605 # algaColors_M_Errors=C-53398 # redColors_HTML_HTMLLinks=C-6385153 # violetColors_M_Warnings=C-26368 # ambraColorsMLintAutoFixBackground=C-11184811 # Editor.VariableHighlighting.Color=C-4495617 # purpleEditor.NonlocalVariableHighlighting.TextColor=C-16725760 # greenEditorhighlight-lines=C-15132391 # Editorhighlight-caret-row-boolean-color=C-16777216 # blackEditorRightTextLimitLineColor=C-13948117 # # XML/HTMLEditor.Language.XML.Color.pi-content=C-6425200 darksteel12345678910111213141516171819202122232425262728293031323334353637ColorsUseSystem=BfalseColorsUseMLintAutoFixBackground=BtrueEditor.VariableHighlighting.Automatic=BtrueEditor.NonlocalVariableHighlighting=BtrueEditorCodepadHighVisible=BtrueEditorCodeBlockDividers=BtrueEditorhighlight-caret-row-boolean=BtrueEditorRightTextLineVisible=BtrueEditorRightTextLimitLineWidth=I1ColorsText=C-1ColorsBackground=C-15066598Colors_M_Keywords=C-1208813Colors_M_Comments=C-14114579Colors_M_Strings=C-16724992Colors_M_UnterminatedStrings=C-4210944Colors_M_SystemCommands=C-7123493Colors_M_Errors=C-45747Colors_HTML_HTMLLinks=C-10592257Colors_M_Warnings=C-27648ColorsMLintAutoFixBackground=C-9223357Editor.VariableHighlighting.Color=C-11184786Editor.NonlocalVariableHighlighting.TextColor=C-16735351Editorhighlight-lines=C-14408662Editorhighlight-caret-row-boolean-color=C-12632257EditorRightTextLimitLineColor=C-5723992# TLCEditor.Language.TLC.Color.Colors_M_Keywords=C-16735351# C/C++Editor.Language.C.Color.preprocessor=C-16735351# VHDLEditor.Language.VHDL.Color.operator=C-16735351# VerilogEditor.Language.Verilog.Color.operator=C-16735351# XMLEditor.Language.XML.Color.operator=C-1710454Editor.Language.XML.Color.doctype=C-6578958Editor.Language.XML.Color.pi-content=C-9868801 monokai1234567891011121314151617181920212223242526ColorsUseSystem=BfalseColorsUseMLintAutoFixBackground=BtrueEditor.VariableHighlighting.Automatic=BtrueEditor.NonlocalVariableHighlighting=BtrueEditorCodepadHighVisible=BtrueEditorCodeBlockDividers=BtrueEditorhighlight-caret-row-boolean=BfalseEditorRightTextLineVisible=BtrueEditorRightTextLimitLineWidth=I1ColorsText=C-460560ColorsBackground=C-14211038Colors_M_Keywords=C-448910Colors_M_Comments=C-9080482Colors_M_Strings=C-1647756Colors_M_UnterminatedStrings=C-65536Colors_M_SystemCommands=C-16711936Colors_M_Errors=C-65536Colors_HTML_HTMLLinks=C-16711681Colors_M_Warnings=C-27648ColorsMLintAutoFixBackground=C-11974594Editor.VariableHighlighting.Color=C-10066330Editor.NonlocalVariableHighlighting.TextColor=C-16729641Editorhighlight-lines=C-13421773Editorhighlight-caret-row-boolean-color=C-10066330EditorRightTextLimitLineColor=C-3355444Color_CmdWinWarnings=C-26368 参考github效果：https://github.com/scottclowe/matlab-schemer/tree/master/schemes]]></content>
      <tags>
        <tag>Matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理推荐资料]]></title>
    <url>%2F2018%2F08%2F31%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%8E%A8%E8%8D%90%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[图像处理推荐资料 图像处理与计算机视觉相关的书籍 数学 我们所说的图像处理实际上就是数字图像处理，是把真实世界中的连续三维随机信号投影到传感器的二维平面上，采样并量化后得到二维矩阵。数字图像处理就是二维矩阵的处理，而从二维图像中恢复出三维场景就是计算机视觉的主要任务之一。这里面就涉及到了图像处理所涉及到的三个重要属性：连续性，二维矩阵，随机性。所对应的数学知识是高等数学（微积分），线性代数（矩阵论），概率论和随机过程。这三门课也是考研数学的三个组成部分，构成了图像处理和计算机视觉最基础的数学基础。如果想要更进一步，就要到网上搜搜林达华推荐的数学书目了。 信号处理 图像处理其实就是二维和三维信号处理，而处理的信号又有一定的随机性，因此经典信号处理和随机信号处理都是图像处理和计算机视觉中必备的理论基础。2.1经典信号处理信号与系统(第2版) Alan V.Oppenheim等著 刘树棠译 离散时间信号处理(第2版) A.V.奥本海姆等著 刘树棠译 数字信号处理:理论算法与实现 胡广书 (编者) 2.2随机信号处理现代信号处理 张贤达著 统计信号处理基础:估计与检测理论 Steven M.Kay等著 罗鹏飞等译 自适应滤波器原理(第4版) Simon Haykin著 郑宝玉等译 2.3 小波变换信号处理的小波导引:稀疏方法(原书第3版) tephane Malla著, 戴道清等译 2.4 信息论信息论基础(原书第2版) Thomas M.Cover等著 阮吉寿等译 模式识别Pattern Recognition and Machine Learning Bishop, Christopher M. Springer 模式识别(英文版)(第4版) 西奥多里德斯著 Pattern Classification (2nd Edition) Richard O. Duda等著 Statistical Pattern Recognition, 3rd Edition Andrew R. Webb等著 模式识别(第3版) 张学工著 图像处理与计算机视觉的书籍推荐图像处理，分析与机器视觉 第三版 Sonka等著 艾海舟等译 Image Processing, Analysis and Machine Vision ( 附：这本书是图像处理与计算机视觉里面比较全的一本书了，几乎涵盖了图像视觉领域的各个方面。中文版的个人感觉也还可以，值得一看。) 数字图像处理 第三版 冈萨雷斯等著 Digital Image Processing (附：数字图像处理永远的经典，现在已经出到了第三版，相当给力。我的导师曾经说过，这本书写的很优美，对写英文论文也很有帮助，建议购买英文版的。) 计算机视觉：理论与算法 Richard Szeliski著 Computer Vision: Theory and Algorithm (附：微软的Szeliski写的一本最新的计算机视觉著作。内容非常丰富，尤其包括了作者的研究兴趣，比如一般的书里面都没有的Image Stitching和 Image Matting等。这也从另一个侧面说明这本书的通用性不如Sonka的那本。不过作者开放了这本书的电子版，可以有选择性的阅读。 http://szeliski.org/Book/ Multiple View Geometry in Computer Vision 第二版Harley等著 引用达一万多次的经典书籍了。第二版到处都有电子版的。第一版曾出过中文版的，后来绝版了。网上也可以找到中英文版的电子版。) 计算机视觉：一种现代方法 DA Forsyth等著 Computer Vision: A Modern Approach MIT的经典教材。虽然已经过去十年了，还是值得一读。期待第二版 Machine vision: theory, algorithms, practicalities 第三版 Davies著 (附：为数不多的英国人写的书，偏向于工业应用。) 数字图像处理 第四版 Pratt著 Digital Image Processing (附：写作风格独树一帜，也是图像处理领域很不错的一本书。网上也可以找到非常清晰的电子版。)]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql基础]]></title>
    <url>%2F2018%2F08%2F31%2FMysql%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Mysql基础]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础]]></title>
    <url>%2F2018%2F08%2F31%2FLinux%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Linux基础 VIM 三个模式 一般指令模式（Command mode）：VIM 的默认模式，可以用于移动游标查看内容； 编辑模式（Insert mode）：按下 “i” 等按键之后进入，可以对文本进行编辑； 指令列模式（Bottom-line mode）：按下 “:” 按键之后进入，用于保存退出等操作。 在指令列模式下，有以下命令用于离开或者保存文件。 命令 作用 :w 写入磁盘 :w! 当文件为只读时，强制写入磁盘。到底能不能写入，与用户对该文件的权限有关 :q 离开 :q! 强制离开不保存 :wq 写入磁盘后离开 :wq! 强制写入磁盘后离开 磁盘的文件名Linux 中每个硬件都被当做一个文件，包括磁盘 分区1. MBRMBR 中，第一个扇区最重要，里面有主要开机记录（Master boot record, MBR）及分区表（partition table），其中主要开机记录占 446 bytes，分区表占 64 bytes。 2. GPT不同的磁盘有不同的扇区大小，GPT 第 1 个区块记录了主要开机记录（MBR） 文件属性用户分为三种：文件拥有者、群组以及其它人，对不同的用户有不同的文件权限。 使用 ls 查看一个文件时，会显示一个文件的信息，例如 drwxr-xr-x. 3 root root 17 May 6 00:14 .config，对这个信息的解释如下： drwxr-xr-x：文件类型以及权限，第 1 位为文件类型字段，后 9 位为文件权限字段 3：链接数 root：文件拥有者 root：所属群组 17：文件大小 May 6 00:14：文件最后被修改的时间 .config：文件名 常见的文件类型及其含义有： d：目录 -：文件 l：链接文件 9 位的文件权限字段中，每 3 个为一组，共 3 组，每一组分别代表对文件拥有者、所属群组以及其它人的文件权限。一组权限中的 3 位分别为 r、w、x 权限，表示可读、可写、可执行。 文件时间有以下三种： modification time (mtime)：文件的内容更新就会更新； status time (ctime)：文件的状态（权限、属性）更新就会更新； access time (atime)：读取文件时就会更新。 孤儿进程一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。 孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。 由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。 僵尸进程一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。 僵尸进程通过 ps 命令显示出来的状态为 Z（zombie）。 系统所能使用的进程号是有限的，如果产生大量僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。 要消灭系统中大量的僵尸进程，只需要将其父进程杀死，此时僵尸进程就会变成孤儿进程，从而被 init 所收养，这样 init 就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客 报错 Cannot read property 'replace' of null]]></title>
    <url>%2F2018%2F08%2F28%2Fhexo_error_replace%2F</url>
    <content type="text"><![CDATA[报错内容-情况报错内容如下123FATAL Cannot read property &apos;replace&apos; of nullTypeError: Cannot read property &apos;replace&apos; of null 如图： 报错情况，执行 hexo clean 清理本地缓存或者 hexo g 生成本地缓存时报此错误 解决方法打开 hexo配置文件，配置123456# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: https://www.aomanhao.toproot: AomanHao.github.iopermalink: :year/:month/:day/:title/permalink_defaults: root，url属性配置正确，填写自己对应的 参考文章]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理_图像插值]]></title>
    <url>%2F2018%2F08%2F28%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86_%E5%9B%BE%E5%83%8F%E6%8F%92%E5%80%BC%2F</url>
    <content type="text"><![CDATA[图像插值 比较常用的插值算法有这么几种：最邻近插值，双线性二次插值，三次插值，Lanczos插值等等 1，最邻近插值最邻近插值算法也叫做零阶插值算法，主要原理是让输出像素的像素值等于邻域内 离它距离最近的像素值。 这种放大图像的方法叫做最临近插值算法，这是一种最基本、最简单的图像缩放算法，效果也是最不好的，放大后的图像有很严重的马赛克，缩小后的图像有很严重的失真；效果不好的根源就是其简单的最临近插值方法引入了严重的图像失真。 2，双线性二次插值3、三次内插法内插值，外插值两张图像混合时通过内插与外插值方法可以实现图像亮度、对比度、饱和度、填色、锐化等常见的图像处理操作。在两张图像混合时最常见是线性插值方法，使用的混合权重公式如下： Out(x,y) = Src2(x,y) *\alpha + Src1(x,y)(1-\alpha)$\alpha$的范围是[0,1]之间 内插值方法：常见的值属于[0,1]之间。 外插值方法：可以用来生成跟内插值效果相反的图像。 比如内插值模糊图像，通过外插值可以去模糊，外插值可以调节饱和度，可以实现图像一些列的处理比如亮度、饱和度、对比度、锐化调整。 插值算法的类型：一般分为两类: 自适应和非自适应。自适应的方法可以根据插值的内容来改变（尖锐的边缘或者是平滑的纹理），非自适应的方法对所有的像素点都进行同样的处理。 非自适应算法包括: 最邻近方法, 双线性, 双三次, 样条, sinc, lanczos 和其他。由于其复杂度, 这些插值的时候使用从0 to 256 (or more) 邻近像素。 包含越多的邻近像素，他们越精确，但是花费的时间也越长。这些算法可以用来扭曲和缩放照片。 OriginalEnlarged 250%自适应算法包含许多专利，如: Qimage, PhotoZoom Pro, Genuine Fractals和其他。许多应用他们插值的不同版本 (on a pixel-by-pixel basis)当他们检测边缘时 —目标是最小化插值干扰。 最邻近插值最邻近算法在所有插值算法中时间最短，因为它只考虑一个像素点—离待插像素点最近的像素点。 双线性插值双线性插值考虑待插像素最近的 2x2 已知像素点。需要加权四个像素值来求得最终的像素值。这使得插值出来比最邻近插值平滑。 双三次插值 基于双线性插值，考虑最近的 4x4已知像素点 —总共16个像素点。由于离待插像素点的距离不同， 在计算中距离近的像素给出的权重较大。双三次产生的图像比前两次的尖锐，有理想的处理时间和输出质量。因此，在很多图像编辑程序中是标准算法 (包括 Adobe Photoshop), 打印机和相机插值。]]></content>
      <tags>
        <tag>图像插值</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谷歌浏览器加载静态文件错误，请修改DNS配置]]></title>
    <url>%2F2018%2F08%2F24%2FDNS_error%2F</url>
    <content type="text"><![CDATA[谷歌浏览器加载静态文件错误，请修改DNS配置 当我登陆CSDN/牛客网的时候，页面不能正常显示，只能显示纯文字，访问百度或者视频网站的时候是可以的报错提示静态文件加载出错，请检查当前网络情况是否正常，或者按照下面步骤修改电脑的DNS等等折腾了一晚上 修改DNS百度经验修改DNS 按照要求修改了dns，失败，仍然不能正常加载网页 修改hosts文件百度经验修改hosts文件 hosts属于系统文件，需要谨慎操作，需要很高的权限 打开hosts文件，发现最后一行是192.168.137.1 windows10.microdone.cn神秘代码有没有，寻找其出处，网友指出他是银联网银插件修改的代码解释链接 解决方法：卸载最近安装的 网银插件/控件（我没有就不用卸载了） 然后按照百度经验修改hosts文件，保存后，发现过一会打开又出现了192.168.137.1 windows10.microdone.cn这下怀疑中病毒了 使用360断网急救箱诊断确实是 hosts文件出现异常 修复在检测，依然有问题 使用360系统急救箱深度检测，删了一些文件（可能中毒）重启电脑，依然CSDN/牛客网的时候，页面不能正常显示 谷歌浏览器插件问题我鬼使神差的试试用微软自带的Eage浏览器登陆CSDN/牛客网，可以正常显示，惊了。我这一通操作，就是换个浏览器的题 仔细回想一下，之前安装的谷歌访问助手插件崩溃了，我就卸载了 1、卸载谷歌浏览器，重新安装 失败，不能正常显示网页CSDN/牛客网 2、安装谷歌访问助手插件 CSDN/牛客网可以正常显示了。 原因：怀疑是插件的上网代理搞鬼 解决方法：谷歌浏览器谷歌访问助手重新安装我的个人博客主页，欢迎访问我的CSDN主页，欢迎访问我的简书主页，欢迎访问我的GitHub主页，欢迎访问]]></content>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客yilia主题首页添加helper-live2d模型插件]]></title>
    <url>%2F2018%2F08%2F23%2Fhexo-helper-live2d%2F</url>
    <content type="text"><![CDATA[Hexo添加helper-live2d模型插件 插件效果插件的github地址插件作者提供了较为详细的安装步骤，我结合自己操作和图示，提供大家。 效果展示：红框内为2d模型，可以随鼠标移动而变化 安装模块:hexo博客根目录选择cmd命令窗口或者git bash 输入以下代码，安装插件 操作：1npm install --save hexo-helper-live2d 下载模型作者提供了三个下载模型的办法，我选择操作比较简单的一种npm 模块名 的方法 作者提供以下模型的模型包，模型包预览地址见下面的链接，选择你想用的模型，记住名字，选择对应的后缀模型包 作者各种模型包展示 12345678910111213141516171819202122live2d-widget-model-chitoselive2d-widget-model-epsilon2_1live2d-widget-model-gflive2d-widget-model-haru/01 (use npm install --save live2d-widget-model-haru)live2d-widget-model-haru/02 (use npm install --save live2d-widget-model-haru)live2d-widget-model-harutolive2d-widget-model-hibikilive2d-widget-model-hijikilive2d-widget-model-izumilive2d-widget-model-koharulive2d-widget-model-mikulive2d-widget-model-ni-jlive2d-widget-model-nicolive2d-widget-model-nietzschelive2d-widget-model-nipsilonlive2d-widget-model-nitolive2d-widget-model-shizukulive2d-widget-model-tororolive2d-widget-model-tsumikilive2d-widget-model-unitychanlive2d-widget-model-wankolive2d-widget-model-z16 选择好对应的模型，使用 npm install 模型的包名来安装，比如我选择的的是live2d-widget-model-koharu 模型包 操作：在hexo博客根目录选择cmd命令窗口或者git bash 输入以下代码 1npm install live2d-widget-model-koharu 执行安装就完事了 配置请向Hexo的 _config.yml 文件添加配置. 操作：打开个人Hexo博客文件根目录下的 _config.yml 文件，在最后添加一下代码示例: 12345678910111213141516live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-koharu display: position: right width: 150 height: 300 mobile: show: true 你需要配置的是use: live2d-widget-model-koharuuse后为你选择的安装包的全称 插件部署与应用就完成了，接下来就是部署hexo博客和个人主页]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>yilia</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理_Retinex图像增强]]></title>
    <url>%2F2018%2F08%2F17%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86_Retinex%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%2F</url>
    <content type="text"><![CDATA[图像处理_Retinex图像增强 单尺度SSR(Single Scale Retinex) 图像$S(x,y)$分解为两个不同的图像：反射图像$R(x,y)$,入射图像$L(x,y)$ 图像可以看做是入射图像和反射图像构成，入射光照射在反射物体上，通过反射物体的反射，形成反射光进入人眼。最后形成的图像$r(x,y)$可以如下公式表示 r(x,y)=logR(x,y)=log\frac{S(x,y)}{L(x,y)}R(x, y)表示了物体的反射性质，即图像内在属性，我们应该最大程度的保留；而L(x, y)表示入射光图像，决定了图像像素能达到的动态范围，我们应该尽量去除。 我们把照射图像假设估计为空间平滑图像，原始图像为S(x, y)，反射图像为R(x, y)，亮度图像为L(x, y)，使用公式 r(x,y)=logR(x,y)=log\frac{S(x,y)}{L(x,y)}或者 r(x,y)=logS(x,y)-log[F(x,y)⨂S(x,y)]其中r(x, y)是输出图像,卷积运算，$F(x, y)$是中心环绕函数 F(x,y)=\lambda*e^{-\frac{x^2+y^2}{c^2}}其中C是高斯环绕尺度，λ是一个尺度，满足$∫∫F(x,y)dxdy=1$ SSR算法中的卷积是对入射图像的计算，其物理意义是通过计算像素点与周围区域在加权平均的作用下，估计图像中照度的变化，并将L(x,y)去除，只保留S(x,y)属性。 多尺度MSR(Multi-Scale Retinex) MSR是在SSR基础上发展来的，优点是可以同时保持图像高保真度与对图像的动态范围进行压缩的同时，MSR也可实现色彩增强、颜色恒常性、局部动态范围压缩、全局动态范围压缩，也可以用于X光图像增强。 r(x,y)=∑_k^Kw_klogS(x,y)-log[F_k(x,y)*S(x,y)]K是高斯中心环绕函数的个数。当K=1时，MSR退化为SSR,K取值通常为3 w1=w2=w3=\frac13 缺点:边缘锐化不足，阴影边界突兀，部分颜色发生扭曲，纹理不清晰，高光区域细节没有得到明显改善，对高光区域敏感度小 带颜色恢复的MSR方法MSRCR(Multi-Scale Retinex with Color Restoration)SSR和MSR普遍都存在明显的偏色问题 MSRCR在MSR的基础上，加入了色彩恢复因子C来调节由于图像局部区域对比度增强而导致颜色失真的缺陷。 改进公式： R_{MSRCR_i}(x,y)=C_i(x,y)R_{MSR_i}(x,y)其中 C_i(x,y)=f[I_i^{'}(x,y)]=f[\frac{I_i(x,y)}{∑_{j=1}^{N}I_j(x,y)}]其中 f[I_i^{'}(x,y)]=βlog[αI_i^{'}(x,y)]=β{log[αI_i^{'}i(x,y)]-log[∑_{j=1}^NI_j(x,y)]}参数说明12345Ii(x, y)表示第i个通道的图像Ci表示第i个通道的彩色回复因子，用来调节3个通道颜色的比例；f(·)表示颜色空间的映射函数；β是增益常数；α是受控制的非线性强度； MSRCR算法利用彩色恢复因子C，调节原始图像中3个颜色通道之间的比例关系，从而把相对较暗区域的信息凸显出来，达到了消除图像色彩失真的缺陷。处理后的图像局部对比度提高，亮度与真实场景相似，在人们视觉感知下，图像显得更加逼真。 参考文章]]></content>
      <tags>
        <tag>Opencv</tag>
        <tag>图像处理</tag>
        <tag>图像增强</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法_动态规划]]></title>
    <url>%2F2018%2F08%2F16%2F%E7%AE%97%E6%B3%95_%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[算法_动态规划 求解最优化问题 背包问题1123456789101112131415161718192021222324252627282930313233343536373839404142434445Problem Description: 有 n 个重量和价值分别为Wi,Vi的物品，现从这些物品中挑选出总量不超过 W 的物品，求所有方案中价值总和的最大值。Input:输入包含多组测试用例，每一例的开头为两位整数 n、W（1&lt;=n&lt;=10000,1&lt;=W&lt;=1000），接下来有 n 行，每一行有两位整数 Wi、Vi（1&lt;=Wi&lt;=10000,1&lt;=Vi&lt;=100）。Output:输出为一行，即所有方案中价值总和的最大值。Sample Input:3 41 22 53 7Sample Output:9Java代码：import java.util.Arrays;import java.util.Scanner; public class Main &#123; static Scanner scan = new Scanner(System.in); static int[] v = new int[10001]; static int[] w = new int[10001]; static int[] dp = new int[10001]; public static void main(String[] args) &#123; // TODO Auto-generated method stub while(scan.hasNext())&#123; int n = scan.nextInt(); int W = scan.nextInt(); v = new int[n+1]; w = new int[n+1]; for(int i=1;i&lt;=n;i++)&#123; w[i] = scan.nextInt(); v[i] = scan.nextInt(); &#125; for(int i = 1; i &lt;= n; i++) for(int j = W; j &gt;= 0; j--)&#123; //每次更新容量为j，所能放下最大价值的物品 if(j &gt;= w[i])&#123; //j一定要大于w[i],要不最大容量为j的背包放不下第i件物品 dp[j] = Math.max(dp[j], dp[j-w[i]] + v[i]); //dp[j] 表示最大容量为j的背包所装下物品最大的价值， 这里求的是第i件物品放和不放的价值的最大的价值 &#125; &#125; System.out.println(dp[W]); &#125; &#125;&#125; 背包问题21234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * @author miracle *切割钢条问题： *长度：1 2 3 4 5 6 7 8 9 10 *价格：1 5 8 9 10 17 17 20 24 30 *问长度为n的钢条的最多卖多少钱 */public class Solution &#123; int[] prices = &#123;0, 1, 5, 8, 9, 10, 17, 17, 20, 24, 30&#125;; int[] dp = new int[prices.length]; public int solve(int[] prices, int n)&#123; if(n == 0) return 0; int max = Integer.MIN_VALUE; for(int i = 1; i &lt;= n; i++)&#123; max = Math.max(max, prices[i] + solve(prices, n - i)); &#125; return max; &#125; public int solveWithMemoUpToBottom(int[] prices, int n)&#123; if(n == 0 || dp[n] &gt; 0) return dp[n]; int max = Integer.MIN_VALUE; for(int i = 1; i &lt;= n; i++)&#123; max = Math.max(max, prices[i] + solve(prices, n - i)); &#125; dp[n] = max; return max; &#125; public int solveBottomToUp(int[] prices, int n)&#123; int[] dp = new int[prices.length]; for(int i = 1; i &lt;= n; i++)&#123; int max = Integer.MIN_VALUE; for(int j = 1; j &lt;= i; j++)&#123; max = Math.max(max, prices[j] + prices[i - j]); &#125; dp[i] = max; &#125; return dp[n]; &#125; public static void main(String args[])&#123; Solution s = new Solution();// System.out.println(s.solve(s.prices, 1));// System.out.println(s.solve(s.prices, 2));// System.out.println(s.solve(s.prices, 3));// System.out.println(s.solve(s.prices, 4));// System.out.println(s.solve(s.prices, 5)); System.out.println(s.solveBottomToUp(s.prices, 1)); System.out.println(s.solveBottomToUp(s.prices, 2)); System.out.println(s.solveBottomToUp(s.prices, 3)); System.out.println(s.solveBottomToUp(s.prices, 4)); System.out.println(s.solveBottomToUp(s.prices, 5)); &#125;&#125; 递归 运算量比较大 O(2^N) 递归，dp，分治的区别递归只是一种编程的思想，只要自己调用自己，就算是递归。 分治，有三步，先分，再各自处理，最后整合。这里也涉及了子问题，这里的子问题是不重叠的，每一个只被处理一次，因此不需要memo。 dp，可以使用递归，而且dp的子问题是重复的。]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-梯度消失爆炸]]></title>
    <url>%2F2018%2F08%2F16%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E7%88%86%E7%82%B8%2F</url>
    <content type="text"><![CDATA[机器学习-梯度消失爆炸 梯度消失本层的神经元的激活等于上一层神经元对应的权值进行加权和运算，最后通过一个非线性函数（激活函数）如ReLu，sigmoid等函数，最后得到的结果就是本层神经元的输出，逐层逐神经元通过该操作向前传播，最终得到输出层的结果。 梯度消失的影响：1) 浅层基本不学习，后面几层一直在学习，失去深度的意义。2) 无法收敛。 梯度消失的现象呢？因为通常神经网络所用的激活函数是sigmoid函数这个函数有个特点: 就是能将负无穷到正无穷的数映射到0和1之间，并且对这个函数求导的结果是f′(x)=f(x)(1−f(x))。因此两个0到1之间的数相乘，得到的结果就会变得很小了。神经网络的反向传播是逐层对函数偏导相乘，因此当神经网络层数非常深的时候最后一层产生的偏差就因为乘了很多的小于1的数而越来越小，最终就会变为0，从而导致层数比较浅的权重没有更新 一是在深层网络中，网络层数过多二是采用了不合适的损失函数，比如sigmoid 梯度爆炸就是由于初始化权值过大，前面层会比后面层变化的更快，就会导致权值越来越大，梯度爆炸的现象就发生了。 解决用ReLU激活函数来替代sigmoid函数。 区别：（1）sigmoid函数值在[0,1],ReLU函数值在[0,+无穷]，所以sigmoid函数可以描述概率，ReLU适合用来描述实数；（2）sigmoid函数的梯度随着x的增大或减小和消失，而ReLU不会。 早期多层神经网络如果用sigmoid函数或者hyperbolic tangent作为激活函数，如果不进行pre-training的话，会因为gradient vanishing problem而无法收敛。 而预训练的用处：规则化，防止过拟合；压缩数据，去除冗余；强化特征，减小误差；加快收敛速度。而采用ReLu则不需要进行pre-training。]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指Offer算法Code_Java_C++(0820更新)]]></title>
    <url>%2F2018%2F08%2F16%2F%E5%89%91%E6%8C%87Offer%E7%AE%97%E6%B3%95Code_Java_C%2B%2B%2F</url>
    <content type="text"><![CDATA[剑指Offer算法Code_Java_C++ 1在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 思路：从左下角元素往上查找，右边元素是比这个元素大，上边是的元素比这个元素小。Java代码1234567891011121314151617public class Solution &#123; public boolean Find(int target, int [][] array) &#123; //填写 int row = array.length; int col = array[0].length; int i=row-1,j=0; while(i&gt;=0&amp;&amp;j&lt;=col-1)&#123; if(target&lt;array[i][j])&#123; i--; &#125;else if(target&gt;array[i][j])&#123; j++; &#125;else return true; &#125; return false; &#125;&#125; C++代码123456789101112131415161718class Solution &#123;public: bool Find(int target, vector&lt;vector&lt;int&gt; &gt; array) &#123; // array是二维数组，这里没做判空操作 int rows = array.size(); int cols = array[0].size(); int i=rows-1,j=0;//左下角元素坐标 while(i&gt;=0 &amp;&amp; j&lt;cols)&#123;//使其不超出数组范围 if(target&lt;array[i][j]) i--;//查找的元素较少，往上找 else if(target&gt;array[i][j]) j++;//查找元素较大，往右找 else return true;//找到 &#125; return false; &#125;&#125;; 2请实现一个函数，将一个字符串中的每个空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。Java代码：1234567public class Solution &#123; public String replaceSpace(StringBuffer str) &#123; String str1 = str.toString(); String str2 = str1.replace(&quot; &quot;,&quot;%20&quot;); return str2; &#125;&#125; Java代码：1234567891011121314151617181920212223public class Solution &#123; public String replaceSpace(StringBuffer str) &#123; int spacenum = 0;//spacenum为计算空格数 for(int i=0;i&lt;str.length();i++)&#123; if(str.charAt(i)==&apos; &apos;) spacenum++; &#125; int indexold = str.length()-1; //indexold为为替换前的str下标 int newlength = str.length() + spacenum*2;//计算空格转换成%20之后的str长度 int indexnew = newlength-1;//indexold为为把空格替换为%20后的str下标 str.setLength(newlength);//使str的长度扩大到转换成%20之后的长度,防止下标越界 for(;indexold&gt;=0 &amp;&amp; indexold&lt;newlength;--indexold)&#123; if(str.charAt(indexold) == &apos; &apos;)&#123; // str.setCharAt(indexnew--, &apos;0&apos;); str.setCharAt(indexnew--, &apos;2&apos;); str.setCharAt(indexnew--, &apos;%&apos;); &#125;else&#123; str.setCharAt(indexnew--, str.charAt(indexold)); &#125; &#125; return str.toString(); &#125;&#125; c++代码123456789101112131415161718192021class Solution &#123;public: void replaceSpace(char *str,int length) &#123; int count = 0; for (int i=0;i&lt;length;i++)&#123; if (str[i]==&apos; &apos;)&#123; count++; &#125; for (int i=length-1;i&gt;=0;i--)&#123; if (str[i]==&apos; &apos;)&#123; count--; str[i+2*count]=&apos;%&apos;; str[i+2*count+1]=&apos;2&apos;; str[i+2*count+2]=&apos;0&apos;; &#125;else&#123; str[i+2*count]=str[i]; &#125; &#125; &#125; &#125;&#125;; 3输入一个链表，按链表值从尾到头的顺序返回一个ArrayList。 Java代码：1234567891011java 递归超简洁版本public class Solution &#123; ArrayList&lt;Integer&gt; arrayList=new ArrayList&lt;Integer&gt;(); public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; if(listNode!=null)&#123; this.printListFromTailToHead(listNode.next); arrayList.add(listNode.val); &#125; return arrayList; &#125;&#125; C++代码1234567891011121314class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(ListNode* head) &#123; vector&lt;int&gt; value; if (head != NULL)&#123; value.insert(value.begin(),head-&gt;val); while (head-&gt;next !=NULL)&#123; value.insert(value.begin(),head-&gt;next-&gt;val); head = head -&gt;next; &#125; &#125; return value; &#125;&#125;; 4输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。 递归思想，每次将左右两颗子树当成新的子树进行处理，中序的左右子树索引很好找，前序的开始结束索引通过计算中序中左右子树的大小来计算，然后递归求解，直到startPre&gt;endPre||startIn&gt;endIn说明子树整理完到。方法每次返回左子树活右子树的根节点1234567 1 / \ 2 3 /\ /4 5 6 \ / 7 8 Java代码：12345678910111213141516171819202122public class Solution &#123; public TreeNode reConstructBinaryTree(int [] pre,int [] in) &#123; TreeNode root=reConstructBinaryTree(pre,0,pre.length-1,in,0,in.length-1); return root; &#125; //前序遍历&#123;1,2,4,7,3,5,6,8&#125;和中序遍历序列&#123;4,7,2,1,5,3,8,6&#125; private TreeNode reConstructBinaryTree(int [] pre,int startPre,int endPre,int [] in,int startIn,int endIn) &#123; if(startPre&gt;endPre||startIn&gt;endIn) return null; TreeNode root=new TreeNode(pre[startPre]); for(int i=startIn;i&lt;=endIn;i++) if(in[i]==pre[startPre])&#123; root.left=reConstructBinaryTree(pre,startPre+1,startPre+i-startIn,in,startIn,i-1); root.right=reConstructBinaryTree(pre,i-startIn+startPre+1,endPre,in,i+1,endIn); break; &#125; return root; &#125;&#125; 5大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。n&lt;=39 Java代码123456789101112131415public class Solution &#123; public int Fibonacci(int n) &#123; if(n&lt;1)&#123; return n; &#125; int[] ints = new int[n+1]; ints[0] = 0; ints[1] = 1; for(int i = 2; i &lt;= n; i++ )&#123; ints[i] = ints[i-1] + ints[i-2]; &#125; return ints[n]; &#125;&#125; C++代码：1234567891011121314151617class Solution &#123;public: int Fibonacci(int n) &#123; int pre = 0; int last=1; int result =0; if(n&lt;=1)&#123; return n; &#125; for(int i=2; i&lt;=n; i++)&#123; result=pre+last; pre=last; last=result; &#125; return result; &#125;&#125;; 6一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法（先后次序不同算不同的结果）。 思路：，f(1) = 1, f(2) = 2, f(3) = 3, f(4) = 5， 可以总结出f(n) = f(n-1) + f(n-2)的规律Java代码：123456789101112131415public class Solution &#123; public int JumpFloor(int target) &#123; int[] ints= new int[target+1]; if(target &lt;=0 )&#123; return 0; &#125;else if(target==1 || target==2)&#123; return target; &#125; ints[0] = 1;ints[1] = 2; for(int i =2; i&lt;=target; i++)&#123; ints[i] = ints[i-1] + ints[i-2]; &#125; return ints[target-1]; &#125;&#125; C++代码1234567891011121314151617class Solution &#123;public: int jumpFloor(int number) &#123; int first = 1;int second = 2; int result = 0; if (number&lt;=0)&#123; return 0; &#125;else if (number==1||number==2)&#123; return number; &#125; for (int i=3; i&lt;=number; i++)&#123; result = first + second; first = second; second = result; &#125; return result; &#125;&#125;; 7输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。 思路：1自身左移动，然后跟原数字做与比较，如果对应相同输出为1，否则为0。Java代码：12345678910111213public class Solution &#123; public int NumberOf1(int n) &#123; int count = 0; int flag = 1; while(flag != 0)&#123; if((n &amp; flag) !=0 )&#123; count++; &#125; flag = flag &lt;&lt; 1; &#125; return count; &#125;&#125; C++代码：123456789101112131415class Solution &#123;public: int NumberOf1(int n) &#123; int count = 0; int flag = 1; while(flag != 0)&#123; if((n &amp; flag)!=0)&#123; count++; &#125; flag = flag &lt;&lt; 1; &#125; return count ; &#125; &#125;; 8输入一个链表，反转链表后，输出新链表的表头: 整体反转链表，但是要把断开的节点保存起来，才能继续反转链表Java代码：12345678910111213141516171819202122232425262728293031public class Solution &#123; public ListNode ReverseList(ListNode head) &#123; if(head==null) return null; //head为当前节点，如果当前节点为空的话，那就什么也不做，直接返回null； ListNode pre = null; ListNode next = null; //当前节点是head，pre为当前节点的前一节点，next为当前节点的下一节点 //需要pre和next的目的是让当前节点从pre-&gt;head-&gt;next1-&gt;next2变成pre&lt;-head next1-&gt;next2 //即pre让节点可以反转所指方向，但反转之后如果不用next节点保存next1节点的话，此单链表就此断开了 //所以需要用到pre和next两个节点 //1-&gt;2-&gt;3-&gt;4-&gt;5 //1&lt;-2&lt;-3 4-&gt;5 while(head!=null)&#123; //做循环，如果当前节点不为空的话，始终执行此循环，此循环的目的就是让当前节点从指向next到指向pre //如此就可以做到反转链表的效果 //先用next保存head的下一个节点的信息，保证单链表不会因为失去head节点的原next节点而就此断裂 next = head.next; //保存完next，就可以让head从指向next变成指向pre了，代码如下 head.next = pre; //head指向pre后，就继续依次反转下一个节点 //让pre，head，next依次向后移动一个节点，继续下一次的指针反转 pre = head; head = next; &#125; //如果head为null的时候，pre就为最后一个节点了，但是链表已经反转完毕，pre就是反转后链表的第一个节点 //直接输出pre就是我们想要得到的反转后的链表 return pre; &#125;&#125; C++代码：123456789101112131415161718192021222324class Solution &#123;public: ListNode* ReverseList(ListNode* pHead) &#123; if(pHead == NULL)&#123; return NULL; &#125; ListNode* pNode = pHead;//当前指针 ListNode* pPre = NULL;//链表的前一个指针 ListNode* pNewHead = NULL; while(pNode != NULL)&#123; ListNode* pNext = pNode-&gt;next; if(pNext == NULL)&#123; //尾节点 pNewHead = pNode; &#125; pNode-&gt;next = pPre; pPre = pNode; pNode = pNext; &#125; return pNewHead; &#125;&#125;; 9输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 两两数值对比,merge可以合并两个事物，链表也行，考点在取两个链表比较小的头节点 Java代码：1234567891011121314151617public class Solution &#123; public ListNode Merge(ListNode list1,ListNode list2) &#123; if(list1 == null)&#123; return list2; &#125; if(list2 == null)&#123; return list1; &#125; if(list1.val &lt;= list2.val)&#123; list1.next = Merge(list1.next,list2); return list1; &#125;else&#123; list2.next = Merge(list1,list2.next); return list2; &#125; &#125;&#125; C++代码：12345678910111213141516171819202122class Solution &#123;public: ListNode* Merge(ListNode* pHead1, ListNode* pHead2) &#123; if(pHead1 == NULL)&#123; return pHead2; &#125; if(pHead2 == NULL)&#123; return pHead1; &#125; ListNode* NewHead = NULL; if(pHead1-&gt;val &lt;= pHead2-&gt;val)&#123; NewHead = pHead1; NewHead-&gt;next = Merge(pHead1-&gt;next,pHead2); &#125;else&#123; NewHead = pHead2; NewHead-&gt;next = Merge(pHead1,pHead2-&gt;next); &#125; return NewHead; &#125;&#125;; 10 从上往下打印出二叉树的每个节点，同层节点从左至右打印。 Java代码：123456789101112131415161718192021222324/**思路是用arraylist模拟一个队列来存储相应的TreeNode*/public class Solution &#123; public ArrayList&lt;Integer&gt; PrintFromTopToBottom(TreeNode root) &#123; ArrayList&lt;Integer&gt; arr = new ArrayList&lt;&gt;(); ArrayList&lt;TreeNode&gt; TN = new ArrayList&lt;&gt;(); if(root==null)&#123; return arr; &#125; TN.add(root); while(TN.size()!=0)&#123; TreeNode temp = TN.remove(0); if(temp.left!= null)&#123; TN.add(temp.left); &#125; if(temp.right!= null)&#123; TN.add(temp.right); &#125; arr.add(temp.val); &#125; return arr; &#125;&#125; C++代码：12345678```### 111个整型数组里除了两个数字之外，其他的数字都出现了偶数次。请写程序找出这两个只出现一次的数字。&gt;思路：两个相同数字异或=0，一个数和0异或还是它本身。&lt;br&gt;我们首先还是先异或，剩下的数字肯定是A、B异或的结果，这个结果的二进制中的1，表现的是A和B的不同的位。我们就取第一个1所在的位数，假设是第3位，接着把原数组分成两组，分组标准是第3位是否为1。如此，相同的数肯定在一个组，因为相同数字所有位都相同，而不同的数，肯定不在一组。然后把这两个组按照最开始的思路，依次异或，剩余的两个结果就是这两个只出现一次的数字。Java代码： public class Solution { public void FindNumsAppearOnce(int[] array, int[] num1, int[] num2) { int length = array.length; if(length == 2){ num1[0] = array[0]; num2[0] = array[1]; return; } int bitResult = 0; for(int i = 0; i &lt; length; ++i){ bitResult ^= array[i]; } int index = findFirst1(bitResult); for(int i = 0; i &lt; length; ++i){ if(isBit1(array[i], index)){ num1[0] ^= array[i]; }else{ num2[0] ^= array[i]; } } } private int findFirst1(int bitResult){ int index = 0; while(((bitResult &amp; 1) == 0) &amp;&amp; index &lt; 32){ bitResult &gt;&gt;= 1; index++; } return index; } private boolean isBit1(int target, int index){ return ((target &gt;&gt; index) &amp; 1) == 1; } }12C++代码： 链接：https://www.nowcoder.com/questionTerminal/e02fdb54d7524710a7d664d082bb7811来源：牛客网 class Solution {public: void FindNumsAppearOnce(vector data,int num1,int num2) { if(data.size()&gt;1; ++index; } num1=num2=0; for(int i=0;i&gt;index; return (num&amp;1); }};1234567 ^=:逐位异或 ### 12最小的k个数输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。Java代码：(快排/最小堆) 链接：https://www.nowcoder.com/questionTerminal/6a296eb82cf844ca8539b57c23e6e9bf来源：牛客网 / 基于堆排序算法，构建最大堆。时间复杂度为O(nlogk)如果用快速排序，时间复杂度为O(nlogn)； 如果用冒泡排序，时间复杂度为O(nk) /import java.util.ArrayList;public class Solution { public ArrayList GetLeastNumbers_Solution(int [] input, int k) { ArrayList list=new ArrayList(); //检查输入的特殊情况 if(input==null || input.length&lt;=0 || input.length=0; len—){ adjustMaxHeapSort(input,len,k-1); } //从第k个元素开始分别与最大堆的最大值做比较，如果比最大值小，则替换并调整堆。 //最终堆里的就是最小的K个数。 int tmp; for(int i=k; i&lt;input.length; i++){ if(input[i]&lt;input[0]){ tmp=input[0]; input[0]=input[i]; input[i]=tmp; adjustMaxHeapSort(input,0,k-1); } } for(int j=0; j&lt;k; j++){ list.add(input[j]); } return list; } public void adjustMaxHeapSort(int[] input, int pos, int length){ int temp; int child; for(temp=input[pos]; 2*pos+1&lt;=length; pos=child){ child=2*pos+1; if(child&lt;length &amp;&amp; input[child]&lt;input[child+1]){ child++; } if(input[child]&gt;temp){ input[pos]=input[child]; }else{ break; } } input[pos]=temp; } }1### 二叉树的景象 题目描述操作给定的二叉树，将其变换为源二叉树的镜像。输入描述:二叉树的镜像定义：源二叉树 8 / \ 6 10 / \ / \ 5 7 9 11 镜像二叉树 8 / \ 10 6 / \ / \ 11 9 7 51C++代码： 12345### 13Java代码： public class Solution { public void Mirror(TreeNode root) { if(root == null){ return; } TreeNode temp; if(root!=null){ temp = root.left; root.left = root.right; root.right = temp; } if(root.left!=null){ Mirror(root.left); } if(root.right!=null){ Mirror(root.right); } } }12C++代码： 12345Java代码： 1C++代码： 1234Java代码： 12C++代码： 12345Java代码： 12C++代码： 12345Java代码： 1C++代码： ```]]></content>
      <tags>
        <tag>Java</tag>
        <tag>C++</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面经-概率论算法]]></title>
    <url>%2F2018%2F08%2F16%2F%E9%9D%A2%E7%BB%8F-%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Q1100人坐飞机，第一个乘客在座位中随便选一个坐下，第100人正确坐到自己坐位的概率是？ Q2给定三个随机变量X,Y,Z，已知X和Y的相关系数(correlation)为0.8，X和Z的相关系数为0.8。问Y和Z的相关系数最大／最小为多少？ 答： |1|0.8|0.8||0.8|1|a||0.8|a|1| Q3几何分布:一个国家重男轻女，只要生了女孩就继续生，直到生出男孩为止，问这个国家的男女比例？ 答： 1比1 因为只要生了女孩就继续生，直到生出男孩为止，影响的是家庭男女孩的比例，国家总人数比例还是1比1 Q4有50个红球，50个蓝球，如何放入两个盒子中使得拿到红球的概率最大 如果要拿两个红的，一个盒子放一个红球，一个盒子放49红，50蓝，取两个红球概率49/99 Q5一根木棍随机折成三段，能组成三角形的概率多大？ 答：任意两边之和大于第三边p=[(1/8)a^2]/[(1/2)a^2]=1/4=0.25 Q6Q7Q8Q9Q10]]></content>
      <tags>
        <tag>笔面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode题解]]></title>
    <url>%2F2018%2F08%2F16%2Fleetcode_sum%2F</url>
    <content type="text"><![CDATA[三数之和给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？找出所有满足条件且不重复的三元组。 注意：答案中不可以包含重复的三元组。 例如, 给定数组 nums = [-1, 0, 1, 2, -1, -4]， 满足要求的三元组集合为：[ [-1, 0, 1], [-1, -1, 2]] 1 Two Sum5 array、set sort、Two Pointers 8 String to Integer (atoi) 5 string Math15 3Sum 5 array Two Pointers20 Valid Parentheses 5 string Stack21 Merge Two Sorted Lists 5 linked list sort、Two Pointers、merge28 Implement strStr() 5 string Two Pointers、KMP、rolling hash50 Pow(x, n) 5 Binary Search、Math56 Merge Intervals 5 array、linked list、red-black tree sort、merge57 Insert Interval 5 array sort65 Valid Number 5 string Math70 Climbing Stairs 5 DP73 Set Matrix Zeroes 5 array88 Merge Sorted Array 5 array Two Pointers、merge98 Validate Binary Search Tree 5 tree DFS125 Valid Palindrome 5 string Two Pointers127 Word Ladder 5 graph BFS、path2 Add Two Numbers 4 linked list Two Pointers、Math12 Integer to Roman 4 Math13 Roman to Integer 4 Math22 Generate Parentheses 4 string DFS23 Merge k Sorted Lists 4 linked list、heap sort、Two Pointersmerge24 Swap Nodes in Pairs 4 linked list27 Remove Element 4 array Two Pointers46 Permutations 4 array permutation49 Anagrams 4 string、hashtable67 Add Binary 4 string Two Pointers、Math69 Sqrt(x) 4 Binary Search77 Combinations 4 combination78 Subsets 4 array Recursion、combination79 Word Search 4 array DFS91 Decode Ways 4 string Recursion、DP102 Binary Tree Level Order Traversal 4 tree BFS129 Sum Root to Leaf Numbers 4 tree DFS131 Palindrome Partitioning 4 string DFS4 Median of Two Sorted Arrays 3 array Binary Search7 Reverse Integer 3 Math10 Regular Expression Matching 3 string Recursion、DP17 Letter Combinations of a Phone Number 3 string DFS19 Remove Nth Node From End of List 3 linked list Two Pointers26 Remove Duplicates from Sorted Array 3 array Two Pointers29 Divide Two Integers 3 Binary Search33 Search in Rotated Sorted Array 3 array Binary Search34 Search for a Range 3 array Binary Search39 Combination Sum 3 array combination43 Multiply Strings 3 string Two Pointers、Math44 Wildcard Matching 3 string Recursion、DP、greedy51 N-Queens 3 array DFS52 N-Queens II 3 array DFS53 Maximum Subarray 3 array DP62 Unique Paths 3 array DP63 Unique Paths II 3 array DP64 Minimum Path Sum 3 array DP72 Edit Distance 3 string DP74 Search a 2D Matrix 3 array Binary Search81 Search in Rotated Sorted Array II 3 array Binary Search82 Remove Duplicates from Sorted List II 3 linked list Recursion、Two Pointers83 Remove Duplicates from Sorted List 3 linked list86 Partition List 3 linked list Two Pointers93 Restore IP Addresses 3 string DFS94 Binary Tree Inorder Traversal 3 tree、hashtable Recursion、morris、Stack103 Binary Tree Zigzag Level Order Traversal 3 queue、tree BFS、Stack105 Construct Binary Tree from Preorder and Inorder Tr 3 array、tree DFS106 Construct Binary Tree from Inorder and Postorder T 3 array、tree DFS108 Convert Sorted Array to Binary Search Tree 3 tree DFS109 Convert Sorted List to Binary Search Tree 3 linked list Recursion、Two Pointers112 Path Sum 3 tree DFS114 Flatten Binary Tree to Linked List 3 tree Recursion、Stack116 Populating Next Right Pointers in Each Node 3 tree DFS128 Longest Consecutive Sequence 3 array130 Surrounded Regions 3 array BFS、DFS132 Palindrome Partitioning II 3 string DP3 Longest Substring Without Repeating Characters 2 string、hashtable Two Pointers5 Longest Palindromic Substring 2 string9 Palindrome Number 2 Math11 Container With Most Water 2 array Two Pointers18 4Sum 2 array25 Reverse Nodes in k-Group 2 linked list Recursion、Two Pointers31 Next Permutation 2 array permutation35 Search Insert Position 2 array36 Valid Sudoku 2 array37 Sudoku Solver 2 array DFS38 Count and Say 2 string Two Pointers40 Combination Sum II 2 array combination41 First Missing Positive 2 array sort42 Trapping Rain Water 2 array Two Pointers、Stack45 Jump Game II 2 array47 Permutations II 2 array permutation48 Rotate Image 2 array54 Spiral Matrix 2 array55 Jump Game 2 array59 Spiral Matrix II 2 array61 Rotate List 2 linked list Two Pointers66 Plus One 2 array Math68 Text Justification 2 string75 Sort Colors 2 array sort、Two Pointers76 Minimum Window Substring 2 string Two Pointers80 Remove Duplicates from Sorted Array II 2 array Two Pointers84 Largest Rectangle in Histogram 2 array Stack87 Scramble String 2 string Recursion、DP89 Gray Code 2 combination90 Subsets II 2 array Recursion、combination92 Reverse Linked List II 2 linked list Two Pointers97 Interleaving String 2 string Recursion、DP99 Recover Binary Search Tree 2 tree DFS101 Symmetric Tree 2 tree DFS110 Balanced Binary Tree 2 tree DFS113 Path Sum II 2 tree DFS115 Distinct Subsequences 2 string DP117 Populating Next Right Pointers in Each Node II 2 tree DFS124 Binary Tree Maximum Path Sum 2 tree DFS6 ZigZag Conversion 1 string14 Longest Common Prefix 1 string16 3Sum Closest 1 array Two Pointers30 Substring with Concatenation of All Words 1 string Two Pointers32 Longest Valid Parentheses 1 string DP58 Length of Last Word 1 string60 Permutation Sequence 1 permutation、Math71 Simplify Path 1 string Stack85 Maximal Rectangle 1 array DP、Stack95 Unique Binary Search Trees II 1 tree DP、DFS96 Unique Binary Search Trees 1 tree DP100 Same Tree 1 tree DFS104 Maximum Depth of Binary Tree 1 tree DFS107 Binary Tree Level Order Traversal II 1 tree BFS111 Minimum Depth of Binary Tree 1 tree DFS118 Pascal’s Triangle 1 array119 Pascal’s Triangle II 1 array120 Triangle 1 array DP121 Best Time to Buy and Sell Stock 1 array DP122 Best Time to Buy and Sell Stock II 1 array greedy123 Best Time to Buy and Sell Stock III 1 array DP126 Word Ladder II 1]]></content>
      <tags>
        <tag>笔面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10大数据算法排序Java_C++]]></title>
    <url>%2F2018%2F08%2F16%2F10%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AE%97%E6%B3%95%E6%8E%92%E5%BA%8FJava_C%2B%2B%2F</url>
    <content type="text"><![CDATA[10大数据算法排序Java_C++ 冒泡排序 依次比较n与后面的数字，大的放右面，小的放左边Java代码12345678910111213141516171819202122232425/** * 冒泡排序 * 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 * 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 * 针对所有的元素重复以上的步骤，除了最后一个。 * 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 * @param numbers 需要排序的整型数组 */ public static void bubbleSort(int[] numbers) &#123; int temp = 0; int size = numbers.length; for(int i = 0 ; i &lt; size-1; i ++) &#123; for(int j = 0 ;j &lt; size-1-i ; j++) &#123; if(numbers[j] &gt; numbers[j+1]) //交换两数位置 &#123; temp = numbers[j]; numbers[j] = numbers[j+1]; numbers[j+1] = temp; &#125; &#125; &#125; &#125; C++代码1待补充 选择排序 选择n个数组成的数组arr里最大的一个数，放在arr[n-1]，然后维数n-1选择前n-1个数组成的数组，取最大数，放在arr Java代码：1234567891011121314151617181920212223242526272829/** * 选择排序算法 * 在未排序序列中找到最小元素，存放到排序序列的起始位置 * 再从剩余未排序元素中继续寻找最小元素，然后放到排序序列末尾。 * 以此类推，直到所有元素均排序完毕。 * @param numbers */ public static void selectSort(int[] numbers) &#123; int size = numbers.length; //数组长度 int temp = 0 ; //中间变量 for(int i = 0 ; i &lt; size ; i++) &#123; int k = i; //待确定的位置 //选择出应该在第i个位置的数 for(int j = size -1 ; j &gt; i ; j--) &#123; if(numbers[j] &lt; numbers[k]) &#123; k = j; &#125; &#125; //交换两个数 temp = numbers[i]; numbers[i] = numbers[k]; numbers[k] = temp; &#125; &#125; C++代码：1待补充 快速排序及其改进算法C++实现 快速排序可以看成是插入排序的改进，它是一种分治的排序算法 Java代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445public class FastSort&#123; public static void main(String []args)&#123; System.out.println(&quot;Hello World&quot;); int[] a = &#123;12,20,5,16,15,1,30,45,23,9&#125;; int start = 0; int end = a.length-1; sort(a,start,end); for(int i = 0; i&lt;a.length; i++)&#123; System.out.println(a[i]); &#125; &#125; public void sort(int[] a,int low,int high)&#123; int start = low; int end = high; int key = a[low]; while(end&gt;start)&#123; //从后往前比较 while(end&gt;start&amp;&amp;a[end]&gt;=key) //如果没有比关键值小的，比较下一个，直到有比关键值小的交换位置，然后又从前往后比较 end--; if(a[end]&lt;=key)&#123; int temp = a[end]; a[end] = a[start]; a[start] = temp; &#125; //从前往后比较 while(end&gt;start&amp;&amp;a[start]&lt;=key)//如果没有比关键值大的，比较下一个，直到有比关键值大的交换位置 start++; if(a[start]&gt;=key)&#123; int temp = a[start]; a[start] = a[end]; a[end] = temp; &#125; //此时第一次循环比较结束，关键值的位置已经确定了。左边的值都比关键值小，右边的值都比关键值大，但是两边的顺序还有可能是不一样的，进行下面的递归调用 &#125; //递归 if(start&gt;low) sort(a,low,start-1);//左边序列。第一个索引位置到关键值索引-1 if(end&lt;high) sort(a,end+1,high);//右边序列。从关键值索引+1到最后一个 &#125; &#125; C++代码：cankao12345678910111213141516171819202122232425262728293031323334353637383940#include&lt;iostream&gt;using namespace std;int main()&#123; int array[]=&#123;34,65,12,43,67,5,78,10,3,70&#125;,k; int len=sizeof(array)/sizeof(int); cout&lt;&lt;&quot;The orginal arrayare:&quot;&lt;&lt;endl; for(k=0;k&lt;len;k++) cout&lt;&lt;array[k]&lt;&lt;&quot;,&quot;; cout&lt;&lt;endl; quickSort(array,0,len-1); cout&lt;&lt;&quot;The sorted arrayare:&quot;&lt;&lt;endl; for(k=0;k&lt;len;k++) cout&lt;&lt;array[k]&lt;&lt;&quot;,&quot;; cout&lt;&lt;endl; system(&quot;pause&quot;); return 0;&#125; void quickSort(int s[], int low, int high)&#123; if (low&lt; high) &#123; int i = low, j = high, x = s[low]; while (i &lt; j) &#123; while(i &lt; j &amp;&amp; s[j]&gt;= x) // 从右向左找第一个小于x的数 j--; if(i &lt; j) s[i++] = s[j]; while(i &lt; j &amp;&amp; s[i]&lt; x) // 从左向右找第一个大于等于x的数 i++; if(i &lt; j) s[j--] = s[i]; &#125; s[i] = x; quickSort(s, low, i - 1); // 递归调用 quickSort(s, i + 1, high); &#125;&#125; 归并排序 归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。分治思想：合并步骤如下 Java代码：cankao12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package sortdemo;import java.util.Arrays;/** * Created by chengxiao on 2016/12/8. */public class MergeSort &#123; public static void main(String []args)&#123; int []arr = &#123;9,8,7,6,5,4,3,2,1&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125; public static void sort(int []arr)&#123; int []temp = new int[arr.length];//在排序前，先建好一个长度等于原数组长度的临时数组，避免递归中频繁开辟空间 sort(arr,0,arr.length-1,temp); &#125; private static void sort(int[] arr,int left,int right,int []temp)&#123; if(left&lt;right)&#123; int mid = (left+right)/2; sort(arr,left,mid,temp);//左边归并排序，使得左子序列有序 sort(arr,mid+1,right,temp);//右边归并排序，使得右子序列有序 merge(arr,left,mid,right,temp);//将两个有序子数组合并操作 &#125; &#125; private static void merge(int[] arr,int left,int mid,int right,int[] temp)&#123; int i = left;//左序列指针 int j = mid+1;//右序列指针 int t = 0;//临时数组指针 while (i&lt;=mid &amp;&amp; j&lt;=right)&#123; if(arr[i]&lt;=arr[j])&#123; temp[t++] = arr[i++]; &#125;else &#123; temp[t++] = arr[j++]; &#125; &#125; while(i&lt;=mid)&#123;//将左边剩余元素填充进temp中 temp[t++] = arr[i++]; &#125; while(j&lt;=right)&#123;//将右序列剩余元素填充进temp中 temp[t++] = arr[j++]; &#125; t = 0; //将temp中的元素全部拷贝到原数组中 while(left &lt;= right)&#123; arr[left++] = temp[t++]; &#125; &#125;&#125; C++代码：cankao1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include&lt;iostream&gt;using namespace std;const int maxn=500000,INF=0x3f3f3f3f;int L[maxn/2+2],R[maxn/2+2];void merge(int a[],int n,int left,int mid,int right)&#123; int n1=mid-left,n2=right-mid; for(int i=0;i&lt;n1;i++) L[i]=a[left+i]; for(int i=0;i&lt;n2;i++) R[i]=a[mid+i]; L[n1]=R[n2]=INF; int i=0,j=0; for(int k=left;k&lt;right;k++) &#123; if(L[i]&lt;=R[j]) a[k]=L[i++]; else a[k]=R[j++]; &#125;&#125;void mergesort(int a[],int n,int left,int right)&#123; if(left+1&lt;right) &#123; int mid=(left+right)/2; mergesort(a,n,left,mid); mergesort(a,n,mid,right); merge(a,n,left,mid,right); &#125;&#125;int main()&#123; int a[maxn],n; cin&gt;&gt;n; for(int i=0;i&lt;n;i++) cin&gt;&gt;a[i]; mergesort(a,n,0,n); for(int i=0;i&lt;n;i++) &#123; if(i) cout&lt;&lt;&quot; &quot;; cout&lt;&lt;a[i]; &#125; cout&lt;&lt;endl; return 0;&#125; 堆排序 http://www.cnblogs.com/MOBIN/p/5374217.html 堆排序主要在于理解堆的构造过程和在输出最大元素后如何对堆进行重新调整 大顶堆：父结点始终&gt;子节点 小顶堆：父结点始终&lt;子节点12345算法思想(以大顶堆为例)：1.将长度为n的待排序的数组进行堆有序化构造成一个大顶堆2.将根节点与尾节点交换并输出此时的尾节点3.将剩余的n -1个节点重新进行堆有序化4.重复步骤2，步骤3直至构造成一个有序序列 我们开始只需要扫描一半的元素（n/2-1 ~ 0）,因为(n/2-1)~0的节点才有子节点 构建有序堆：1、第一次for循环将节点3和它的子节点7 8的元素进行比较，最大者作为父节点（即元素60作为父节点）红色表示交换后的状态2、第二次for循环将节点2和它的子节点5 6的元素进行比较，最大者为父节点（元素80作为父节点）3、第三次for循环将节点1和它的子节点3 4的元素进行比较，最大者为父节点（元素70作为父节点） 调整堆1、堆顶元素80和尾40交换后—&gt;调整堆2、堆顶元素70和尾30交换后—&gt;调整堆。。。完成调整 左右父节点下标:123左：i*2+1右：i*2+2父：(i-1)/2 Java代码：123456789101112131415161718192021222324252627282930313233343536373839404142public class HeapSort &#123;private static void heapSort(int[] arr) &#123;int len = arr.length -1;//堆构造，调整结构，符合大顶堆或者小顶堆for(int i = len/2 ; i &gt;=0; i --)&#123; heapAdjust(arr,i,len);&#125;while (len &gt;=0)&#123;swap(arr,0,len--); //将堆顶元素与尾节点交换后，长度减1，尾元素最大heapAdjust(arr,0,len); //再次对堆进行调整&#125;&#125;public static void heapAdjust(int[] arr,int i,int len)&#123;int left = 2*i+1,right = 2*i+2,largest = i;if(left &lt;= len &amp;&amp; arr[left] &gt; arr[i])largest = left;if(right &lt;= len &amp;&amp; arr[right] &gt; arr[largest])largest = right;if(largest != i) &#123;swap(arr, i, largest);heapAdjust(arr,largest,len);&#125;&#125;public static void swap(int[] arr,int i,int len)&#123;int temp = arr[i];arr[i] = arr[len];arr[len] = temp;&#125;public static void main(String[] args) &#123;int array[] = &#123;20,50,20,40,70,10,80,30,60&#125;;System.out.println(&quot;排序之前：&quot;);for(int element : array)&#123;System.out.print(element+&quot; &quot;);&#125;heapSort(array);System.out.println(&quot;\n排序之后：&quot;);for(int element : array)&#123;System.out.print(element+&quot; &quot;);&#125;&#125;&#125; C++代码：1待补充 插入排序Java代码：1待补充 C++代码：1待补充 桶排序需要求数组中的最大数1、桶排序不在是一种基于比较的排序方法，而是需要待排序列满足以下两个条件： 1、待排序列的值处于一个可枚举的范围内2、待排序列所在可枚举范围不应太大，不然开销会很大。 原理： 假设待排序的数组a中共有N个整数，并且已知数组a中数据的范围[0, MAX)。在桶排序时，创建容量为MAX的桶数组r，并将桶数组元素都初始化为0；将容量为MAX的桶数组中的每一个单元都看作一个”桶”。在排序时，逐个遍历数组a，将数组a的值，作为”桶数组r”的下标。当a中数据被读取时，就将桶的值加1。例如，读取到数组a[3]=5，则将r[5]的值+1。 桶排序适用场景:根据桶排序的特点，桶排序一般适用于一些特定的环境，比如数据范围较为局限或者有一些特定的要求，比如需要通过哈希映射快速获取某些值，需要统计每个数的数量。但是这一切都以确认数据的范围为前提，如果范围跨度过大，则考虑用其他算法。 Java代码：12345678910111213141516171819202122232425262728/// &lt;summary&gt;/// 桶排序//////如果有重复的数字,则需要 List&lt;int&gt;数组,这里举的例子没有重复的数字/// &lt;/summary&gt;/// &lt;param name=&quot;unsorted&quot;&gt;待排数组&lt;/param&gt;/// &lt;param name=&quot;maxNumber&quot;&gt;待排数组中的最大数,如果可以提供的话&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;static int[] bucket_sort(int[] unsorted, int maxNumber = 97)&#123; int[] sorted = new int[maxNumber + 1]; for (int i = 0; i &lt; unsorted.Length; i++) &#123; sorted[unsorted[i]] = unsorted[i]; &#125; return sorted;&#125;static void Main(string[] args)&#123; int[] x = &#123;49、 38 、 35、 97 、 76、 73 、 27、 49 &#125;; var sorted = bucket_sort(x, 97); for (int i = 0; i &lt; sorted.Length; i++) &#123; if (sorted[i] &gt; 0) Console.WriteLine(sorted[i]); &#125; Console.ReadLine();&#125; C++代码：1待补充 Java代码：1待补充 C++代码：1待补充 Java代码：1待补充 C++代码：1待补充 Java代码：1待补充 C++代码：1待补充]]></content>
      <tags>
        <tag>Java</tag>
        <tag>C++</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面经—机器学习]]></title>
    <url>%2F2018%2F08%2F15%2F%E9%9D%A2%E7%BB%8F%E2%80%94%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[面经—机器学习 CVTE面经作者：一一后链接：https://www.nowcoder.com/discuss/88069来源：牛客网 1.解释方差 2.PCA的实现过程；推导PCA 3.传统的图像特征有哪些 4.Sift特征为什么能实现尺度不变性（讲sift原理到一半，我发现完全解释不了为啥尺度不变，就停了，尴尬）[参考](https://blog.csdn.net/u014485485/article/details/78681086?locationNum=1&amp;fps=1）123尺度不变性：不管原图尺度是多少，在包含了所有尺度的尺度空间下都能找到那些稳定的极值点，这样就做到了尺度不变！高斯函数是唯一可行的尺度空间核 5.Hough直线检测的原理 6.梯度下降和牛顿法的区别1234567891011牛顿法的优缺点优点：二阶收敛，收敛速度快；缺点：牛顿法是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢梯度下降法的缺点：靠近极小值时收敛速度减慢，；直线搜索时可能会产生一些问题；可能会“之字形”地下降。牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快 7.SVM和Lr的共同点和不同点1234567891011121314151617LR和SVM都是分类算法LR和SVM都是线性分类算法LR和SVM都是监督学习算法LR和SVM都是判别模型LR和SVM在学术界和工业界都广为人知并且应用广泛不同：损失函数LR：逻辑回归方法基于概率理论逻辑回归考虑全局（远离的点对边界线的确定也起作用）对数据不做处理LR必须另外在损失函数上添加正则项SVM：几何间隔最大化原理支持向量机只考虑局部的边界线附近的点，线性SVM不直接依赖于数据分布线性SVM依赖数据表达的距离测度，所以需要对数据先做归一化SVM的损失函数就自带正则 8.rf和Adaboost的异同(优秀的基于决策树的组合算法)123451，相同：二者都是bootsrap自助法选取样本。 2，相同：二者都是要训练很多棵决策树。 3，不同：adaboost后面树的训练，其在变量抽样选取的时候，对于上一棵树分错的样本，抽中的概率会加大。 4，不同：随机森林在训练每一棵树的时候，随机挑选了部分变量作为拆分变量，而不是所有的变量都去作为拆分变量。 5，不同：在预测新数据时，adaboost中所有的树加权投票来决定因变量的预测值，每棵树的权重和错误率有关；随机森林按照所有树中少数服从多数树的分类值来决定因变量的预测值。 9.给出一堆大小不一的矩形框，快速求矩形框的灰度值之和（当时没理解，这不是肯定要遍历么…后来结束后我想这些矩形框可能是重叠的，估计是要问我关于Bing中快速求梯度的算法） 10.有什么要问他的 作业帮提前批机器学习算法岗作者：编程一头牛链接：https://www.nowcoder.com/discuss/90245来源：牛客网 对数据预处理怎么填充的缺失值，哪些判定为异常值，对连续属性进行离散化有什么好处，Logistic回归能处理浮点数吗？多项式组合特征对哪个模型中效果提升最大。这个没答上来，问了面试官，面试官说是Logistic回归里面提升最大，而且组合起来的两个特征也是想出来的，没什么理论支撑。还问了模型的评价指标AUC是如何计算的，ROC曲线的横纵坐标代表了什么含义。XGBoost模型里面参数有哪些？如何发现过拟合。XGBoost模型中对数据进行采样的好处？ 如何最快的找出两个集合中的交集，提出用哈希表的方法，问了这种方法的复杂度，然后又问如果这两个集合都特别大，不能再内存中构建哈希表该如何做？可能是想让我回答多线程相关的内容，但是我不会。如何设计哈希表？期间也问过有编过多线程多进程的代码吗 深信服【机器学习】一面作者：Rnanprince链接：https://www.nowcoder.com/discuss/87283来源：牛客网 【机器学习】一面：1.项目介绍，研究的最成功的地方，我以写的文章为例，涉及到的知识点就问2.笔试的数组求和100怎么做的？没抽到这个题，但是做过；接着我说做了查找重复字符串最大长度，深搜，过了就没想别的方法一个数组，求最长的连续子序列的起始下标，当时没理解明白，其实有歧义，简单说了一下3.自己的哪些方面的优点没有涉及到，介绍一下提到了SVM和决策树，介绍一下什么情况下使用？svm:12345678910111213141516171819202122232425262728293031这个模型的优势是什么？分类效果好；可以有效地处理高维空间的数据；可以有效地处理变量个数大于样本个数的数据；只是使用了一部分子集来进行训练模型，所以SVM模型不需要太大的内存；可以提高泛化能力；无局部极小值问题；他什么情况下表现最好？数据的维度较高；需要模型具有非常强的泛化能力；样本数据量较小时；解决非线性问题；这个模型的缺点是什么？无法处理大规模的数据集，因为该算法需要较长的训练时间；无法有效地处理包含噪声太多的数据集；SVM模型没有直接给出概率的估计值，而是利用交叉验证的方式估计，这种方式耗时较长；对缺失数据非常敏感；对于非线性问题，有时很难找到一个合适的核函数。什么条件下它表现很差？数据集的数据量过大；数据集中的含有噪声；数据集中的缺失较多的数据；对算法的训练效率要求较高；根据我们当前数据集的特点，为什么这个模型适合这个问题。 该项目所提供的样本数据相对较少；该问题是属于非线性问题；数据集经过“独热编码”后，维度较高 决策树：1234567891011121314151617181920212223242526272829303132这个模型的优势是什么？决策树易于实现和理解；对于决策树，数据的准备工作一般比较简单；能够同时处理多种数据类型给定一个决策树模型，可以根据产生的决策树推出相应的逻辑表达式；通过静态测试来对模型的表现进行评价；在相对较短的时间内可以对大量的数据做出非常好的结果；决策树可以很好地扩展到大型数据中，同时决策树的大小独立于数据库的大小；计算复杂度相对较低，结果的输出易于理解，对部分的数据缺失不敏感。他什么情况下表现最好？实例是由“属性-值”对表示的；目标函数具有离散的输出值；训练数据集包含部分错误(决策树对错误有适应性)；训练数据缺少少量属性的实例。这个模型的缺点是什么？易于出现过拟合问题；忽略了数据集中属性之间的相关性；对于类比不一致的样本，决策树的信息增益倾向于那些数据值较多的特征什么条件下它表现很差？决策树匹配的数据过多时；分类的类别过于复杂；数据的属性之间具有非常强的关联。根据我们当前数据集的特点，为什么这个模型适合这个问题。不需要准备太多的训练数据，不需要对数据过多的处理如删除空白值等；易于编码；该问题是非线性问题，决策树能够很好地解决非线性问题；算法的执行效率高，对机器的要求较小。 360浏览器事业部 推荐算法工程师作者：泡了个泡链接：https://www.nowcoder.com/discuss/77924来源：牛客网 二面 1.项目 2.SVM原始问题为什么要转化为对偶问题，为什么对偶问题就好求解，原始问题不能求解么 3.K-means 中我想聚成100类 结果发现只能聚成98类，为什么 4.进程中的内存分段是怎样的 5.每个线程有哪些东西是自己独享的 6.一枚不均匀的硬币，我抛了100次，有70次朝上，那么第101次朝上的概率是多少 这个概率怎么样，公示是如何推导出来的 7.给你个字符串，字符串是个数字，怎么转换为int型，不用库函数的话 8.4个海盗，100个金币，每个人轮流提方案，如果你的方案有半数以上通过，那么久可以，否则就会被杀掉，如果你是第一个人，那么你怎么提方案比较好 9.你的优点是什么 腾讯沈阳现场一面1.项目 2.特征选择方法都有用过哪些 3.随机森林怎么进行特征选择 4.用过哪些机器学习算法 5.加密方法知道哪些 6.MD5可逆么 7.word2vec用过么 8.极大似然估计是什么意思 9.上过哪些课 10.排序算法哪些时间复杂度比较低 11.计算机网络了解多少 阿里 新零售 天猫 算法工程师-机器学习一面先是一个简单的自我介绍；1.然后介绍了项目的框架和主要创新点； 2.说一下随机森林和Adaboost，以及区别 3.说一下GBDT和Adaboost，以及区别 4.说一下LDA的原理 5.对于PCA，会有第一主成分、第二主成分，怎么为什么第一主成分是第一，原因是什么？ 6.PCA的主成分是怎么得到的 3.面向对象的三要素 4.对深度学习了解多少 5.你觉得深度学习的方法和传统机器学习比，有什么大的优势 腾讯提前批作者：IamBright链接：https://www.nowcoder.com/discuss/75166来源：牛客网 女朋友在广州又不想换工作的情况下，微信的机器学习算法工程师是最适合我实习的岗位了，因此最先让腾讯的同学内推了一波，在基本没有准备的情况下，接到了提前批电话一面二面，毫无意外的挂了。 电话一面聊论文，但多数听我在说，没插话什么问题。最后问我第二篇论文里RNN实现的时候有什么trick。问了问凸优化了解吗？传统机器学习了解吗？我答机器学习基本知识都学过，凸优化只了解和机器学习优化算法相关的。也没有继续问细节了。编程题：打印所有子集，我用了迭代，但是写的比较蠢，好在不用调试运行电话二面聊论文，最后问了我跟什么算法做了对比，问我研究的实际意义，产业界现在的水平编程题：打印螺旋矩阵，要我给一个可运行的结果。很简单的题，我一个符号错误调了很久都没发现，这里应该就印象很差了。linux里查看端口被占用的命令，linux不熟，没答上。AUC是什么？我说了是ROC曲线下面积，但是想不起来ROC是啥。我都是做序列数据，没做过二分类问题。LR和SVM的区别。我说了损失函数不同，然后说了SVM通过核技巧可以更好的应对非线性，但是前面好差，这里也没好好组织语言了。提前批挂的没什么话说，就是没准备，好久没做过算法题的情况下，突然出题做就很不顺手。而且机器学习的基础知识都有点忘了，像AUC这种没用过的，基本一问就懵逼。 之后跟工作的同学聊了一下，来牛客刷了刷面经，制定了简单的复习内容和刷题计划。花了一周时间，复习了一下西瓜书前11章和deep learning book前11章，刷了leetcode上三四十道medium的题吧（链表、字符串、迭代、dfs、堆、树、动态规划等每天刷一类题练练手），并且给自己做完2篇论文都准备了面试介绍版，又让同学推了阿里和网易，并进入腾讯笔试流程。 算法、数据挖掘岗面经作者：胖胖胖子链接：https://www.nowcoder.com/discuss/81814来源：牛客网 1.华为回国之后参加的第一次面试就是华为的留学生专场招聘，岗位是大数据开放（华为好像填什么岗位都没差吧~），一共只有两面一面：介绍我的项目经历，我介绍完面试官尴尬的笑了笑说他不是做大数据方向的，也就没问我什么，聊了聊天愉快的过了二面：可能会针对笔试提问，因为面试官问我为什么没参加笔试，然后就问了问职业规划，说大数据方向都在深圳工作，然后就一直问怎么看待华为的加班文化，怎么看待压力之类的大概10天之后就直接把offer发到了邮箱里2.第四范式（二面挂）刚面完华为就参加了第四范式的面试，以为面试就是聊聊天，后来发现真是naive，第四范式的岗位是nlp研究员一面：就写了两个代码，一个是逆时针打印矩阵，一个是leetcode原题count and say，虽然当时还没刷过题但写的都是easy难度，就过了二面：二面面试官是牛津大学的phd，问我是不是distinction我说不是，就感受到了一股失望~讲了讲项目，问的很细，但是都在自己的项目范围内，问完之后又是写代码，一个字符串如何删除不匹配的括号然后输出括号匹配的字符串，比如（abc（），输出（abc）和abc（），哼哼唧唧没写出来就跪了3.招银网络招银网络面试岗位是算法工程师，一共两轮技术面，一轮hr面一面：讲项目，问了决策树ID3，C4.5，CART的区别，讲了SVM的原理，然后写了找两个数的最小公倍数的代码二面：讲项目，然后面试官说他是做C++开发的，问我会不会C++，我说学过但很久没用了，就聊了聊天愉快的过了hr面：略（就谈人生谈理想接不接受调岗） 平安科技招银网络面试岗位是算法工程师，一共两轮技术面，一轮hr面一面：讲项目，问了问当时爬虫有没有用什么框架，然后问为什么文本分类我选择了朴素贝叶斯，然后让我说了一下对word2vec的理解二面：最痛的一次面试，三个面试官，一个问数据结构和数据库：问我知道的数据结构和使用场景，然后口述怎么把单链表变双向链表，讲了一下红黑树，以及红黑树的应用，数据的范式，索引失效的情况，如何优化数据库性能等等。第二个面试官问操作系统和计算机网络：TCP三次握手，四次挥手，第二次挥手和第三次挥手的时间间隔如何界定，TCP拥塞控制，OSI五层模型，每层有什么协议，TCP和UDP的区别，UDP的应用（这个问题我没太理解），ARP协议，python多线程，python3对python2是否有改进。第三个面试官问设计模式和算法：python闭包，bagging/boosting的区别，XGboost特点，tf-idf缺点，单例模式（设计模式我完全不会），怎样设计一个分布式的爬虫。hr面：大概聊了聊对薪资的期望，和工作的部门5.链家链家是参加了牛客的留学生专场，感觉链家的面试官人真的好~岗位是机器学习/数据挖掘工程师，不过链家面试有点坎坷面完前两面才发现我面的大数据开发，其实我想去的是数据挖掘，然后就开始了第三轮面试一面：先写了一个很简单的判断两个二叉树是不是一样的树，然后就说给一台机器内存有限制，然后10台服务器，每个服务器上有一个1G文件，假设文件里单词，如何给这些单词按频率排序，又问了求数据流的中位数，最后是智力题，给你两个一模一样的杯子，假设一共有10层楼，怎样找到杯子摔下来能不碎的最高楼层。二面：面试官先问我职业规划，我说数据挖掘，他就比较懵说他们是大数据开发部门，问我考不考虑，我说还是倾向于做数据挖掘，就开始了面试，问了数据库索引的优缺点，索引失效的情况，然后复合索引如何引用会失效，然后问了ACID，剩下的记不清了，说我基础不错去给我联系数据挖掘的面试官三面：手写LR损失函数，LR/SVM区别，手画word2vec网络结构，bagging，boosting，stacking的区别和联系，如果RF和GBDT达到同样的准确度哪个分裂的树更少为什么，随机梯度下降和梯度下降哪一个更快，XGBoost特点，XGBoost的L1和L2正则化怎么体现，特征工程相关的卡方统计和互信息计算公式，然后写了一个如何用最少的硬币找钱。HR面：介绍了一下链家的福利和部门的发展。6.快手快手4.18的笔试，5.5面试大概是备胎池捞起来了，三轮技术面，一轮hr面一面：介绍项目，边讲项目边提问，然后写了个代码，判断有向图中是否有环二面：介绍项目，边讲项目边提问，问了文本分类问什么朴素贝叶斯比SVM，决策树效果更好，然后分类性能度量，precision，recall，F1 score和ROC AUC对比，写了一个leetcode的flatten nested list iterator三面：只写代码，第一个AABB的字符串输出AB，第二个找数组的最长递增子序列，然后介绍了一下他们做的东西HR面：谈了谈offer 顺丰提前批人工智能岗技术面面经作者：撒泼打滚求Offer链接：https://www.nowcoder.com/discuss/92370来源：牛客网 目标检测了解吗，（了解一点）Faster RCNN跟RCNN有什么区别 SPP， YOLO了解吗（不了解）（后悔没去看看= =） 梯度消失梯度爆炸怎么解决 RNN容易梯度消失，怎么解决（LSTM） LSTM跟RNN有啥区别 传统的机器学习算法了解吗（不怎么了解，说了个KMeans） KMeans讲讲，KMeans有什么缺点，K怎么确定（不会） 卷积层和池化层有什么区别（不是很懂这个问题的点） 防止过拟合有哪些方法 1234567891011121314151、正则化，即在对模型的目标函数（objective function）或代价函数（cost function）加上正则项 随着模型训练的进行，模型的复杂度会增加，此时模型在训练数据集上的训练误差会逐渐减小，但是在模型的复杂度达到一定程度时，模型在验证集上的误差反而随着模型的复杂度增加而增大。此时便发生了过拟合，即模型的复杂度升高。1、early stopping、 迭代次数（epochs）截断的方法（常用 梯度下降法）； 训练数据一次遍历结束，计算指标，指标不增加，停止训练； 记录一个最好的指标，如果之后的10次，20次训练达到的指标都没有之前最好的高，则停止训练。2、数据增强（Data augmentation）、 从数据源采集更多数据 复制原有数据并加上随机噪声 重采样 根据当前数据集估计数据分布参数，使用该分布产生更多数据等3、正则化（Regularization）、 正则化方法是指在进行目标函数或代价函数优化时，在目标函数或代价函数后面加上一个正则项，一般有L1正则与L2正则等。4、Dropout dropout咋回事讲讲 你有什么要问我的吗 联影医疗 Offer作者：吃饭睡觉编论文链接：https://www.nowcoder.com/discuss/52357来源：牛客网 联影医疗 Offer一面1、GBDT和xgboost的区别2、GBDT和LR的区别3、讲项目（为什么用GBDT LR？）4、随便讲一个熟悉的传统图像处理中的特征提取和描述子（sift和sift描述子）二面1、写代码：实现统计图像灰度直方图的代码2、熟悉的聚类算法、k-means原理、混合高斯模型原理3、PCA原理、数学解释（应该是一个最优的线性子空间）4、surf相比sift特征点的优化之处5、写代码：dijkstra最短路径算法6、SVM原理、过拟合怎么解决7、霍夫变换检测直线和圆的原理HR面个人优缺点、拿到的offer、期望薪资、是不是独生子、对联影医疗的了解 VIVO算法作者：MadCoder链接：https://www.nowcoder.com/discuss/94110来源：牛客网 1.评估指标2.在AUC值大时，Log损失也大。请问可能的原因3.梯度消失，梯度爆炸原因及解决4.概率题：8支球队循环赛，前四名晋级。求晋级可能性5.Spark和hadoop实现K-MEANS，及优劣比较]]></content>
      <tags>
        <tag>笔面试</tag>
        <tag>C++</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git_update_error1]]></title>
    <url>%2F2018%2F08%2F01%2Fgit_update_error1%2F</url>
    <content type="text"><![CDATA[git 上传报错及解决 failed to push some refs to报错内容，不能推送文件到github上1error: failed to push some refs to github地址 原因是github项目与本地文件夹一些关键文件的确实，比如.git，readme.md文件等等 解决：本地文件夹打开控制命令台 1、添加本地文件夹，github项目更新到本地12git add .git pull origin master 2、再上传文件夹到github1git push -u origin master fatal: The remote end hung up unexpectedlygit推送项目时候出现 “fatal: The remote end hung up unexpectedly ” 原因是推送的文件太大。 上传网速过慢导致文件传输不完整 解决等一会，重新在push上传一遍]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用LaTex添加公式到Hexo博客里]]></title>
    <url>%2F2018%2F07%2F23%2Fhexo_LeTex1%2F</url>
    <content type="text"><![CDATA[使用LaTex添加公式到Hexo博客里 代码编辑器，强烈推荐使用微软的 VS code，相比Atom开启迅速，使用方便，扩展丰富 第一步： 安装Kramedhexo 默认的渲染引擎是 marked，但是 marked 不支持 mathjax。，所以需要更换Hexo的markdown渲染引擎为hexo-renderer-kramed引擎，后者支持mathjax公式输出。12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 第二步：更改文件配置打开/node_modules/hexo-renderer-kramed/lib/renderer.js，更改：123456789101112// Change inline math rulefunction formatText(text) &#123; // Fit kramed&apos;s rule: $$ + \1 + $$ return text.replace(/`\$(.*?)\$`/g, &apos;$$$$$1$$$$&apos;);&#125;为，直接返回text// Change inline math rulefunction formatText(text) &#123; return text;&#125; 第三步: 停止使用 hexo-math，并安装mathjax包卸载hexo-math1npm uninstall hexo-math --save 安装 hexo-renderer-mathjax 包1npm install hexo-renderer-mathjax --save 第四步: 更新 Mathjax 的 配置文件打开/node_modules/hexo-renderer-mathjax/mathjax.html如图所示更改&lt;script&gt;为：即注释掉&lt;script&gt;代码，并把以下代码复制到对应位置1&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt; 第五步: 更改默认转义规则因为LaTeX与markdown语法有语义冲突，所以 hexo 默认的转义规则会将一些字符进行转义，所以我们需要对默认的规则进行修改. 打开/node_modules\kramed\lib\rules\inline.js 1、1escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/, 更改为1escape: /^\\([`*\[\]()# +\-.!_&gt;])/, 2、1em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 更改为1em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 第六步: 开启mathjax打开/themes/yilia主题目录下的config.yml文件因为我用的yilia主题，所以路径是/themes/yilia 我们需要在config.yml文件 中开启 Mathjax， 找到 mathjax 字段添加如下代码：(不同的主题配置方法略微有区别)12mathjax: enable: true 或者1mathjax: true 注意的是：，无论是配置文件还是博客文件，配置项跟配置参数均有有一个空格，否则会配置失败例：123mathjax: true（mathjax:空格true）而不是mathjax:true（mathjax:true） 写博客文件时，要开启 Mathjax选项，， 添加以下内容： 1mathjax: true 例如1234title: 特征提取——局部特征date: 2018-07-16 09:39:40tags: [GitHub, Mysql]mathjax: true 如下图所示 通过以上步骤，我们就可以在 hexo 中使用 Mathjax 来书写数学公式。 效果展示： 我的博客主页，欢迎访问我的CSDN主页，欢迎访问我的简书主页，欢迎访问我的GitHub主页，欢迎访问参考文章1参考文章2 https://www.jianshu.com/p/a0aa94ef8ab2]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习_最优化_损失函数]]></title>
    <url>%2F2018%2F07%2F22%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E6%9C%80%E4%BC%98%E5%8C%96_%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[机器学习最优化损失函数 通常机器学习每一个算法中都会有一个目标函数，算法的求解过程是通过对这个目标函数优化的过程。 在分类或者回归问题中，通常使用损失函数（代价函数）作为其目标函数。损失函数用来评价模型的预测值和真实值不一样的程度，损失函数越好，通常模型的性能越好。不同的算法使用的损失函数不一样。 损失函数分为经验风险损失函数和结构风险损失函数 损失函数 概念 经验风险损失函数 预测结果和实际结果的差别 结构风险损失函数 经验风险损失函数+正则项 θ^∗=argmin(1/N)\sum_i=1^n\L(y_i,f(x_i;θ_i))\+λ\phi(\theta)0-1损失函数和绝对值损失函数原理：预测值和目标值不相等为1，否则为0。绝对值损失函数为： L(Y,f(X))=1, if Y≠f(X)L(Y,f(X))=0, if Y=f(X)感知机就是用的这种损失函数改进：Y-f(X)&lt;阈值T判断相等绝对值损失函数为： L(Y,f(X)=|Y−f(X)|log对数损失函数原理：假设样本服从伯努利分布（0-1）分布，然后求得满足该分布的似然函数，接着用对数求极值。log损失函数的标准形式： L(Y,P(Y|X))=−logP(Y|X)平方损失函数最小二乘法是线性回归的一种方法，它将回归的问题转化为了凸优化的问题。最小二乘法的基本原则是：最优拟合曲线应该使得所有点到回归直线的距离和最小。通常用欧几里得距离进行距离的度量。平方损失的损失函数为： L(Y|f(X))=∑N(Y−f(X))^2指数损失函数AdaBoost就是一指数损失函数为损失函数的。指数损失函数的标准形式： L(Y|f(X))=exp[−yf(x)]Hinge损失函数Hinge损失函数和SVM是息息相关的。在线性支持向量机中，最优化问题可以等价于 1/m\sum_i=1^m\l(wx_i+by_i)+||w||^2其中l(wx_i+by_i) 就是hinge损失函数，后面相当于L2正则项。 Hinge函数的标准形式： L(y)=max(0,1−ty) y的值在-1和+1之间就可以了,使分类器可以更专注于整体的分类误差 参考文章]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>最优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习_分类_adaboost]]></title>
    <url>%2F2018%2F07%2F21%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E5%88%86%E7%B1%BB_adaboost%2F</url>
    <content type="text"><![CDATA[机器学习_分类_adaboost 简介Boosting, 也称为增强学习或提升法，是一种重要的集成学习技术， 能够将预测精度仅比随机猜度略高的弱学习器增强为预测精度高的强学习器。 AdaBoost是英文”Adaptive Boosting”（自适应增强）的缩写 步骤1231）首先，是初始化训练数据的权值分布D1。假设有N个训练样本数据，则每一个训练样本最开始时，都被赋予相同的权值：w1=1/N。2）然后，训练弱分类器hi。具体训练过程中是：如果某个训练样本点，被弱分类器hi准确地分类，那么在构造下一个训练集中，它对应的权值要减小；相反，如果某个训练样本点被错误分类，那么它的权值就应该增大。权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。3）最后，将各个训练得到的弱分类器组合成一个强分类器。各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用，而降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。 误差率低的弱分类器在最终分类器中占的权重较大，否则较小。 alpha值是基于每个弱分类器的错误率进行计算,计算出alpha值之后，可以对权重向量进行更新，以使得那些正确分类的样本的权重降低而错分样本的权重升高，直到错误率为0或者弱分类器的数目达到用户的指定值为止 算法过程 参考文章地址 参考文章 数据分类模型12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &quot;opencv2/core/core.hpp&quot; #include &quot;opencv2/highgui/highgui.hpp&quot; #include &quot;opencv2/imgproc/imgproc.hpp&quot; #include &quot;opencv2/ml/ml.hpp&quot; #include &lt;iostream&gt; using namespace cv; using namespace std; int main( int argc, char** argv ) &#123; //训练样本 float trainingData[42][2]=&#123; &#123;40, 55&#125;,&#123;35, 35&#125;,&#123;55, 15&#125;,&#123;45, 25&#125;,&#123;10, 10&#125;,&#123;15, 15&#125;,&#123;40, 10&#125;, &#123;30, 15&#125;,&#123;30, 50&#125;,&#123;100, 20&#125;,&#123;45, 65&#125;,&#123;20, 35&#125;,&#123;80, 20&#125;,&#123;90, 5&#125;, &#123;95, 35&#125;,&#123;80, 65&#125;,&#123;15, 55&#125;,&#123;25, 65&#125;,&#123;85, 35&#125;,&#123;85, 55&#125;,&#123;95, 70&#125;, &#123;105, 50&#125;,&#123;115, 65&#125;,&#123;110, 25&#125;,&#123;120, 45&#125;,&#123;15, 45&#125;, &#123;55, 30&#125;,&#123;60, 65&#125;,&#123;95, 60&#125;,&#123;25, 40&#125;,&#123;75, 45&#125;,&#123;105, 35&#125;,&#123;65, 10&#125;, &#123;50, 50&#125;,&#123;40, 35&#125;,&#123;70, 55&#125;,&#123;80, 30&#125;,&#123;95, 45&#125;,&#123;60, 20&#125;,&#123;70, 30&#125;, &#123;65, 45&#125;,&#123;85, 40&#125; &#125;; Mat trainingDataMat(42, 2, CV_32FC1, trainingData); //训练样本的响应值 float responses[42] = &#123;&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;, &apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;,&apos;R&apos;, &apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos;,&apos;B&apos; &#125;; Mat responsesMat(42, 1, CV_32FC1, responses); float priors[2] = &#123;1, 1&#125;; //先验概率 CvBoostParams params( CvBoost::REAL, // boost_type 10, // weak_count 0.95, // weight_trim_rate 15, // max_depth false, // use_surrogates priors // priors ); CvBoost boost; boost.train ( trainingDataMat, CV_ROW_SAMPLE, responsesMat, Mat(), Mat(), Mat(), Mat(), params ); //预测样本 float myData[2] = &#123;55, 25&#125;; Mat myDataMat(2, 1, CV_32FC1, myData); double r = boost.predict( myDataMat ); cout&lt;&lt;endl&lt;&lt;&quot;result: &quot;&lt;&lt;(char)r&lt;&lt;endl; return 0; &#125; 基于的OpenCV的检测Demo 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;opencv/highgui.h&gt;#include &lt;opencv/cv.h&gt;#include &lt;opencv2/imgproc/imgproc_c.h&gt;#include &lt;opencv2/objdetect/objdetect.hpp&gt;using namespace cv;int main(int argc, char** argv)&#123; CascadeClassifier stFaceCascade; IplImage *pstImage = NULL; std::vector&lt;Rect&gt; faceRects; if( !stFaceCascade.load(&quot;D:\\ProgramFiles\\develop\\opencv2.4.8\\sources\\data\\lbpcascades\\lbpcascade_frontalface.xml&quot;) ) &#123; printf(&quot;Loading cascade error\n&quot;); return -1; &#125; pstImage = cvLoadImage(&quot;D:\\test.jpg&quot;, CV_LOAD_IMAGE_COLOR); stFaceCascade.detectMultiScale(pstImage, faceRects, //检出结果 1.1, //缩放步长 2, //框融合时的最小检出个数 0|CV_HAAR_SCALE_IMAGE,//标志 |CV_HAAR_FIND_BIGGEST_OBJECT|CV_HAAR_DO_ROUGH_SEARCH|CV_HAAR_DO_CANNY_PRUNING Size(30, 30), //最小人脸尺寸 Size(300, 300) ); //最大人脸尺寸 printf(&quot;Face Num[%d]\n&quot;, faceRects.size()); for( unsigned int j = 0; j &lt; faceRects.size(); j++ ) &#123; cvRectangle(pstImage, cvPoint(faceRects[j].x, faceRects[j].y), cvPoint(faceRects[j].x + faceRects[j].width, faceRects[j].y + faceRects[j].height), cvScalar(0,255,0), 2,8,0); &#125; cvShowImage(&quot;FDWin&quot;, pstImage); cvWaitKey(0); cvReleaseImage(&amp;pstImage); return 0;&#125;]]></content>
      <tags>
        <tag>C++</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习_分类_SVM]]></title>
    <url>%2F2018%2F07%2F20%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E5%88%86%E7%B1%BB_SVM%2F</url>
    <content type="text"><![CDATA[机器学习_分类_SVM 支持向量机（Support Vector Machine, SVM）的基本模型是在特征空间上找到最佳的分离超平面使得训练集上正负样本间隔最大。 二分类问题的有监督学习算法，引入了核方法之后SVM也可以用来解决非线性问题一般SVM有下面三种： 1、硬间隔支持向量机（线性可分支持向量机）：当训练数据线性可分时，可通过硬间隔最大化学得一个线性可分支持向量机。2、软间隔支持向量机：当训练数据近似线性可分时，可通过软间隔最大化学得一个线性支持向量机。3、非线性支持向量机：当训练数据线性不可分时，可通过核方法以及软间隔最大化学得一个非线性支持向量机。 SVM算法认为图1中的分类器A在性能上优于分类器B，其依据是A的分类间隔比B要大 这两条平行虚线正中间的分界线就是在保持当前决策面方向不变的前提下的最优决策面。两条虚线之间的垂直距离就是这个最优决策面对应的分类间隔。 那个具有“最大间隔”的决策面就是SVM要寻找的最优解,而这个真正的最优解对应的两侧虚线所穿过的样本点，就是SVM中的支持样本点，称为支持向量。 对于图1中的数据，A决策面就是SVM寻找的最优解，而相应的三个位于虚线上的样本点在坐标系中对应的向量就叫做支持向量。 基于最大间隔分割数据优点，错误率低，计算开销不大，结果容易解释缺点，对参数调节敏感，原始分类器不加修改只能解决二类问题。 w^{t}x+b为分类函数输人数据给分类器会输出一个类别标签,单位阶跃函数）的函数对w^{t}x+b作用得到f(w^{t}x+b),其中当u&lt;0时输出-1, 反之则输出+1。这是由于-1和+1仅仅相差一个符号，方便数学上的处理。 如果数据点处于正方向（即+1类 ）并且离分隔超平面很远的位置时，w^{t}x+b会是一个很大的正数，同时label*(w^{t}x+b)也会是一个很大的正数。而如果数据点处于负方向（-1类 ）并且离分隔超平面远的位置时，此时由于类别标签为-1，则label*(w^{t}x+b)仍然是一个很大的正数。 目标：找到分类器定义中的w和b。找到具有最小间隔的数据点即支持向量。找到支持向量，对间隔最大化。 SVM的目标函数：分离超平面分类函数为0，支持向量的分类函数为+-1,为了优化目标函数，固定一个优化另外一个，该问题是一个带约束条件的优化问题。这里的约束条件就是label*(w^{t}x+b)=1。注：label*(w^{t}x+b)被称为点到分隔面的函数间隔，label*(w^{t}x+b)*(1/w)称为点到分隔面的几何间隔。求解这个问题需要经过一系列的转换。具体如下： 求$ 1/W$的最大值相当于求$0.5w^2$的最小值，一个凸二次规划问题 12345注：新目标函数约束条件：alpha&gt;=0,所有的aplha*lable=0但是数据未必100%线性可分，引人所谓松弛变量C新目标函数约束条件为：C&gt;alpha&gt;=0,所有的aplha*lable=0 SVM中的主要工作就是求解这些alpha。SMO算法(序列最小优化（SequentialMinimalOptimization ))的目标是求出一系列alpha和b，一旦求出了这些alpha，就很容易计算出权重向量w，并得到分隔超平面。 SMO的工作原理是：每次循环中选择两个alpha进行优化处理，一旦找到一对合适的alpha，那么就增大其中一个，同时减小另一个。选择的alpha要满足在间隔边界之外的条件，而且还没有进行过区间化处理或者不再边界上。 核函数：大部分时候数据并不是线性可分的，这个时候满足这样条件的超平面就根本不存在。在上文中，我们已经了解到了SVM处理线性可分的情况，那对于非线性的数据SVM咋处理呢？对于非线性的情况，SVM 的处理方法是选择一个核函数，通过将数据映射到高维空间，来解决在原始空间中线性不可分的问题。 这是原始数据和原始空间，明显有红蓝两类：通过核函数，将样本数据映射到更高维的空间（在这里，是二维映射到三维）：而后进行分离超平面：再将分割的超平面映射回去：效果图： 核函数的选择变成了支持向量机的最大变数（如果必须得用上核函数，即核化），因此选用什么样的核函数会影响最后的结果。而最常用的核函数有：线性核、多项式核、高斯核、拉普拉斯核、sigmoid核、通过核函数之间的线性组合或直积等运算得出的新核函数。 Opencv代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;opencv2/core/core.hpp&gt; #include &lt;opencv2/highgui/highgui.hpp&gt; #include &lt;opencv2/ml/ml.hpp&gt; using namespace cv; int main() &#123; // Data for visual representation int width = 512, height = 512; Mat image = Mat::zeros(height, width, CV_8UC3); // Set up training data float labels[5] = &#123;1.0, -1.0, -1.0, -1.0,1.0&#125;; Mat labelsMat(5, 1, CV_32FC1, labels); float trainingData[5][2] = &#123; &#123;501, 10&#125;, &#123;255, 10&#125;, &#123;501, 255&#125;, &#123;10, 501&#125;,&#123;501,128&#125; &#125;; Mat trainingDataMat(5, 2, CV_32FC1, trainingData); //设置支持向量机的参数 CvSVMParams params; params.svm_type = CvSVM::C_SVC;//SVM类型：使用C支持向量机 params.kernel_type = CvSVM::LINEAR;//核函数类型：线性 params.term_crit = cvTermCriteria(CV_TERMCRIT_ITER, 100, 1e-6);//终止准则函数：当迭代次数达到最大值时终止 //训练SVM //建立一个SVM类的实例 CvSVM SVM; //训练模型，参数为：输入数据、响应、XX、XX、参数（前面设置过） SVM.train(trainingDataMat, labelsMat, Mat(), Mat(), params); Vec3b green(0,255,0), blue (255,0,0); //显示判决域 for (int i = 0; i &lt; image.rows; ++i) for (int j = 0; j &lt; image.cols; ++j) &#123; Mat sampleMat = (Mat_&lt;float&gt;(1,2) &lt;&lt; i,j); //predict是用来预测的，参数为：样本、返回值类型（如果值为ture而且是一个2类问题则返回判决函数值，否则返回类标签）、 float response = SVM.predict(sampleMat); if (response == 1) image.at&lt;Vec3b&gt;(j, i) = green; else if (response == -1) image.at&lt;Vec3b&gt;(j, i) = blue; &#125; //画出训练数据 int thickness = -1; int lineType = 8; circle( image, Point(501, 10), 5, Scalar( 0, 0, 0), thickness, lineType);//画圆 circle( image, Point(255, 10), 5, Scalar(255, 255, 255), thickness, lineType); circle( image, Point(501, 255), 5, Scalar(255, 255, 255), thickness, lineType); circle( image, Point( 10, 501), 5, Scalar(255, 255, 255), thickness, lineType); circle(image, Point( 501, 128), 5, Scalar(0, 0, 0), thickness, lineType); //显示支持向量 thickness = 2; lineType = 8; //获取支持向量的个数 int c = SVM.get_support_vector_count(); for (int i = 0; i &lt; c; ++i) &#123; //获取第i个支持向量 const float* v = SVM.get_support_vector(i); //支持向量用到的样本点，用灰色进行标注 circle( image, Point( (int) v[0], (int) v[1]), 6, Scalar(128, 128, 128), thickness, lineType); &#125; imwrite(&quot;result.png&quot;, image); // save the image imshow(&quot;SVM Simple Example&quot;, image); // show it to the user waitKey(0); &#125;]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Opencv图像分割]]></title>
    <url>%2F2018%2F07%2F19%2Fopencv_imgseg%2F</url>
    <content type="text"><![CDATA[Opencv图像分割 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/* * * 功能：通过灰度图做简单的图像分割,再使用findContours去掉多余的轮廓 * */ #include &lt;vector&gt; #include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt; using namespace cv;using namespace std; void contours(); int main()&#123; contours();&#125; void contours()&#123; //--1.读入图片 Mat image = imread(&quot;horse_hw.jpg&quot;); Mat gray;//mat类型数据存放图片，opencv特有 cvtColor(image,gray,CV_RGB2GRAY); Mat binary; threshold(gray,binary,60,255,THRESH_BINARY_INV); vector&lt;vector&lt;Point&gt; &gt; contours; Mat binary_copy; //因为findcontours函数会改变输入的图像，所以复制一个图像作为函数的输入 binary.copyTo(binary_copy); findContours(binary_copy,contours,CV_RETR_EXTERNAL/*获取外轮廓*/,CV_CHAIN_APPROX_NONE/*获取每个轮廓的每个像素*/); //遍历每一个轮廓，把多余的轮廓去掉 vector&lt;vector&lt;Point&gt; &gt;::const_iterator it=contours.begin(); while(it!=contours.end()) &#123; if(it-&gt;size()&lt;500) it = contours.erase(it); else ++it; &#125; Mat dst(image.size(),CV_8U,Scalar(0)); drawContours(dst,contours,-1/*绘制所有轮廓*/,Scalar(255)/*绘制为白色*/,CV_FILLED/*轮廓全部填充*/); //--4.显示结果(原图和结果图显示在一起) const int width = image.cols; const int height = image.rows; Mat show_image(Size(3*width,height),CV_8UC3); //将image拷贝到显示图片指定位置 image.copyTo(show_image(Rect(0,0,width,height))); //将binary,dst转换为3通道，使得show_image和dst通道数一致，或者使用convertTo()函数做操作 cvtColor(binary,binary,CV_GRAY2RGB); cvtColor(dst,dst,CV_GRAY2RGB); //将binary,dst拷贝image指定位置 binary.copyTo(show_image(Rect(width,0,width,height))); dst.copyTo(show_image(Rect(2*width,0,width,height))); //显示 imshow(&quot;show&quot;,show_image); waitKey(0);&#125;]]></content>
      <tags>
        <tag>Opencv</tag>
        <tag>图像处理</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-正则化-L1L2]]></title>
    <url>%2F2018%2F07%2F19%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%AD%A3%E5%88%99%E5%8C%96-L1L2%2F</url>
    <content type="text"><![CDATA[机器学习-正则化-L1L2 样本数据量大：经验⻛风险最⼩小化 样本数据量小：结构⻛风险最⼩小化==正则化 经验风险最⼩小化（empirical risk minimization）认为经验⻛风险最⼩小的模型是最优的模型，即求解最优化问题 minf ∈ F(1/N)\sum_{i=1}^NL(y_i,f(x_i))样本容量量⾜足够⼤大的时候，经验⻛风险最⼩小化学习效果良好 结构⻛风险=经验⻛风险+模型复杂度的正则化项（regularizer）或罚项（penalty term） minf ∈ F(1/N)\sum_{i=1}^NL(y_i,f(x_i))+\lambda{J(f)}$J(f)$是模型的复杂度，模型$f$越复杂，复杂度$J(f)$越大。$\lambda ≥ 0$是系数，⽤用以权衡经验⻛风险和模型复杂度。 结构风险⼩需要1、经验风险和2、模型复杂度同时⼩ 范数因为非负性：可以做损失函数，正则项 损失函数通常是⼀个有下确界的函数 常用范数：L0 L1:绝对值 ||x||=\sum_{i=1}^{d}{|x_i|}L2；平方再开根号 ||x||_2=(\sum_{i=1}^{d}{|x_i^2|})^{1/2}Lp ||x||_2=(\sum_{i=1}^{d}{|x_i^p|})^{1/p}p=1,曼哈顿距离，L1范数，表示某个向量量中所有元素绝对值的和p=2,欧式距离，L2范数 使用L1正则项，倾向于使参数稀疏化，使用L2正则项，使参数稠密的接近于0。L1正则是菱形，参数的交点都落在坐标轴上，实现稀疏化。L2是圆形， 正则项是为了降低模型的复杂度，从而避免模型区过分拟合训练数据，包括噪声与异常点（outliers）。从另一个角度上来讲，正则化即是假设模型参数服从先验概率，即为模型参数添加先验，只是不同的正则化方式的先验分布是不一样的。这样就规定了参数的分布，使得模型的复杂度降低（试想一下，限定条件多了，是不是模型的复杂度降低了呢），这样模型对于噪声与异常点的抗干扰性的能力增强，从而提高模型的泛化能力。还有个解释便是，从贝叶斯学派来看：加了先验，在数据少的时候，先验知识可以防止过拟合；从频率学派来看：正则项限定了参数的取值，从而提高了模型的稳定性，而稳定性强的模型不会过拟合，即控制模型空间。]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构_二叉树]]></title>
    <url>%2F2018%2F07%2F19%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84_%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[数据结构_二叉树 树的遍历顺序大体分为三种：前序遍历（先根遍历、先序遍历），中序遍历（中根遍历），后序遍历（后根遍历） 123456二叉树： A / \ B C /\ / D E F 前序遍历前序遍历可以记为根左右。前序遍历的规则：123（1）访问根节点（2）前序遍历左子树（3）前序遍历右子树 前序遍历的输出结果：ABDECF 中序遍历中序遍历可以记为左根右中序遍历的规则：123（1）中序遍历左子树（2）访问根节点（3）中序遍历右子树 中序遍历的输出结果：DBEAFC 后序遍历后序遍历可以记为左右根后序遍历二叉树的规则：123（1）后序遍历左子树（2）后序遍历右子树（3）访问根节点 后序遍历的输出顺序：DEBFCA]]></content>
      <tags>
        <tag>数据结构</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大佬终极面经]]></title>
    <url>%2F2018%2F07%2F19%2F%E5%A4%A7%E4%BD%AC%E7%BB%88%E6%9E%81%E9%9D%A2%E7%BB%8F%2F</url>
    <content type="text"><![CDATA[大佬终极面经 作者：非理性的猫链接：https://www.nowcoder.com/discuss/92930来源：牛客网 去年秋招在准备求职算法岗的过程中，经过一整个秋招的努力，拿了蚂蚁金服、滴滴、宜信大数据、美图几个厂的算法offer，这中间我参考了牛客网很多大神的经验，自己总结了一些经验，写成这篇文章。 一个完整的机器学习工程师的面试过程主要有以下这些环节：自我介绍、项目介绍、算法推导和解释、数据结构与算法题（写代码）。 关于自我介绍，主要就是简单介绍下自己的教育背景，在校期间的研究方向和所做的项目以及在项目中所充当的角色等等，为之后的面试做个铺垫，让面试官从中捕捉点来问。 项目介绍是最为重要的，这也是体现你综合实力的地方，对项目背景、项目实现的方案，项目所实现的东西都要了如指掌，做机器学习的，必然需要准备一到两个重点的机器学习项目，可以是比赛，也可以是实验室项目，关键是项目中间的技术细节都要了如指掌，比如你用了树模型，就得知道所有树模型相关的推导和原理，决不能含糊，一旦你说不太清楚，面试官就会对项目的真实性存疑。参加比赛应该是没有实验室项目的同学最佳的积累经验的途径，比较好的比赛平台有Kaggle、天池大数据、datacastle等 接下来就是机器学习算法原理和推导，这也是要重点去准备的，在面试前得达到，给你一张白纸，你可以把推导的每一步写的清清楚楚的，推导的话面试常考逻辑回归和SVM的推导，关于原理面试官常会问你几个树模型之间的对比等等等，其他的算法比如LR、SVM、EM、Adaboost、PageRank、 FFM、决策树，随机森林， GBDT ， XGBoost 、推荐算法、聚类、CNN、RNN、LSTM、Word2Vec等等，以及他们的适用场景，再如一些机器学习的理论，非平衡问题、过拟合问题，交叉验证问题，模型选择问题，模型融合问题。这一部分我会在文末贴出一个问题集锦，大家按照这个去准备就行。还有必看的书李航的《统计学习方法》、周志华的《机器学习》、项亮的《推荐系统实践》 最后就是写代码了，很多非计算机出身的大都会栽在这个地方，代码写得少，训练不到位，就会导致当场思路不清晰，不知从哪写起，但目前市面上已经有很多专门为这块总结的一些书籍，推荐使用《剑指offer》、《王道程序员求职宝典》等等，有时间的话再刷一下leetcode。排序算法、查找算法、二叉树遍历这些最基本的一定要很顺溜的写下来，其他的就看自己去拓展了，同样的，我也总结了一些笔记供大家参考， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135机器学习机器学习算法系列（40）：机器学习中的数据清洗与特征处理综述机器学习算法系列（39）：实例详解机器学习如何解决问题机器学习算法系列（38）：外卖订单量预测异常报警模型实践机器学习算法系列（37）：外卖O2O的用户画像实践机器学习算法系列（36）：GBDT算法原理深入解析机器学习算法系列（35）：使用Sklearn进行集成学习（实践）机器学习算法系列（34）：使用Sklearn进行集成学习（理论）机器学习算法系列（33）：特征处理（Feature Processing）机器学习算法系列（32）：MapReduce执行流程详解机器学习算法系列（31）：在线最优化求解（online Optimization）机器学习算法系列（30）：Scikit-Learn总结机器学习算法系列（29）：Sparsity and Some Basics of L1 Regularization机器学习算法系列（28）：L1、L2正则化机器学习算法系列（27）：Isolation Forest机器学习算法系列（26）：因子分解机（FM）与场感知分解机（FFM）机器学习算法系列（24）：机器学习中的损失函数机器学习算法系列（25）：最速下降法、牛顿法、拟牛顿法机器学习算法系列（23）：TF-IDF与余弦相似度机器学习算法系列（22）：主成分分析机器学习算法系列（21）：SVD机器学习算法系列（20）：机器学习模型优化四要素机器学习算法系列（19）：机器学习性能评价指标机器学习算法系列（18）：方差偏差权衡（Bias-Variance Tradeoff）机器学习算法系列（17）：非平衡数据处理机器学习算法系列（16）：统计学习概论机器学习算法系列（15）：EM算法机器学习算法系列（14）：关联分析机器学习算法系列（13）：推荐系统（3）—矩阵分解技术机器学习算法系列（13）：推荐系统（2）—基于领域的协同过滤机器学习算法系列（13）：推荐系统（1）—简介机器学习算法系列（12）：SVM（4）—SMO机器学习算法系列（12）：SVM（3）—非线性支持向量机机器学习算法系列（12）：SVM（2）—线性支持向量机机器学习算法系列（12）：SVM（1）—线性可分支持向量机机器学习算法系列（11）：聚类（4）—密度最大值聚类机器学习算法系列（11）：聚类（3）—DBSCAN机器学习算法系列（11）：聚类（2）—Kmeans机器学习算法系列（11）：聚类（1）—简介机器学习算法系列（10）：朴素贝叶斯机器学习算法系列（9）：感知机机器学习算法系列（8）：XgBoost机器学习算法系列（7）：GBDT机器学习算法系列（6）：AdaBoost机器学习算法系列（5）：随机森林机器学习算法系列（4）：决策树机器学习算法系列（3）：逻辑斯谛回归机器学习算法系列（2）：线性回归机器学习算法系列（1）：K近邻自然语言处理自然语言处理系列（10）：自然语言处理的发展与趋势自然语言处理系列（9）：DCNN自然语言处理系列（8）：RCNN自然语言处理系列（7）：TextCNN调参技巧自然语言处理系列（6）：TextCNN自然语言处理系列（5）：FastText自然语言处理系列（4）：深度学习解决大规模文本分类问题自然语言处理系列（3）：中文维基语料词向量训练自然语言处理系列（2）：Word2Vec自然语言处理系列（1）：词向量和语言模型深度学习深度学习系列（12）：pytorch实现卷积神经网络深度学习系列（11）：神经网络防止过拟合的方法深度学习系列（10）：DMC—卷积神经网络分享深度学习系列（9）：Batch Normalization深度学习系列（8）：激活函数深度学习系列（7）：神经网络的优化方法深度学习系列（6）：递归神经网络深度学习系列（5）：长短时记忆网络（LSTM）深度学习系列（4）：循环神经网络（RNN）深度学习系列（3）：卷积神经网络（CNN）深度学习系列（2）：神经网络MNIST实战深度学习系列（1）：神经网络与反向传播算法数据结构与算法数据结构与算法题解（11）：最长回文子串数据结构与算法题解（10）：0-1背包问题与部分背包问题数据结构与算法题解（9）：最长公共子序列和最长公共子串数据结构与算法题解（8）：KMP算法数据结构与算法题解（7）：最短编辑距离数据结构与算法题解（6）：重点掌握数据结构与算法题解（5）：剑指offer解题报告数据结构与算法题解（4）：二叉树题解数据结构与算法题解（3）：字符串题解数据结构与算法题解（2）：数组题解数据结构与算法题解（1）：链表题解数据结构与算法（19）：海量数据处理数据结构与算法（18）：倒排索引数据结构与算法（17）：simhash数据结构与算法（16）：一致性哈希数据结构与算法（15）：布隆过滤器数据结构与算法（14）：最短路算法数据结构与算法（13）：深度优先搜索和广度优先搜索数据结构与算法（12）：排序数据结构与算法（11）：哈希表数据结构与算法（10）：查找数据结构与算法（9）：Trie树数据结构与算法（8）：红黑树数据结构与算法（7）：数据库索引原理及优化数据结构与算法（6）：B树、B+树数据结构与算法（5）：AVL树数据结构与算法（4）：二叉查找树数据结构与算法（3）：二叉树数据结构与算法（2）：栈与队列数据结构与算法（1）：数组与链表JavaJava学习笔记（12）：单例模式Java学习笔记（11）：进程与线程Java学习笔记（10）：QAJava学习笔记（9）：内部类、抽象类、接口Java学习笔记（8）：常用库类、向量与哈希Java学习笔记（7）：深入理解java异常处理机制Java学习笔记（6）：异常处理Java学习笔记（5）：static、final关键字和Object类Java学习笔记（4）：多态Java学习笔记（3）：继承、覆盖、重载Java学习笔记（2）：类与对象Java学习笔记（1）：语法基础Java集合学习手册（11）：Java HashMap源码全剖析Java集合学习手册（10）：hashCode方法与equal方法Java集合学习手册（9）：Java 集合对比Java集合学习手册（8）：Java 集合框架Java集合学习手册（7）：Java LinkedListJava集合学习手册（6）：Java ArrayListJava集合学习手册（5）：Java LinkedHashSetJava集合学习手册（4）：Java LinkedHashMapJava集合学习手册（3）：Java HashTableJava集合学习手册（2）：Java HashSetJava集合学习手册（1）：Java HashMap 以下是我总结的机器学习提问集锦，大家可以在把所有算法过了一遍的基础上把一个个问题都仔细揣摩一遍，加强对算法的理解和延伸。 SVM：12345678910111213简单介绍SVM（详细原理）：从分类平面，到求两类间的最大间隔，到转化为求间隔分之一，等优化问题，然后就是优化问题的解决办法，首先是用拉格拉日乘子把约束优化转化为无约束优化，对各个变量求导令其为零，得到的式子带入拉格朗日式子从而转化为对偶问题， 最后再利用SMO（序列最小优化）来解决这个对偶问题。svm里面的c有啥用SVM的推导，解释原问题和对偶问题，SVM原问题和对偶问题的关系，KKT限制条件，KKT条件用哪些，完整描述；软间隔问题，解释支持向量、核函数（哪个地方引入、画图解释高维映射，高斯核可以升到多少维，如何选择核函数），引入拉格朗日的优化方法的原因，最大的特点，损失函数解释，SVM与LR最大区别，LR和SVM对于outlier的敏感程度分析，逻辑回归与SVM的区别为什么要把原问题转换为对偶问题？因为原问题是凸二次规划问题，转换为对偶问题更加高效。为什么求解对偶问题更加高效？因为只用求解alpha系数，而alpha系数只有支持向量才非0，其他全部为0.alpha系数有多少个？样本点的个数加大训练数据量一定能提高SVM准确率吗？与感知器的联系和优缺点比较如何解决多分类问题、可以做回归吗，怎么做它与其他分类器对比的优缺点，它的速度机器学习有很多关于核函数的说法，核函数的定义和作用是什么？https://www.zhihu.com/question/24627666支持向量机(SVM)是否适合大规模数据？https://www.zhihu.com/question/19591450SVM和逻辑斯特回归对同一样本A进行训练，如果某类中增加一些数据点，那么原来的决策边界分别会怎么变化？https://www.zhihu.com/question/30123068各种机器学习的应用场景分别是什么？例如，k近邻,贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。https://www.zhihu.com/question/26726794Linear SVM 和 LR 有什么异同？https://www.zhihu.com/question/26768865 LR12345678910111213141516LR推导（伯努利过程，极大似然，损失函数，梯度下降）有没有最优解？LR可以用核么？可以怎么用？l1和l2正则项是啥？lr加l1还是l2好？加哪个可以用核（加l2正则项，和svm类似，加l2正则项可以用核方便处理）LR可以用来处理非线性问题么？（还是lr啊 只不过是加了核的lr 这里加核是显式地把特征映射到高维 然后再做lr）怎么做？可以像SVM那样么？为什么？为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好，为什么把特征组合之后还能提升，反正这些基本都是增强了特征的表达能力，或者说更容易线性可分吧美团技术团队《Logistic Regression 模型简介》https://tech.meituan.com/intro_to_logistic_regression.htmlSVM和logistic回归分别在什么情况下使用？https://www.zhihu.com/question/21704547逻辑斯蒂回归能否解决非线性分类问题？https://www.zhihu.com/question/29385169为什么LR可以用来做CTR预估？https://www.zhihu.com/question/23652394逻辑回归估计参数时的目标函数 （就是极大似然估计那部分），逻辑回归估计参数时的目标函数 （呵呵，第二次） 逻辑回归估计参数时的目标函数 如果加上一个先验的服从高斯分布的假设，会是什么样（天啦。我不知道，其实就是在后面乘一个东西，取log后就变成加一个东西，实际就变成一个正则项）逻辑回归估计参数时的目标函数逻辑回归的值表示概率吗？（值越大可能性越高，但不能说是概率）手推逻辑回归目标函数，正类是1，反类是-1，这里挖了个小坑，一般都是正例是1，反例是0的，他写的时候我就注意到这个坑了，然而写的太快又给忘了，衰，后来他提醒了一下，改了过来，就是极大似然函数的指数不一样，然后说我这里的面试就到这了。看没看过scikit-learn源码LR的实现？（回头看了一下是调用的liblinear，囧）为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好，为什么把特征组合之后还能提升，反正这些基本都是增强了特征的表达能力，或者说更容易线性可分吧naive bayes和logistic regression的区别http://m.blog.csdn.net/blog/muye5/19409615LR为什么用sigmoid函数。这个函数有什么优点和缺点？为什么不用其他函数？sigmoid函数由那个指数族分布，加上二项分布导出来的。损失函数是由最大似然估计求出的。了解其他的分类模型吗，问LR缺点，LR怎么推导（当时我真没准备好，写不出来）写LR目标函数，目标函数怎么求最优解（也不会）讲讲LR的梯度下降，梯度下降有哪几种，逻辑函数是啥 L1和L212345678910111213L2正则化，为什么L2正则化可以防止过拟合？L1正则化是啥？深度学习里面怎么防止过拟合？（data aug；dropout；multi-task learning）如何防止过拟合，我跟他列举了4中主要防止过拟合方法：Early Stopping、数据集扩充、正则化法以及dropout，还详细跟他说了每种方法原理及使用的场景，并解释我在哪些项目里具体用到了这些方法，机器学习中使用「正则化来防止过拟合」到底是一个什么原理？为什么正则化项就可以防止过拟合？https://www.zhihu.com/question/20700829机器学习中常常提到的正则化到底是什么意思？https://www.zhihu.com/question/20924039什么是正则项，L1范式，L2范式区别是什么，各自用在什么地方？L1 与 L2 的区别以及如何解决 L1 求导困难；L1正则为什么能让系数变为0？L1正则怎么处理0点不可导的情形？（这个谁会？近端梯度下降）L0，L1，L2正则化(如果能推导绝对是加分项，一般人最多能画个等高线，L0是NP问题)其实上面的这些问题基本都能在《李航：统计学习方法》《周志华：机器学习》里面找到，能翻个4，5遍基本就无压力了避免过拟合策略、如何提高模型泛化能力、L1与L2正则区别，优缺点、生成式，判别式模型、深度学习这块了解多少、如何克服过拟合，欠拟合L1 与 L2 的区别以及如何解决 L1 求导困难；L1正则为什么可以把系数压缩成0，坐标下降法的具体实现细节为什么L1正则可以实现参数稀疏，而L2正则不可以？为什么L1很多系数可以被压缩为0，L2是被压缩至接近于0？树模型 决策树：1234567891011121314151617181920212223242526rf ， gbdt 的区别； gbdt ， xgboost 的区别（烂大街的问题最好从底层原理去分析回答）介绍决策树，谈了3种决策树及其区别和适应场景决策树处理连续值的方法；简单介绍决策树几种算法，有什么区别？决策树基本模型介绍？决策树算法中缺失值怎么处理？决策树算法在应用中有什么值得注意的地方。SVM、LR、决策树的对比？GBDT 和 决策森林 的区别？决策树的特性？（3 ）决策树处理连续值的方法；解释下随机森林和gbdt的区别。gbdt的boosting体现在哪里。解释下随机森林节点的分裂策略，以及它和gbdt做分类有什么区别？哪个效果更好些？为什么？哪个更容易过拟合？为什么？ 问了随机森林的损失函数，和lr的优缺点对比， adaboost和随机森林的比较，为了防止随机森林过拟合可以怎么做，是否用过随机森林，怎么用的。随机森林和GBDT的区别？CART（回归树用平方误差最小化准则，分类树用基尼指数最小化准则）GBDT（利用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值，拟合一个回归树）随机森林（Bagging+CART）SVM与随机森林比较改变随机森林的训练样本数据量，是否会影响到随机森林学习到的模型的复杂度Logistics与随机森林比较GBDT与随机森林比较随机森林的学习过程；随机森林中的每一棵树是如何学习的；随机森林学习算法中CART树的基尼指数是什么？RF 与 GBDT 区别，原理优缺点适用场景分析，哪个具备交叉验证功能等接着写一下信息增益的公式。之后就是问机器学习相关算法，说了一下bagging跟boosting，之后问了GBDT（没做过，只能说说大体思路）。（2 ） rf ， gbdt 的区别； gbdt ， xgboost 的区别；说说xgboost、gbdt区别、Tree-based Model如何处理连续型特征。让我把一个完整的数据挖掘流程讲一下，从预处理，特征工程，到模型融合。介绍常用的算法，gbdt和xgboost区别，具体怎么做预处理，特征工程，模型融合常用方式，融合一定会提升吗？gbdt树根据什么分裂（瞎扯的梯度近似残差、梯度下降方向，其实还是信息增益这种东西）gbdt怎么并发（特征选择层面，树层面不能并发）介绍LR、RF、GBDT ，分析它们的优缺点，是否写过它们的分布式代码XGB和GBDT区别与联系也会经常问到：https://www.zhihu.com/question/41354392/answer/128008021?group_id=773629156532445184CART（回归树用平方误差最小化准则，分类树用基尼指数最小化准则）、Logistics（推导）、GBDT（利用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值，拟合一个回归树）在面试过程中主动引导面试官提问，比如面试官让你讲解 gbdt 原理时，这会你可以跟他说，一般说起 gbdt ，我们都会跟 rf 以及 xgboost 一块讲，然后你就可以主动地向面试官输出你的知识；面试并不是死板地你问我答，而是一种沟通交流，所以尽可能地把面试转化成聊天式的对话，多输出自己一些有价值的观点而不是仅仅为了回答面试官的问题；几种树模型的原理和对比，特征选取怎么选？ 为什么信息增益可以用来选特征？信息熵和基尼指数的关系(信息熵在x=1处一阶泰勒展开就是基尼指数)介绍xgboost一下。写下xgboost目标函数。（因为我提到xgboost在目标函数里显式地加入了正则项..血雪崩）怎么调整XGB参数；xgboost原理 K-means1234567891011k-means 聚类的原理以及缺点及对应的改进；kmeans 算法的优缺点。。。。kmeans 的原理，优缺点以及改进；em 与 kmeans 的关系；kmeans 代码；说说 Kmeans 算法， Kmeans 算法 K 怎么设置、适用什么样数据集、怎么评价 Kmeans 聚类结果、 Kmeans 有什么优缺点？你的项目中使用 Kmeans 遇到哪些问题，怎么解决的 ?用 EM 算法推导解释 Kmeans。KMeans的算法伪代码如何判断自己实现的 LR、Kmeans 算法是否正确？如何优化kmeans算法如何用hadoop实现k-means手写k-means的伪代码（就6行） 集成学习123456bagging和boosting是怎么做的和他们的比较详细讨论了样本采样和bagging的问题聊的比较多的是如何知道一个特征的重要性，如何做ensemble哪些方法比较好。聊了聊计算广告方面FM，embedding。常见融合框架原理，优缺点，bagging，stacking，boosting，为什么融合能提升效果是否了解线性加权、bagging、boosting、cascade等模型融合方式K-means起始点http://www.cnki.com.cn/Article/CJFDTotal-DNZS200832067.htm 贝叶斯12345朴素贝叶斯分类器原理以及公式，出现估计概率值为 0 怎么处理（拉普拉斯平滑），缺点；解释贝叶斯公式和朴素贝叶斯分类。贝叶斯分类，这是一类分类方法，主要代表是朴素贝叶斯，朴素贝叶斯的原理，重点在假设各个属性类条件独立。然后能根据贝叶斯公式具体推导。考察给你一个问题，如何利用朴素贝叶斯分类去分类，比如：给你一个人的特征，判断是男是女，比如身高，体重，头发长度等特征的的数据，那么你要能推到这个过程。给出最后的分类器公式。那你说说贝叶斯怎么分类啊？比如说看看今天天气怎么样？我：blabla，，，利用天气的历史数据，可以知道天气类型的先验分布，以及每种类型下特征数据（比如天气数据的特征：温度啊，湿度啊）的条件分布，这样我们根据贝叶斯公式就能求得天气类型的后验分布了。。。。面试官：en（估计也比较满意吧）那你了解关于求解模型的优化方法吗？一般用什么优化方法来解？贝叶斯分类器的优化和特殊情况的处理 深度学习12345678910111213141516解释一下CNN、介绍CNN、卷积公式，以及特点，假设面试官什么都不懂，详细解释 CNN 的原理；问CNN的细节特点，哪些特点使得CNN这么好用，哪些场景用CNN可以，抽象一下这些场景的特征，可以降采样但仍能保持主要信息；局部连接可以保证获取局部信息；权值共享保证高效，DNN和CNN相比有哪些区别，用过RNN么？画一下RNN的图，你在深度学习过程中遇到过哪些问题？如果出现过拟合你怎么办？dropout是什么？它有什么用？你会怎么用它？当全连接跟dropout连着用需要注意什么？你之前过拟合怎么解决的？如果本身training loss就很大你怎么办？如果数据不变，怎么调整网络结构解决这个问题？（batch normalization）梯度消失知道么？为什么会出现梯度消失？dnn和rnn中的梯度消失原理一样么？dnn中是哪个部分导致梯度消失？（激活层如sigmoid）rnn中怎么解决梯度消失问题？（lstm的结构相对普通RNN多了加和，为避免梯度消散提供了可能。线性自连接的memory是关键。）讲一下CNN吧，有哪些重要的特点？CNN可以处理哪些场景？为什么CNN要用权值共享？（每个卷积核相当于一个特征提取器，它的任务是匹配局部图像中的特征，权值共享后，匹配的特征方式都是一样的，提取若干特征后就知道学习的是啥了）CNN里面哪些层？讲一下卷积。卷积的形式是啥样？给定一个输入，算输出的feature map大小。卷积有啥用？池化有啥用？有哪些池化方式？池化除了降采样还有啥用？（就不知道了）还有哪些层你用过？讲讲dropout。dropout内部是怎么实现只让部分信号通过并不更新其余部分对于输入的权值的？讲讲BN（BatchNormalization）为什么好？全连接有什么用处？知道RNN么？讲讲RNN大致的实现思路。知道梯度消失么？为什么会出现梯度消失？RNN里的梯度消失一般怎么处理？细讲下lstm的结构，这样设计为什么好？（门关闭，当前信息不需要，只有历史依赖；门打开，历史和当前加权平均）你觉得梯度消失靠引入一些新的激活层可以完全解决么？为什么？问了做的比赛里面使用tensorflow的细节，LSTM里调参的细节用过哪些库或者工具，mkl，cuda这些会用吗？有一个弱分类器和大量未被标记过的图像数据，如何人工标记图像来对分类器进行提升介绍下RNN和它的优缺点让我推导BP反向传播、随机梯度下降法权重更新公式卷积神经网络结构特点、各参数对模型结果影响、项目进展遇到的难题、推导BP神经网络参数更新方式、随机梯度下降法（SGD）优化函数存在的缺点以及拟牛顿法在优化函数使用上更有优势、修改Caffe开源框架、开源社区代码贡献量就跟我聊了很多行业发展趋势及问题，知道目前深度学习的一个趋势，也了解到最新行业发展动态，改进相机智能化程度，也聊到了美颜相机美颜效果以及小米相机人脸分类、年龄检测等等不足之处，了解到新兴行业大佬商汤科技和旷视科技（face++脸草）在研究的热门方向看到有deep learning相关的项目，就问了deep learning 相关问题：如何减少参数（权值共享、VGG的感受野、GoogLeNet的inception ），激活函数的选择（sigmoid-&gt;ReLu-&gt;LReLU-&gt;PReLU ），为什么之前没有深度网络出现（数据量不够+机器性能），由数据引申到数据不平衡怎么处理（10W正例，1W负例，牛客上有原题），后面问了下DNN原理，应用，瞎扯一通……你了解神经网络吗？我：了解一些，讲感知机，然后是BP网络。简单讲了一下原理。图像处理题：如何找相似图片。我说用感知哈希算法，计算汉明距离，他说这种方法精度不行；我说那就用SIFT算法吧，他说SIFT效果还可以，但计算有点繁重，有没有轻量级的方法？我想起来去年在美图秀秀实习时，曾经做过一种图像滤波算法，有一步是把像素点用K-means聚类。我就说先把图片灰度化，然后用K-means聚类，把聚类后的各个中心点作为一张图片的特征向量如果两张图片的特征向量相近则说明这两张图片相似。貌似我这个答案有点出乎他的意料，他意味深长地说了个“行吧~~~~”（个人觉得颜色直方图匹配是个他期待的常规回答）介绍卷积神经网络，和 DBN 有什么区别？Deep CNN, Deep RNN, RBM的典型应用与局限，看Hinton讲义和Paper去吧神经网络,plsi的推导验证码图片的去噪和提取字符有限状态自动机,然后要我画状态转移图. 聚类12用过哪些聚类算法，解释密度聚类算法。聚类算法中的距离度量有哪些？ 优化12345678梯度下降的优缺点；主要问最优化方面的知识，梯度下降法的原理以及各个变种（批量梯度下降，随机梯度下降法， mini 梯度下降法），以及这几个方法会不会有局部最优问题，牛顿法原理和适用场景，有什么缺点，如何改进（拟牛顿法）常用优化算法：1.梯度下降法：又有随机梯度下降和负梯度下降，2.牛顿法 主要是问了各自的优缺点，速度，能不能得到全局最优解，牛顿法的二次收敛等问你如果有若干个极小值点，如何避免陷入局部最优解。它们间的牛顿学习法、SGD如何训练，如何判断函数凸或非凸？线性回归的梯度下降和牛顿法求解公式的推导最速下降法和共轭梯度法 wolfe条件 最速下降法和共轭梯度法的收敛速度如何判断深刻理解常用的优化方法：梯度下降、牛顿法、各种随机搜索算法（基因、蚁群等等），深刻理解的意思是你要知道梯度下降是用平面来逼近局部，牛顿法是用曲面逼近局部等等。 推荐系统12345678910介绍SVD、SVD++推荐系统的冷启动问题如何解决深度学习在推荐系统上可能有怎样的发挥？推荐系统的算法中最近邻和矩阵分解各自适用场景白板写SVD/SVD++公式，SGD迭代更新p，q矩阵公式，SVD/SVD++优化方法对推荐算法的未来看法；用过什么算法？最好是在项目/实习的大数据场景里用过，比如推荐里用过 CF、LR，我面的推荐，问了各类协同过滤的好与坏。问了一个很有意思的问题，现实应用中的Top-N推荐问题和学术研究中的评分预测问题之间有什么不同。问我ItemCF的工程实现，面对大数据如何实现，又追问了有没有什么工程优化算法。这个问题我没答好，一开始我说了一个MapReduce模型，他问能不能更快一点，我就卡那了。。。最后面试官告诉我，不能只从算法角度分析，要从系统设计分析，利用内存来减小MapReduce的吞吐量。（当然也许从MapReduce那一刻开始我就输了也不一定）推荐系统的算法中最近邻和矩阵分解各自适用场景http://www.doc88.com/p-3961053026557.html PCA12那你对pca了解吗？我：了解啊，面试官：那讲一下pca是用来干嘛的？我：pca啊，可以用来分析主方向啊，降维啊，特征筛选啊，具体方法是用svd分解得到特征值矩阵和特征向量矩阵，然后根据不同的任务对选择特征值或向量进行计算。 EM1采用 EM 算法求解的模型有哪些，为什么不用牛顿法或梯度下降法？ NLP12345用过哪些 NLP 算法项目中用过哪些机器学习算法。海量的 item 算文本相似度的优化方法；解释 word2vec 的原理以及哈夫曼树的改进；word2vec的原理二面面试官主要跟我聊简历上的几个项目，他好像不能理解词向量的形式，反复解释了很多遍，问的问题都比较简单，有TF-IDF,余弦相似度，分词工具等等。然后我说我做过LDA，问我，Dirichlet Distribution的定义和性质，并问我，为什么它和multinomial distribution是共轭的，顺便问了我啥叫共轭分布。 关联分析：1项目中涉及到频繁模式挖掘，于是问了一下如何实现的？ 用的是 Apriori算法，描述他的原理过程，关键字眼：支持度，支持度计数，k项候选频繁项集，怎么从k项到k+1项等，连接剪枝过程。 hadoop12345678简单介绍 MapReduce 原理，有没有看过源码，说说 Map 阶段怎么实现的,MapReduce 实现统计出现次数最多的前 100 个访问 IP.MapReduce 实现统计不重复用户 ID,MapReduce 实现两个数据集求交集。HBase 行健怎么设计,spark 性能一般优化方法,spark streaming 和 storm 区别.给了一张笔试题， 10 道选择，一道大题。选择题是 java 基础知识，大题一个有三问：根据场景写出 Hive 建表语句； Hsql 从表中查询；用MapReduce写好友推荐，在一堆单词里面找出现次数最多的k个用分布式的方法做采样怎么保证采样结果完全符合预期？后面又问了Hadoop,Spark,storm下面的产品，原理，适用场景，写一个 Hadoop 版本的 wordcount。 HMM1234567891011121314151617181920212223242526272829实现 hmm 的状态转移代码；机器学习理论讲机器学习中常用的损失函数有哪些？交叉熵有什么好处？（凸优化问题）判别模型与生成模型的本质区别是什么分类模型和回归模型的区别，分类模型可以做回归分析吗？反过来可以吗？（我回答是分类不可以做回归，回归倒是可以做分类，不知道对不对）k折交叉验证 中k取值多少有什么关系 （我不知道，随便答，然后面试官后面问我知道bias和variance吗？估计是和这两个东西有关， 知乎上有个问题讨论了k值大小与bias和variance的关系）解释局部相关性特征选择的方法；在模型的训练迭代中，怎么评估效果；特征选择方法有哪些(能说出来10种以上加分)，之后和面试官仔细聊了一下特征选择的问题，我介绍了了解的几种基本的特征选择思路（错误率选择、基于熵的选择、类内类间距离的选择）；有没有接触过机器学习的前沿，深度学习看过paper没有？（并没有）如何用尽可能少的样本训练模型同时又保证模型的性能；你读哪些期刊会议的论文？你遇到的比较有意思的算法？生成模型，判别模型线性分类和非线性分类各有哪些模型比较各个模型的Loss function，设计一个结构存取稀疏矩阵 （面试官最后告诉我了一个极度压缩的存法，相同行或列存偏差，我当时没听懂，还不懂装懂，最后还是没记住）PageRank原理，怎么用模型来查找异常用户，我讲了一大堆我的理解，然后面试官一句你怎么不用规则把我噎到了……无监督和有监督算法的区别？经典算法推导(加分项)，原理，各个损失函数之间区别，使用场景，如何并行化，有哪些关键参数什么叫判别模型什么叫生成模型。先针对项目十分细致地询问了各种细节，然后就问我如何处理数据中的噪声点、数据清洗算法（正好自己做了一个算法）、如何选择特征等。校招TST内推，面过了2面，还是跟之前那个有点类似的游戏开发的安全部门，因为我也玩LOL，又问到怎么来判断玩家有没有作弊之类的问题，这次我小心翼翼的说用模型怎么做，用规则怎么做，感觉这次聊的都挺开心的。是否了解A/B Test以及A/B Test结果的置信度特征工程经验是否了解mutual infomation、chi-square、LR前后向、树模型等特征选择方式深刻理解各种算法对应采用的数据结构和对应的搜索方法。比如KNN对应的KD树、如何给图结构设计数据结构？如何将算法map-red化矩阵的各种变换，尤其是特征值相关的知识。分布式的矩阵向量乘的算法线性分类器与非线性分类器的区别及优劣；特征比数据量还大时，选择什么样的分类器？对于维度很高的特征，你是选择线性还是非线性分类器？对于维度极低的特征，你是选择线性还是非线性分类器？如何解决过拟合问题？L1和L2正则的区别，如何选择L1和L2正则？项目中的数据是否会归一化处理，哪个机器学习算法不需要归一化处理并行计算、压缩算法LDA http://www.doc88.com/p-1621945750499.html]]></content>
      <tags>
        <tag>笔面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-线性回归]]></title>
    <url>%2F2018%2F07%2F19%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[机器学习-线性回归 LR模型每个特征变量可以首先映射到⼀一个函数，然后再参与线性计算,模型如下： y = \theta_0 + \theta_1x_1 + \theta_2x_2 + · · · + \theta_nx_n其中$ x_1,x_2,…,x_n$表示自变量（特征分量），$y$表示因变量，$\theta$是权重，$\theta_0$是偏移项（截距）;$\theta_i$越大，说明$x_i$对$y$结果的影响越⼤输入空间映射到特征空间(映射函数$\phi(x)$)，建模.为 h_\theta(x)=\theta^T\phi(x)特征映射相关技术，包括特征哈希、特征学习、Kernel等 目标函数预测值$ h_\theta(x)$与真实值$y$之差越小越好，加入损失函数(平方损失函数): J(\theta)={0.5}\sum_{i=1}^{n}{(h_\theta(x^i)-y^i)^2}求$min{J(\theta)}$损失函数就是$x^i$的预测值$h_\theta(x^i)$与真实值$y^i$之差的平方和 回归模型（尤其是线性回归类）的⽬目标函数通常⽤用平⽅方损失函数来作为优化的⽬目标函数 为什么用误差平方和作为目标函数： 根据中⼼心极限定理理，把那些对结果影响⽐比较⼩小的变量量（假设独⽴立同分布）之和认为服从正态分布是合理理的 如果数据是高斯分布的，输入值$x^i$，预测值$\theta^Tx^i$，真实值$y^i$，误差$\epsilon^{i}$，线性模型为， y^i=\theta^Tx^i+\epsilon^{i}根据中心极限定理，认为变量之和服从高斯分布,即 e^{i} = y^i-\theta^Tx^i则，x,y的条件概率为 p(y^i|x^i;\theta) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y^i-\theta^Tx^i)^2}{2\sigma^2})$p(y^i|x^i;\theta)$越大，证明越接近真实值，还要考虑拟合过度以及模型的泛化能力问题 优化目标函数：使目标函数最小12345最小二乘法梯度下降法 批量梯度下降法 随机梯度下降法拉格朗日乘子法 例子 \begin{bmatrix} {a_{11}}&{a_{12}}&{\cdots}&{a_{1n}}\\ {a_{21}}&{a_{22}}&{\cdots}&{a_{2n}}\\ {\vdots}&{\vdots}&{\ddots}&{\vdots}\\ {a_{m1}}&{a_{m2}}&{\cdots}&{a_{mn}}\\ \end{bmatrix}]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习推荐书]]></title>
    <url>%2F2018%2F07%2F19%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[机器学习推荐书 5本深度学习书籍资源推荐 深度学习（Deep Learning）byIan Goodfellow and Yoshua Bengio and Aaron Courville 中文版下载地址：https://github.com/exacity/deeplearningbook-chinese R语言深度学习实践指南（Deep Learning Made Easy with R）by Dr. N.D. Lewis 下载地址：http://download.csdn.net/detail/oscer2016/9829915 深度学习基础（Fundamentals of Deep Learning）by Nikhil Buduma 下载地址：http://www.taodocs.com/p-32598980.html 神经网络和统计学习（Neural networks and statistical learning） by K.-L. Du and M.N.s. Swamy 下载地址：http://download.csdn.net/detail/oscer2016/9829919 神经网络和深度学习（Neural Networks and Deep Learning） by Michael Niels 下载地址：http://download.csdn.net/download/newhotter/9651111 10本机器学习书籍资源推荐 机器学习、神经网络和统计分类（Machine Learning, Neural Networks, and Statistical Classification）by D. Michie, D.J. Spiegelhalter, C.C. Taylor 下载地址：http://www1.maths.leeds.ac.uk/~charles/statlog/ 贝叶斯推理和机器学习（Bayesian Reasoning and Machine Learning）by David Barber 下载地址：http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online 机器学习的高斯过程（Gaussian Processes for Machine Learning） by Carl Edward Rasmussen and Christopher K. I. Williams，The MIT Press 下载地址：http://www.gaussianprocess.org/gpml/ 信息理论、推理和学习算法（Information Theory, Inference, and Learning Algorithms） by David J.C. MacKay 下载地址：http://www.inference.phy.cam.ac.uk/mackay/itprnn/book.html 统计学习元素（The Elements of Statistical Learning）by Trevor Hastie, Robert Tibshirani, Jerome Friedman 下载地址：http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf 机器学习课程（A Course in Machine Learning）by Hal Daumé III 下载地址：http://ciml.info/ 机器学习导论（Introduction to Machine Learning）by Amnon Shashua，Cornell University 下载地址：https://arxiv.org/abs/0904.3664v1 强化学习（Reinforcement Learning） 下载地址：https://www.intechopen.com/books/reinforcement_learning 机器学习导论（Introduction to Machine Learning）- By Nils Nilsson 下载地址：http://ai.stanford.edu/~nilsson/mlbook.html 强化学习（Reinforcement Learning）- MIT Press 下载地址：http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习_分类_KNN_EM]]></title>
    <url>%2F2018%2F07%2F19%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E5%88%86%E7%B1%BB_KNN_EM%2F</url>
    <content type="text"><![CDATA[机器学习_分类_KNN_EM K最近邻(kNN，k-NearestNeighbor)分类算法在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，在这里距离一般使用欧氏距离或曼哈顿距离： 123456789101112步骤：其算法的描述为：1）计算测试数据与各个训练数据之间的距离；2）按照距离的递增关系进行排序；3）选取距离最小的K个点；4）确定前K个点所在类别的出现频率；5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。 KNN算法的优点：123451）简单、有效。 2）重新训练的代价较低（类别体系的变化和训练集的变化，在Web环境和电子商务应用中是很常见的）。 3）计算时间和空间线性于训练集的规模（在一些场合不算太大）。 4）由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为适合。 5）该算法比较适用于样本容量比较大的类域的自动分类，而那些样本容量较小的类域采用这种算法比较容易产生误分。 KNN算法缺点： 123451）KNN算法是懒散学习方法（lazy learning,基本上不学习），一些积极学习的算法要快很多。 2）类别评分不是规格化的（不像概率评分）。 3）输出的可解释性不强，例如决策树的可解释性较强。 4）该算法在分类时有个主要的不足是，当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数。该算法只计算“最近的”邻居样本，某一类的样本数量很大，那么或者这类样本并不接近目标样本，或者这类样本很靠近目标样本。无论怎样，数量并不能影响运行结果。可以采用权值的方法（和该样本距离小的邻居权值大）来改进。 5）计算量较大。目前常用的解决方法是事先对已知样本点进行剪辑，事先去除对分类作用不大的样本。 EM算法EM的策略就是先随便给一个条件概率p1(x1|thera)，然后找到一个l(thera)的下界函数r(x1|thera),求r的最大值p2(x2|thera)，再找到经过p2点的下界函数r2(x2|thera)，重复该过程直到收敛到局部最大值。 灰度图分割：参考 point.h文件1234567891011#ifndef POINT_H#define POINT_H//point结构主要用来存储图像中节点的横坐标，纵坐标以及灰度值struct point&#123; int row; int col; double pixVal; point(int row, int col, double pixVal) :row(row),col(col),pixVal(pixVal) &#123;&#125;&#125;;#endif keams.h头文件：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161#ifndef KMEANS_H#define KMEANS_H#include&lt;opencv2\opencv.hpp&gt;#include&lt;random&gt;#include&lt;time.h&gt;#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;list&gt;#include&lt;iostream&gt;#include&lt;math.h&gt;#include&quot;point.h&quot;using namespace cv;using namespace std;class Kmeans&#123;private: //存储所有点 vector&lt;point&gt; points; //存储簇的中心点 vector&lt;point&gt; centers; //存储每个点到相应的簇 vector&lt;point&gt;* clusters; //向量的维数 int dimension; //簇的个数 int k;public: //构造函数 Kmeans(vector&lt;point&gt; points, vector&lt;point&gt; centers, int k, int dimension) &#123; this-&gt;points = points; this-&gt;centers = centers; this-&gt;dimension = dimension; this-&gt;k = k; clusters = new vector&lt;point&gt;[k]; &#125; //析构函数 ~Kmeans() &#123; delete clusters; &#125; //获取簇 vector&lt;point&gt;* getClusters() &#123; return this-&gt;clusters; &#125; //计算两个向量之间的欧式距离 double getDistanceBetweenTwoPoints(const point&amp; point1, const point&amp; point2) &#123; double sum = 0; //double tmp; //for (int i = 0; i &lt; dimension; i++) //&#123; //tmp = pow(point1.pixVal - point2.pixVal,2); //sum += tmp; //&#125; sum = pow(point1.pixVal - point2.pixVal, 2); return sqrt(sum); &#125; //计算每个点到离它最近的簇中心点，结果保存到vector中 vector&lt;int&gt; getClosetClusterCenterLabel() &#123; double min; int label; vector&lt;int&gt; labels; for (int i = 0; i &lt; points.size(); i++) &#123; label = 0; min = getDistanceBetweenTwoPoints(points[i], centers[0]); for (int j = 1; j &lt; centers.size(); j++) &#123; double tmp = getDistanceBetweenTwoPoints(points[i], centers[j]); if (tmp &lt; min) &#123; min = tmp; label = j; &#125; &#125; labels.push_back(label); &#125; return labels; &#125; //将每个点放入它离的最近的中心点对应的簇中 void computeClusters(const vector&lt;int&gt;&amp; labels) &#123; for (int i = 0; i &lt; k; i++) &#123; clusters[i].clear(); &#125; for (int i = 0; i &lt; labels.size(); i++) &#123; int label = labels[i]; clusters[label].push_back(points[i]); &#125; &#125; //重新计算所有簇的中心点的灰度值 void computeCenters() &#123; centers.clear(); for (int i = 0; i &lt; k; i++) &#123; double sum = 0; for (int j = 0; j &lt; clusters[i].size(); j++) &#123; sum += clusters[i][j].pixVal; &#125; double meanVal = sum / clusters[i].size(); point cp(-1, -1, meanVal); centers.push_back(cp); &#125; &#125; //确定新的中心点后重新计算一次cost double computeCost() &#123; double sum = 0; for (int i = 0; i &lt; k; i++) &#123; vector&lt;point&gt; tmpVec=clusters[i]; for (int j = 0; j &lt; tmpVec.size(); j++) &#123; sum += getDistanceBetweenTwoPoints(tmpVec[j], centers[i]); &#125; &#125; return sum / points.size(); &#125; //迭代执行k-means算法的步骤 void kmeans() &#123; double oldCost, newCost; vector&lt;int&gt; labels=getClosetClusterCenterLabel(); computeClusters(labels); newCost = computeCost(); computeCenters(); labels = getClosetClusterCenterLabel(); computeClusters(labels); oldCost = newCost; newCost = computeCost(); while (oldCost != newCost) &#123; oldCost = newCost; computeCenters(); labels = getClosetClusterCenterLabel(); computeClusters(labels); newCost = computeCost(); &#125; cout &lt;&lt;&quot;Final Cost: &quot;&lt;&lt; newCost &lt;&lt; endl; &#125;&#125;;#endif 测试的kmeans.cpp文件：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#include &quot;kmeans.h&quot;//图片的存放位置const String imageFolder = &quot;F:\\&quot;;//簇的个数（即k的大小，根据自己需要调整）const int numOfCluster =4;//最大像素值const int MAX_PIX_VALUE = 255;//存放所有点vector&lt;point&gt; points;//存放所有簇中心vector&lt;point&gt; centers;//存放所有点颜色特征(i,j)-&gt;i*rows+jvector&lt;double&gt; pixVec;//读取图像Mat readImage(String imageName)&#123; String imageLoc = imageFolder + imageName; Mat image=imread(imageLoc); return image;&#125;//初始化k-means聚类中心void initializeCenters(const Mat&amp; img)&#123; srand((unsigned)time(NULL)); for (int i = 0; i &lt; numOfCluster; i++) &#123; int randomX = rand() % img.rows; int randomY = rand() % img.cols; uchar pixVal = img.at&lt;uchar&gt;(randomX, randomY); point cp(randomX, randomY, (double)pixVal); centers.push_back(cp); &#125;&#125;//将图像中的所有点装入points中void initializePoints(const Mat&amp; img)&#123; for (int i = 0; i &lt; img.rows; i++) &#123; const uchar* data = img.ptr&lt;uchar&gt;(i); for (int j = 0; j &lt; img.cols; j++) &#123; uchar pixVal = data[j]; point p(i,j, (double)pixVal); points.push_back(p); &#125; &#125;&#125;int main()&#123; String imageName = &quot;lena.jpg&quot;; Mat img = readImage(imageName); cvtColor(img, img, CV_RGB2GRAY);//转化为灰度图像 namedWindow(imageName,WINDOW_NORMAL); imshow(imageName, img); waitKey(0); int rows = img.rows; int cols = img.cols; initializeCenters(img); initializePoints(img); Kmeans* km=new Kmeans(points, centers, numOfCluster, 1); cout &lt;&lt; &quot;---------------k-means start-------------&quot; &lt;&lt; endl; km-&gt;kmeans(); cout &lt;&lt; &quot;---------------k-means end---------------&quot; &lt;&lt;endl; vector&lt;point&gt;* clusters = km-&gt;getClusters(); Mat res(img.rows,img.cols,img.type()); double div = MAX_PIX_VALUE / numOfCluster; for (int i = 0; i &lt; numOfCluster; i++) &#123; vector&lt;point&gt; tmpVec = clusters[i]; for (int j = 0; j &lt; tmpVec.size(); j++) &#123; res.at&lt;uchar&gt;(tmpVec[j].row, tmpVec[j].col) = i*div; &#125; &#125; namedWindow(&quot;kmeansResult&quot;,WINDOW_NORMAL); imshow(&quot;kmeansResult&quot;, res); waitKey(0); imwrite(&quot;./segment_lena.jpg&quot;, res); system(&quot;pause&quot;);&#125; 彩色图像分割：参考 主函数：123456789101112131415161718192021222324252627282930#include &quot;clusterImagePixels.hpp&quot; int main()&#123; Mat testImage = imread(&quot;E:\\testImage\\board.jpg&quot;); if (testImage.empty()) &#123; return -1; &#125; ClusterPixels clusterPix(testImage,3); Mat colorResults = clusterPix.clusterColorImageByKmeans(); Mat grayResult = clusterPix.clusterGrayImageByKmeans(); if (!colorResults.empty()) &#123; hconcat(testImage, colorResults, colorResults); imshow(&quot;clusterImage&quot;, colorResults); &#125; if (!grayResult.empty()) &#123; hconcat(testImage, grayResult, grayResult); imshow(&quot;grayCluster&quot;, grayResult); &#125; if (waitKey() == 27) return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111#include &lt;opencv.hpp&gt;using namespace cv; Scalar colorTab[] = //10个颜色&#123; Scalar(0, 0, 255), Scalar(0, 255, 0), Scalar(255, 100, 100), Scalar(255, 0, 255), Scalar(0, 255, 255), Scalar(255, 0, 0), Scalar(255, 255, 0), Scalar(255, 0, 100), Scalar(100, 100, 100), Scalar(50, 125, 125)&#125;; class ClusterPixels&#123;private: Mat image; //待聚类图像 Mat labels; //聚类后的标签 int clusterCounts; //分类数,不得大于10，只是颜色定义只有10类，并不是算法限制 public: ClusterPixels() :clusterCounts(0)&#123;&#125; ClusterPixels(const Mat&amp; src, int clusters = 5) :clusterCounts(clusters)&#123; image = src.clone(); &#125; void setImage(const Mat&amp; src)&#123; image = src.clone(); &#125;; void setClusters(int clusters)&#123; clusterCounts = clusters; &#125; Mat getLabels() &#123;return labels; &#125;; //返回聚类后的标签 Mat clusterGrayImageByKmeans() &#123; //转换成灰度图 if (image.channels() != 1) cvtColor(image, image, COLOR_BGR2GRAY); int rows = image.rows; int cols = image.cols; //保存聚类后的图片 Mat clusteredMat(rows, cols, CV_8UC3); clusteredMat.setTo(Scalar::all(0)); Mat pixels(rows*cols, 1, CV_32FC1); //pixels用于保存所有的灰度像素 for (int i = 0; i &lt; rows;++i) &#123; const uchar *idata = image.ptr&lt;uchar&gt;(i); float *pdata = pixels.ptr&lt;float&gt;(0); for (int j = 0; j &lt; cols;++j) &#123; pdata[i*cols + j] = idata[j]; &#125; &#125; kmeans(pixels, clusterCounts, labels, TermCriteria(TermCriteria::EPS + TermCriteria::MAX_ITER, 10, 0), 5, KMEANS_PP_CENTERS); for (int i = 0; i &lt; rows;++i) &#123; for (int j = 0; j &lt; cols;++j) &#123; circle(clusteredMat, Point(j,i), 1, colorTab[labels.at&lt;int&gt;(i*cols + j)]); //标记像素点的类别，颜色区分 &#125; &#125; return clusteredMat; &#125; Mat clusterColorImageByKmeans() &#123; assert(image.channels() != 1); int rows = image.rows; int cols = image.cols; int channels = image.channels(); //保存聚类后的图片 Mat clusteredMat(rows, cols, CV_8UC3); clusteredMat.setTo(Scalar::all(0)); Mat pixels(rows*cols, 1, CV_32FC3); //pixels用于保存所有的灰度像素 pixels.setTo(Scalar::all(0)); for (int i = 0; i &lt; rows; ++i) &#123; const uchar *idata = image.ptr&lt;uchar&gt;(i); float *pdata = pixels.ptr&lt;float&gt;(0); for (int j = 0; j &lt; cols*channels; ++j) &#123; pdata[i*cols*channels + j] = saturate_cast&lt;float&gt;(idata[j]); &#125; &#125; kmeans(pixels, clusterCounts, labels, TermCriteria(CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 10, 0), 5, KMEANS_PP_CENTERS); for (int i = 0; i &lt; rows; ++i) &#123; for (int j = 0; j &lt; cols*channels; j += channels) &#123; circle(clusteredMat, Point(j/channels,i), 1, colorTab[labels.at&lt;int&gt;(i*cols + (j/channels))]); //标记像素点的类别，颜色区分 &#125; &#125; return clusteredMat; &#125;&#125;; opencv3代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include &quot;stdafx.h&quot;#include &quot;opencv2\opencv.hpp&quot;#include &lt;iostream&gt;using namespace std;using namespace cv;using namespace cv::ml;int main()&#123; Mat img = imread(&quot;E:/opencv/opencv/sources/samples/data/digits.png&quot;); Mat gray; cvtColor(img, gray, CV_BGR2GRAY); int b = 20; int m = gray.rows / b; //原图为1000*2000 int n = gray.cols / b; //裁剪为5000个20*20的小图块 Mat data,labels; //特征矩阵 for (int i = 0; i &lt; n; i++) &#123; int offsetCol = i*b; //列上的偏移量 for (int j = 0; j &lt; m; j++) &#123; int offsetRow = j*b; //行上的偏移量 //截取20*20的小块 Mat tmp; gray(Range(offsetRow, offsetRow + b), Range(offsetCol, offsetCol + b)).copyTo(tmp); data.push_back(tmp.reshape(0,1)); //序列化后放入特征矩阵 labels.push_back((int)j / 5); //对应的标注 &#125; &#125; data.convertTo(data, CV_32F); //uchar型转换为cv_32f int samplesNum = data.rows; int trainNum = 3000; Mat trainData, trainLabels; trainData = data(Range(0, trainNum), Range::all()); //前3000个样本为训练数据 trainLabels = labels(Range(0, trainNum), Range::all()); //使用KNN算法 int K = 5; Ptr&lt;TrainData&gt; tData = TrainData::create(trainData, ROW_SAMPLE, trainLabels); Ptr&lt;KNearest&gt; model = KNearest::create(); model-&gt;setDefaultK(K); model-&gt;setIsClassifier(true); model-&gt;train(tData); //预测分类 double train_hr = 0, test_hr = 0; Mat response; // compute prediction error on train and test data for (int i = 0; i &lt; samplesNum; i++) &#123; Mat sample = data.row(i); float r = model-&gt;predict(sample); //对所有行进行预测 //预测结果与原结果相比，相等为1，不等为0 r = std::abs(r - labels.at&lt;int&gt;(i)) &lt;= FLT_EPSILON ? 1.f : 0.f; if (i &lt; trainNum) train_hr += r; //累积正确数 else test_hr += r; &#125; test_hr /= samplesNum - trainNum; train_hr = trainNum &gt; 0 ? train_hr / trainNum : 1.; printf(&quot;accuracy: train = %.1f%%, test = %.1f%%\n&quot;, train_hr*100., test_hr*100.); waitKey(0); return 0;&#125;]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习常见算法总结]]></title>
    <url>%2F2018%2F07%2F19%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[机器学习常见算法总结 学习方式 概念 监督式学习 从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据此函数预测结果。训练数据集中的目标由人标注的。常见的算法有回归分析和统计分类 非监督式学习 与监督式学习相比，训练集没有人为标注的结果，常见的算法有聚类 半监督式学习 训练集部分被标识，部分没有被标识。常见的算法有SVM 强化学习 输入数据作为模型的反馈，模型对此作出调整。常见的算法有时间差学习 |机器学习算法分类|概念||—————-|—-||决策树算法|根据数据属性，采用树状结构建立决策模型。常用来解决分类和回归问题。常见算法：CART(Classification And Regression Tree)，ID3，C4.5，随机森林等||回归算法|对连续值预测，如逻辑回归LR等||分类算法|对离散值预测，事前已经知道分类，如k-近邻算法||聚类算法|对离散值预测，事前对分类未知，如k-means算法||神经网络|模拟生物神经网络，可以用来解决分类和回归问题感知器神经网络(Perceptron Neural Network) ，反向传递(Back Propagation)和深度学习（DL）||集成算法 |集成几种学习模型进行学习，将最终预测结果进行汇总Boosting、Bagging、AdaBoost、随机森林 (Random Forest) 等| 机器学习算法分类决策树算法根据数据属性，采用树状结构建立决策模型。常用来解决分类和回归问题。常见算法：CART(Classification And Regression Tree)，ID3，C4.5，随机森林等回归算法对连续值预测，如逻辑回归LR等分类算法对离散值预测，事前已经知道分类，如k-近邻算法聚类算法对离散值预测，事前对分类未知，如k-means算法神经网络模拟生物神经网络，可以用来解决分类和回归问题感知器神经网络(Perceptron Neural Network) ，反向传递(Back Propagation)和深度学习（DL）集成算法集成几种学习模型进行学习，将最终预测结果进行汇总Boosting、Bagging、AdaBoost、随机森林 (Random Forest) 等 SVM1、SVM不太容易过拟合：松弛因子+损失函数形式 SVM的求解方法叫拉格朗日乘子法 有时候如果你非要很明确地分类，那么结果就会像右边的一样 —— 过拟合。明显左边的两个都比过拟合好多了，可是这样就要求允许一些样本不在正确的类上. 目标：找出总损失值最小并且能大概分类的超平面 2、方法选择1231、如果Feature的数量很大，跟样本数量差不多，这时候选用LR或者是Linear Kernel的SVM2、如果Feature的数量比较小，样本数量一般，不算大也不算小，选用SVM+Gaussian Kernel3、如果Feature的数量比较小，而样本数量很多，需要手工添加一些feature变成第一种情况 3、数据维度如果数据特征维度高，svm要使用核函数来求解123Note：拉格朗日对偶没有改变最优解，但改变了算法复杂度：原问题—样本维度；对偶问题–样本数量。线性分类 样本维度&lt;样本数量：原问题求解（liblinear默认）； 非线性–升维—一般导致 样本维度&gt;样本数量：对偶问题求解 朴素贝叶斯朴素贝叶斯的优点：对小规模的数据表现很好，适合多分类任务，适合增量式训练。缺点：对输入数据的表达形式很敏感（离散、连续，值极大极小之类的） 线性回归线性回归试图学得一个线性模型以尽可能准确地预测实值输出标记。均方误差是回归任务中最常用的性能度量，基于均方误差最小化来进行模型求解的方法成为最小二乘法。在线性回归中，最小二乘法就是试图找到一条直线，使得所有样本到直线上的欧式距离之和最小。这个想法和分类问题是正好相反的，分类问题是找到一个分界面离所有样本尽可能远。 优化方法 当x矩阵是列满秩的时候，可以用最小二乘法，但是求矩阵的逆比较慢 机器学习算法选择 没有最好的分类器，只有最合适的分类器。 数据维度越高，随机森林就比AdaBoost强越多，但是整体不及SVM。 数据量越大，神经网络就越强。 1、K近邻典型KNN，它的思路就是——对于待判断的点，找到离它最近的几个数据点，根据它们的类型决定待判断点的类型。它的特点是完全跟着数据走，没有数学模型可言。123适用情景：需要一个特别容易解释的模型的时候。比如需要向用户解释原因的推荐算法。 2、贝叶斯典型的例子是Naive Bayes，核心思路是根据条件概率计算待判断点的类型。是相对容易理解的一个模型，至今依然被垃圾邮件过滤器使用。12345适用情景：需要一个比较容易解释，而且不同维度之间相关性较小的模型的时候。可以高效处理高维数据，虽然结果可能不尽如人意。 3、决策树 (Decision tree)决策树的特点是它总是在沿着特征做切分。随着层层递进，这个划分会越来越细。举个简单的例子，当我们预测一个孩子的身高的时候，决策树的第一层可能是这个孩子的性别。男生走左边的树进行进一步预测，女生则走右边的树。这就说明性别对身高有很强的影响。 12适用情景：同时它也是相对容易被攻击的分类器。这里的攻击是指人为的改变一些特征，使得分类器判断错误。常见于垃圾邮件躲避检测中。因为决策树最终在底层判断是基于单个条件的，攻击者往往只需要改变很少的特征就可以逃过监测。受限于它的简单性，决策树更大的用处是作为一些更有用的算法的基石。 随机森林 (Random forest)随机森林其实算是一种集成算法。它首先随机选取不同的特征(feature)和训练样本(training sample)，生成大量的决策树，然后综合这些决策树的结果来进行最终的分类。 它相对于决策树，在准确性上有了很大的提升，同时一定程度上改善了决策树容易被攻击的特点。 12345适用情景：数据维度相对低（几十维），同时对准确性有较高要求时。因为不需要很多参数调整就可以达到不错的效果，基本上不知道用什么方法的时候都可以先试一下随机森林。 优化问题的求解方法大部分的机器学习算法的本质都是建立优化模型，通过最优化方法对目标函数（或损失函数）进行优化，从而训练出最好的模型。常见的最优化方法有梯度下降法、牛顿法和拟牛顿法、共轭梯度法等等。 1、梯度下降法 优化思想1当目标函数是凸函数时，梯度下降法的解是全局解。一般情况下，其解不保证是全局最优解，梯度下降法的速度也未必是最快的。梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢。 缺点梯度下降法的最大问题就是会陷入局部最优，靠近极小值时收敛速度减慢。 2、批量梯度下降法1最小化所有训练样本的损失函数，使得最终求解的是全局的最优解，即求解的参数是使得风险函数最小，但是对于大规模样本问题效率低下。 3、随机梯度下降法1最小化每条样本的损失函数，虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近，适用于大规模训练样本情况。 随机梯度下降是通过每个样本来迭代更新一次，如果样本量很大的情况（例如几十万），那么可能只用其中几万条或者几千条的样本，就已经将theta迭代到最优解了，对比上面的批量梯度下降，迭代一次需要用到十几万训练样本，一次迭代不可能最优，如果迭代10次的话就需要遍历训练样本10次。但是，SGD伴随的一个问题是噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。 4、牛顿法 牛顿法是一种在实数域和复数域上近似求解方程的方法。方法使用函数f (x)的泰勒级数的前面几项来寻找方程f (x) = 0的根。牛顿法最大的特点就在于它的收敛速度很快。 牛顿法比梯度下降法快 牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。 但是牛顿法要算hessian矩阵的逆，比较费时间。 5、拟牛顿法 拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。拟牛顿法和最速下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于最速下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。 6、拉格朗日法 拉格朗日乘数法 拉格朗日乘子法主要用于解决约束优化问题，它的基本思想就是通过引入拉格朗日乘子来将含有n个变量和k个约束条件的约束优化问题转化为含有（n+k）个变量的无约束优化问题。拉格朗日乘子背后的数学意义是其为约束方程梯度线性组合中每个向量的系数。 通过引入拉格朗日乘子建立极值条件，对n个变量分别求偏导对应了n个方程，然后加上k个约束条件（对应k个拉格朗日乘子）一起构成包含了（n+k）变量的（n+k）个方程的方程组问题，这样就能根据求方程组的方法对其进行求解 过拟合： 如果一味的去提高训练数据的预测能力，所选模型的复杂度往往会很高，这种现象称为过拟合。所表现的就是模型训练时候的误差很小，但在测试的时候误差很大。 训练模型很好用，测试时候误差较大 参考]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++入门]]></title>
    <url>%2F2018%2F07%2F19%2FC%2B%2B%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[C++入门 指针入门 指针作用： 引用类型，传递地址，减少内存消耗案例int p &gt;定义变量pint* p &gt;定义指针变量p使用指针，先要定义指针变量12345678#include&lt;stdio.h&gt;int main() &#123; int *p; //int* p &gt;定义指针变量p int a=3; p=&amp;a; //&amp;a是把a的地址赋给指针p，&amp;：取址符a printf(&quot;%d\n&quot;,*p) //输出为3 return 0; &#125; 123&amp; 取变量的地址 &amp;(变量名)* 指针运算符（取值运算） *(变量名)&amp; *互为逆运算 *(&amp;(int i =6))=6 指针变量是存储地址的变量，随机分配例如：123456int *p1;char *nameint x;int *p; p=&amp;x;答：*P=3;p是x的地址，*p是x的值 常用错误：1、指针不能直接复制123456789错误：int *p; p =100;//错误正确：int i, *p, *t;p=&amp;i;t=p;*p *t是指针，把i的地址赋给pt指针（元素地址） 2、不能直接给指针赋值(不能直接变量取值)12int x= 20;printf(&quot;%d,&amp;(*x)); Scanf函数:函数后的参数应该传入指针，不应该是值123int score;printf(&quot;shuru :\n&quot;);scanf(&quot;%d&quot;,score); Swap函数：12345678910111213141516171819#include&lt;stdio.h&gt;void swap(int *x, int *y)&#123; int temp;//中间变量 temp=*x; *x = *y; *y = temp; printf(&quot;x=%d, y=%d \n&quot;, *x, *y);&#125;main()&#123; int i =13, j =45; swap(&amp;i, &amp;j); printf(&quot;i=%d, j=%d\n&quot;,i ,j);&#125;//输出： x=45,y=13 i=45,j=13 二级指针 C语言的参数传递都是值传递，当传传递一个指针给函数的时，其实质上还是值传递，除非使用双指针。只有一个号的时候，我们叫它一级指针。* 两个星号的叫二级指针。 123456789101112131415void swap ( int *a, int *b )&#123; int c; c = *a; *a = *b; *b = c; &#125; int main(int argc, char **argv)&#123; int a,b; a = 16; b = 32; swap( &amp;a, &amp;b); return ( a - b ); &#125; 段代码编译成汇编语言之后，除了会有代码段，数据段，堆栈，那么在调用的时候，会把main函数的参数变量压入main函数的栈帧，然后接着会压入swap函数的局部变量和参数 我们申明 **a之后，其实双指针变量a其实已经存在,内存效果如下12345p中放的是中间桥梁bridge的地址&amp;bridge*p就是中间桥梁bridge的内容(即是目标操作数的地址&amp;income)，**p就是目标操作数中间的bridge是桥梁，中间件使用的，过度吧 双指针主要用在但我们想向一个A函数传递参数的时候，但是我们希望在A内部对参数做任何修改都能保存起来，那么就是用双指针吧。 输入输出流IO库：|头文件|类型||||-|-|-|-||iostream|istream,wistream 从流读取数据|ostream, wostream向流写入数据|iostream. wiostream读写流||fstream|ifstream, wifstream从文件读取数据|ofstream, wofstream向文件写入数据|fstream, wfstream读写文件||sstream|istringstream. wistringstream string 读取数据|ostringstream, wostringstream string 写入数据|stringstream, wstringstream string 读写string| 123类型ifsream和istringstream都继承自istream;类型ofsream和ostringstream都继承自ostream;类型fsream和stringstream都继承自iostream; 1、创建使用文件流对象12345ifstream in(ifile);//构造一个ifstream并打开给定文件ofstream out;//构造输出文件流，未关联任何文件in.close();//关闭文件in.open(ifile + &quot;2&quot;);//打开另一个文件 ifstream,ofstream和fstream是实现文件读写操作的类型 案例12345678910111213141516171819202122#include &lt;iostream&gt; #include &lt;fstream&gt;#include &lt;stdlib.h&gt;#include &lt;vector&gt;using namespace std;int main()&#123; char buffer[256]; ifstream in(&quot;input.txt&quot;);//文件不存在会返回错误 if (! in.is_open())&#123; cout &lt;&lt; &quot;Error opening file&quot;&lt;&lt;endl; exit (1); &#125; vector&lt;string&gt; a; while (!in.eof())&#123; in.getline (buffer,100); //cout &lt;&lt; buffer &lt;&lt; endl; a.push_back(buffer); &#125; for(unsigned int i=0;i&lt;a.size();i++) cout&lt;&lt;a[i]&lt;&lt;endl; return 0;&#125; resize(),reserve()resize()，设置大小（size）;reserve()，设置容量（capacity）;size()是分配容器的内存大小，而capacity()只是设置容器容量大小，但并没有真正分配内存。 ifstreamcankao1、文件打开1ifstream infile(fname,ios::in); 定义ifstream的对象infile,打开文件faname,ios::in是读取 打开文件的方式在ios类(所以流式I/O的基类)中定义 IO流的定义 含义 ios::in 为输入(读)而打开文件 ios::out 为输出(写)而打开文件 ios::ate 初始位置：文件尾 ios::app 所有输出附加在文件末尾 ios::trunc 如果文件已存在则先删除该文件 ios::binary 二进制方式 2、关闭文件：1infile.close 3、文本文件的读写 类ofstream, ifstream 和fstream 是分别从ostream, istream 和iostream 中引申而来的。这就是为什么 fstream 的对象可以使用其父类的成员来访问数据。123456789101112131415161718192021222324252627282930313233343536373839写入内容：#include &lt;fiostream.h&gt; int main () &#123; ofstream out(&quot;out.txt&quot;); if (out.is_open()) &#123; out &lt;&lt; &quot;This is a line.\n&quot;; out &lt;&lt; &quot;This is another line.\n&quot;; out.close(); &#125; return 0; &#125; //结果: 在out.txt中写入： This is a line. This is another line读取内容：// reading a text file #include &lt;iostream.h&gt; #include &lt;fstream.h&gt; #include &lt;stdlib.h&gt; int main () &#123; char buffer[256]; ifstream in(&quot;test.txt&quot;); if (! in.is_open()) &#123; cout &lt;&lt; &quot;Error opening file&quot;; exit (1); &#125; while (!in.eof() ) &#123; in.getline (buffer,100); cout &lt;&lt; buffer &lt;&lt; endl; &#125; return 0; &#125; //结果 在屏幕上输出 This is a line. This is another line``` 状态标识符 bad()如果在读写过程中出错，返回 true 。例如：当我们要对一个不是打开为写状态的文件进行写入时，或者我们要写入的设备没有剩余空间的时候。 fail()除了与bad() 同样的情况下会返回 true 以外，加上格式错误时也返回true ，例如当想要读入一个整数，而获得了一个字母的时候。 eof()如果读文件到达文件末尾，返回true。 good()这是最通用的：如果调用以上任何一个函数返回true 的话，此函数返回 false 。123456要想重置以上成员函数所检查的状态标志，你可以使用成员函数clear()，没有参数。### sizeofsizeof 求对象或者类型的大小`sizeof(array)`&lt;br&gt;[cankao](https://blog.csdn.net/tao20dage/article/details/52372604) 特性0：sizeof是运算符，不是函数特性1：sizeof不能求得void类型的长度特性2：sizeof能求得void类型的指针的长度特性3：sizeof能求得静态分配内存的数组的长度!特性4：sizeof不能求得动态分配的内存的大小!特性5：sizeof不能对不完整的数组求长度！特性6：当表达式作为sizeof的操作数时，它返回表达式的计算结果的类型大小，但是它不对表达式求值！12345678910111213141516### new(std::nothrow) 顾名思义，即不抛出异常，当new一个对象失败时，默认设置该对象为NULL，这样可以方便的通过if(p == NULL) 来判断new操作是否成功 建议在c++代码中，凡是涉及到new操作，都采用new(std::nothrow)，然后if(p==NULL)的方式进行判断 ### vector[cankao](https://blog.csdn.net/duan19920101/article/details/50617190/)&lt;br&gt;在c++中，vector是一个十分有用的容器。作用：它能够像容器一样存放各种类型的对象，简单地说，vector是一个能够存放任意类型的动态数组，能够增加和压缩数据。&lt;br&gt;&gt;1、如果你要表示的向量长度较长（需要为向量内部保存很多数），容易导致内存泄漏，而且效率会很低；&lt;br&gt;2、Vector作为函数的参数或者返回值时，需要注意它的写法： double Distance(vector&lt;int&gt;&amp;a, vector&lt;int&gt;&amp;b) 其中的“&amp;”绝对不能少！！！ c++基本操作 1 、基本操作 (1)头文件#include.(2)创建vector对象，vector vec;(3)尾部插入数字：vec.push_back(a);(4)使用下标访问元素，cout&lt;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征提取_图像矩阵变换]]></title>
    <url>%2F2018%2F07%2F19%2F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96_%E5%9B%BE%E5%83%8F%E7%9F%A9%E9%98%B5%E5%8F%98%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[特征提取_图像矩阵变换 基本的二维变换可包括缩放、旋转、扭曲，和平移四种 几何运算则可以转换为一些基本的矩阵运算 平移运算不是线性的,使用矩阵乘法再使用矩阵加法来完成此操作 综合这几种基本运算，数学家们将其统一为一个3*3矩阵，存储形式 仿射变换的矩阵的第三列总是（0，0，1），在存储矩阵的时候，大多只存成一个2*3的数组。 复合变换是有顺序的，一般说来，先旋转、再缩放、然后平移]]></content>
      <tags>
        <tag>特征提取</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习_分类_决策树]]></title>
    <url>%2F2018%2F07%2F18%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E5%88%86%E7%B1%BB_%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[机器学习分类决策树 决策树算法是借助于树的分支结构实现分类。 叶子节点：存放决策结果非叶子节点：特征属性，及其对应输出，按照输出选择分支决策过程：从根节点出发，根据数据的各个属性，计算结果，选择对应的输出分支，直到到达叶子节点，得到结果 决策树使用自顶向下递归分治法，并采用不回溯的贪心策略。分裂属性的选择算法很多，这里介绍3种常用的算法：信息增益（Information gain）、增益比率（gain ratio）、基尼指数（Gini index）。 我们通过基尼不纯度或者熵来对一个集合进行的有序程度进行量化，然后引入信息增益概念对一次拆分进行量化评价 基尼不纯度基尼不纯度是指将来自集合中的某种结果随机应用于集合中某一数据项的预期误差率。该值越高，说明拆分的越不理想，如果该值为 0，说明完美拆分。 Gini(D)=1−∑_i=(1^m)p_i^2熵用来表示集合的无序程度，熵越大表示集合越混乱 E = -P * log2P 基尼不纯度与熵对比两者主要区别在于，熵到达峰值的过程相对慢一些。因此熵对混乱集合的「判罚」往往更重一些。通常情况下，熵的使用更加频繁。 信息增益（Information Gain）基于香浓的信息论，信息熵表示不确定度，均匀分布时，不确定度最大，此时熵就最大。当选择某个特征对数据集进行分类时，数据集分类后的信息熵会比分类前的小，其差值即为信息增益。信息增益可以衡量某个特征对分类结果的影响大小，越大越好。 信息增益=abs(信息熵（分类后）-信息熵（分类前）) Gain(R)=Info(D)−InfoR(D) 决策树降剪枝 为什么要剪枝训练出得决策树存在过度拟合现象——决策树过于针对训练的数据，专门针对训练集创建出来的分支，其熵值可能会比真实情况有所降低。 如何剪枝人工设置一个信息增益的阀值，自下而上遍历决策树，将信息增益低于该阀值的拆分进行合并 处理缺失数据 决策树模型还有一个很大的优势，就是可以容忍缺失数据。如果决策树中某个条件缺失，可以按一定的权重分配继续往以后的分支走，最终的结果可能有多个，每个结果又一定的概率，即：1最终结果=某个分支的结果 x 该分支的权重(该分支下的结果数/总结果数) 生成算法：ID3和C4.5。1、ID3算法ID3算法可用于划分标称型数据集，没有剪枝的过程，为了去除过度数据匹配的问题，可通过裁剪合并相邻的无法产生大量信息增益的叶子节点（例如设置信息增益阀值）。考虑某个特征后，信息熵减小的多，这个特征就是好的特征(在每层分裂时，选择使得Gain(R)最大的属性作为分裂属性)ID3算法中根据信息增益评估和选择特征，每次选择信息增益最大的特征作为判断模块建立子结点 缺点：1、此公式偏向数据量多的属性，如果样本分布不均，则会导致过拟合。2、不能处理连续分布的数据特征 2、C4.5算法C4.5算法用信息增益率来选择属性，继承了ID3算法的优点优点： 1、克服了用信息增益选择属性时偏向选择取值多的属性的不足；2、在树构造过程中进行剪枝；3、能够完成对连续属性的离散化处理；4、能够对不完整数据进行处理。1C4.5算法产生的分类规则易于理解、准确率较高；但效率低，因树构造过程中，需要对数据集进行多次的顺序扫描和排序C4.5算法在结构与递归上与ID3完全相同，区别只在于选取决决策特征时的决策依据不同，二者都有贪心性质：即通过局部最优构造全局最优 svm:123456789101112131415161718192021222324252627282930313233343536模型在真实世界中也应用场景 支撑向量机用于文本和超文本的分类；用于图像分类；用于手写体识别；这个模型的优势是什么？分类效果好；可以有效地处理高维空间的数据；可以有效地处理变量个数大于样本个数的数据；只是使用了一部分子集来进行训练模型，所以SVM模型不需要太大的内存；可以提高泛化能力；无局部极小值问题；他什么情况下表现最好？数据的维度较高；需要模型具有非常强的泛化能力；样本数据量较小时；解决非线性问题；这个模型的缺点是什么？无法处理大规模的数据集，因为该算法需要较长的训练时间；无法有效地处理包含噪声太多的数据集；SVM模型没有直接给出概率的估计值，而是利用交叉验证的方式估计，这种方式耗时较长；对缺失数据非常敏感；对于非线性问题，有时很难找到一个合适的核函数。什么条件下它表现很差？数据集的数据量过大；数据集中的含有噪声；数据集中的缺失较多的数据；对算法的训练效率要求较高；根据我们当前数据集的特点，为什么这个模型适合这个问题。 该项目所提供的样本数据相对较少；该问题是属于非线性问题；数据集经过“独热编码”后，维度较高 决策树：1234567891011121314151617181920212223242526272829303132这个模型的优势是什么？决策树易于实现和理解；对于决策树，数据的准备工作一般比较简单；能够同时处理多种数据类型给定一个决策树模型，可以根据产生的决策树推出相应的逻辑表达式；通过静态测试来对模型的表现进行评价；在相对较短的时间内可以对大量的数据做出非常好的结果；决策树可以很好地扩展到大型数据中，同时决策树的大小独立于数据库的大小；计算复杂度相对较低，结果的输出易于理解，对部分的数据缺失不敏感。他什么情况下表现最好？实例是由“属性-值”对表示的；目标函数具有离散的输出值；训练数据集包含部分错误(决策树对错误有适应性)；训练数据缺少少量属性的实例。这个模型的缺点是什么？易于出现过拟合问题；忽略了数据集中属性之间的相关性；对于类比不一致的样本，决策树的信息增益倾向于那些数据值较多的特征什么条件下它表现很差？决策树匹配的数据过多时；分类的类别过于复杂；数据的属性之间具有非常强的关联。根据我们当前数据集的特点，为什么这个模型适合这个问题。不需要准备太多的训练数据，不需要对数据过多的处理如删除空白值等；易于编码；该问题是非线性问题，决策树能够很好地解决非线性问题；算法的执行效率高，对机器的要求较小。]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习_分类_随机森林]]></title>
    <url>%2F2018%2F07%2F16%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E5%88%86%E7%B1%BB_%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%2F</url>
    <content type="text"><![CDATA[机器学习分类随机森林 它也是最常用的算法之一，随机森林建立了多个决策树，并将它们合并在一起以获得更准确和稳定的预测。随机森林的一大优势在于它既可用于分类，也可用于回归问题 随机森林的主要限制在于使用大量的树会使算法变得很慢，并且无法做到实时预测。一般而言，这些算法训练速度很快，预测十分缓慢。越准确的预测需要越多的树，这将导致模型越慢。在大多数现实世界的应用中，随机森林算法已经足够快，但肯定会遇到实时性要求很高的情况，那就只能首选其他方法。 随机森林和Adaboost，以及区别：bagging 随机森林，不同的分类器是通过串行训练而获得的，每个新分类器都根据已训练出的分类器的性能来进行训练分类器权重相等. boost ：— §是通过集中关注被已有分类器错分的那些数据来获得新的分类器。匕0081丨明分类的结果是基于所有分类器的加权求和结果的，分类器权重并不相等，每个权重代表的是其对应分类器在上一轮迭代中的成功度 说一下GBDT和Adaboost，以及区别 Bagging + 决策树 = 随机森林 2）AdaBoost + 决策树 = 提升树 3）Gradient Boosting + 决策树 = GBDT]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理-图像去雾]]></title>
    <url>%2F2018%2F07%2F16%2F%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE%2F</url>
    <content type="text"><![CDATA[图像处理-图像去雾 雾图模型I(x)=J(x)t(x)+A(1-t(x))1234I(x) ——待去雾的图像J(x)——无雾图像A——全球大气光成分t——折射率（大气传递系数） 暗通道先验在无雾图像中，每一个局部区域都很有可能会有阴影，或者是纯颜色的东西，又或者是黑色的东西。因此，每一个局部区域都很有可能有至少一个颜色通道会有很低的值。把这个统计规律叫做Dark Channel Prior。 首先求出每个像素RGB分量中的最小值，存入一副和原始图像大小相同的灰度图中，然后再对这幅灰度图进行最小值滤波(林宇中取最小值) 计算折射率 t(x)=1-wmin(minI(y)/A)估计大气光1231.选取暗通道图像暗通道最亮的0.1%的像素（一般来说，这些像素表示雾浓度最大的地方）2.取输入图像里面这些像素对应的像素里面最亮的作为大气光（暗图像最亮的0.1%的像素对应的原图最亮的为大气光） 注：选中的像素未必是全图最亮的，而且要比选取全图最亮的方式鲁棒性更好。 去雾J(x)=I(x)-A/max(t(x),t0) +At0=0.1 流程：1.求图像暗通道 2.利用暗通道计算出折射率 3.利用暗通道估计大气光 4.代回雾图公式去雾]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理_边缘检测]]></title>
    <url>%2F2018%2F07%2F16%2F%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[图像处理_边缘检测 边缘检测：https://blog.csdn.net/tigerda/article/details/61192943 常见边缘检测算子：Roberts 、Sobel 、Prewitt、Laplacian、Log/Marr、Canny、Kirsch、Nevitia&lt;/br&gt; 一阶微分算子：Roberts 、Sobel 、Prewitt&lt;/br&gt;1234567891011121314151617181920模板：Roberts |1, 0||0,-1|sobel算子|1, 0 , 1||1, 0 , 1||1, 0 , 1|prewitt算子|1, 0 , 1||1, 0 , 1||1, 0 , 1|Sobel各向同性算子: |-1 ,0, 1| |-1,-跟2,-1|Gx=|-跟2,0,跟2| ,Gx=| 0, 0, 0| |-1 ,0, 1| | 1, 跟2, 1| Sobel各向同性算子的权值比普通Sobel算子的权值更准确。为什么？模板的权值是离中心位置越远则权值（看绝对值）影响越小123456789101112计算边缘幅值与方向？以Sobel算子为例。3*3Sobel两个方向的算子在图像上滑动，模板与其覆盖的图像3*3区域9个像素进行卷积，求和后得到此方向的边缘检测幅值。 |-1,0,1| |-1,-2,-1|Gx=|-2,0,2|*f(x,y) ,Gx=| 0, 0, 0|*f(x,y) |-1,0,1| | 1, 2, 1|G^2=Gx^2+Gy^2P=arctan(Gx/Gy)f(x,y)为图像，Gx和Gy分别是水平和竖直方向算子的卷积结果，G则是最终得到的边缘幅值，θ值则是边缘方向。当然G的计算有时简化为G=|Gx|+|Gy| 或者 G=max(|Gx|,|Gy|) 二阶微分算子：Laplacian、Log/Marr123456789101112131415Laplacian算子 |-1,-1,-1| Gx=|-1, 8,-1| |-1,-1,-1| | 0,-1, 0| Gx=|-1, 4,-1| | 0,-1, 0| |-2,-4,-4,-4,-2| |-4, 0, 8, 0,-4| Gx=|-4, 8,24, 8,-4| |-4, 0, 8, 0,-4| |-2,-4,-4,-4,-2|Log边缘检测则是先进行高斯滤波再进行拉普拉斯算子检测 非微分边缘检测算子：Canny 算 子 优缺点比较 Roberts 对具有陡峭的低噪声的图像处理效果较好，但利用 Roberts算子提取边缘的结果是边缘比较粗，因此边缘定位不是很准确。 Sobel 对灰度渐变和噪声较多的图像处理效果比较好， Sobel算子对边缘定位比较准确。 Kirsch 对灰度渐变和噪声较多的图像处理效果较好。 Prewitt 对灰度渐变和噪声较多的图像处理效果较好。 aplacian 对图像中的阶跃性边缘点定位准确，对噪声非常敏感，丢失一部分边缘的方向信息，造成一些不连续的检测边缘。 LoG 算 子 经 常 出 现 双 边 缘 像 素 边 界 ， 而 且 该 检 测 方 法 对 噪 声 比铰 敏 感 ， 所 以 很 少 用 LoG算 子 检 测 边 缘 ， 而 是 用 来 判 断 边 缘 像素是位于图像的明区还是暗区。 Canny 此方法不容易受噪声的干扰，能够检测到真正的弱边缘。在edge函数中，最有效的边缘检测方法是 Canny方法。该方法的优点在于使用两种不同的阈值分别检测强边缘和弱边缘，并且汉当弱边缘与强边缘相连时，才将弱边缘包含在输出图像中。因此，这种方法不容易被噪声“填充”，跟容易检测出真正的弱边缘。]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv_ocr]]></title>
    <url>%2F2018%2F07%2F16%2Fopencv_ocr%2F</url>
    <content type="text"><![CDATA[opencv_ocr]]></content>
      <tags>
        <tag>Opencv</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像分割-大津法]]></title>
    <url>%2F2018%2F07%2F16%2F%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2_%E5%A4%A7%E6%B4%A5%E6%B3%95%2F</url>
    <content type="text"><![CDATA[图像分割-大津法 算法介绍最大类间方差法是1979年由日本学者大津提出的，是一种自适应阈值确定的方法，又叫大津法，简称OTSU 算法公式 代码 Opencv249 + vs201012345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &quot;stdio.h&quot;#include &quot;cv.h&quot;#include &quot;highgui.h&quot;#include &quot;Math.h&quot;int Otsu(IplImage* src);int main()&#123; IplImage* img = cvLoadImage(&quot;lena.jpg&quot;,0); //获取灰度图像img IplImage* dst = cvCreateImage(cvGetSize(img), 8, 1); int threshold = Otsu(img); //调用大津法求出最佳阈值 printf(&quot;otsu threshold = %d\n&quot;, threshold); cvThreshold(img, dst, threshold, 255, CV_THRESH_BINARY); //用otsu的阈值二值化 cvNamedWindow( &quot;img&quot;, 1 ); cvNamedWindow( &quot;dst&quot;, 1 ); cvShowImage(&quot;img&quot;, img); cvShowImage(&quot;dst&quot;, dst); cvWaitKey(-1); cvReleaseImage(&amp;img); cvReleaseImage(&amp;dst); cvDestroyWindow( &quot;img&quot; ); cvDestroyWindow( &quot;dst&quot; ); return 0;&#125;int Otsu(IplImage* src) &#123; int height=src-&gt;height; int width=src-&gt;width; //histogram float histogram[256] = &#123;0&#125;; for(int i=0; i &lt; height; i++) &#123; unsigned char* p=(unsigned char*)src-&gt;imageData + src-&gt;widthStep * i; for(int j = 0; j &lt; width; j++) &#123; histogram[*p++]++; &#125; &#125; //normalize histogram &amp; average pixel value int size = height * width; float u =0; for(int i = 0; i &lt; 256; i++) &#123; histogram[i] = histogram[i] / size; u += i * histogram[i]; //整幅图像的平均灰度 &#125; int threshold; float maxVariance=0; float w0 = 0, avgValue = 0; for(int i = 0; i &lt; 256; i++) &#123; w0 += histogram[i]; //假设当前灰度i为阈值, 0~i 灰度像素所占整幅图像的比例即前景比例 avgValue += i * histogram[i]; //avgValue/w0 = u0 float t = avgValue/w0 - u; //t=u0-u float variance = t * t * w0 /(1 - w0); if(variance &gt; maxVariance) &#123; maxVariance = variance; threshold = i; &#125; &#125; return threshold; &#125; 代码212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;opencv2/opencv.hpp&gt; #include &lt;cv.h&gt;#include &lt;highgui.h&gt;#include &lt;cxcore.h&gt;using namespace std;using namespace cv;Mat otsuGray(const Mat src) &#123; Mat img = src; int c = img.cols; //图像列数 int r = img.rows; //图像行数 int T = 0; //阈值 uchar* data = img.data; //数据指针 int ftNum = 0; //前景像素个数 int bgNum = 0; //背景像素个数 int N = c*r; //总像素个数 int ftSum = 0; //前景总灰度值 int bgSum = 0; //背景总灰度值 int graySum = 0; double w0 = 0; //前景像素个数占比 double w1 = 0; //背景像素个数占比 double u0 = 0; //前景平均灰度 double u1 = 0; //背景平均灰度 double Histogram[256] = &#123;0&#125;; //灰度直方图 double temp = 0; //临时类间方差 double g = 0; //类间方差 //灰度直方图 for(int i = 0; i &lt; r ; i ++) &#123; for(int j = 0; j &lt;c; j ++) &#123; Histogram[img.at&lt;uchar&gt;(i,j)]++; &#125; &#125; //求总灰度值 for(int i = 0; i &lt; 256; i ++) &#123; graySum += Histogram[i]*i; &#125; for(int i = 0; i &lt; 256; i ++) &#123; ftNum += Histogram[i]; //阈值为i时前景个数 bgNum = N - ftNum; //阈值为i时背景个数 w0 = (double)ftNum/N; //前景像素占总数比 w1 = (double)bgNum/N; //背景像素占总数比 if(ftNum == 0) continue; if(bgNum == 0) break; //前景平均灰度 ftSum += i*Histogram[i]; u0 = ftSum/ftNum; //背景平均灰度 bgSum = graySum - ftSum; u1 = bgSum/bgNum; g = w0*w1*(u0-u1)*(u0-u1); if(g &gt; temp) &#123; temp = g; T = i; &#125; &#125; for(int i=0; i&lt;img.rows; i++) &#123; for(int j=0; j&lt;img.cols; j++) &#123; if((int)img.at&lt;uchar&gt;(i,j)&gt;T) img.at&lt;uchar&gt;(i,j) = 255; else img.at&lt;uchar&gt;(i,j) = 0; &#125; &#125; return img;&#125;]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Opencv_斑点检测]]></title>
    <url>%2F2018%2F07%2F16%2Fopencv_%E6%96%91%E7%82%B9%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[Opencv_斑点检测 opencv中检测Blobs的类为SimpleBlobDetector这个类在opencv中的定义如下：123456789101112131415161718192021222324252627282930313233class SimpleBlobDetector : public FeatureDetector&#123;public:struct Params&#123; Params(); float thresholdStep; float minThreshold; float maxThreshold; size_t minRepeatability; float minDistBetweenBlobs; bool filterByColor; uchar blobColor; bool filterByArea; float minArea, maxArea; bool filterByCircularity; float minCircularity, maxCircularity; bool filterByInertia; float minInertiaRatio, maxInertiaRatio; bool filterByConvexity; float minConvexity, maxConvexity;&#125;;SimpleBlobDetector(const SimpleBlobDetector::Params &amp;parameters = SimpleBlobDetector::Params());protected: ...&#125;; 算法的大致步骤如下： 对[minThreshold,maxThreshold)区间，以thresholdStep为间隔，做多次二值化。对每张二值图片，使用findContours()提取连通域并计算每一个连通域的中心。根据2得到的中心，全部放在一起。一些很接近的点［由theminDistBetweenBlobs控制多少才算接近］被归为一个group,对应一个bolb特征..从3得到的那些点,估计最后的blob特征和相应半径，并以key points返回。同时该支持提取特征的方法，一共有5个选项，这里就不多加描述了，默认是提取黑色圆形的Blob特征。下面是一个示例1234567891011121314151617int main(int argc, char** argv) &#123; Mat image = imread(argv[1]); vector&lt;KeyPoint&gt; keyPoints; SimpleBlobDetector::Params params; SimpleBlobDetector blobDetect(params); blobDetect.create(&quot;SimpleBlob&quot;); blobDetect.detect(image, keyPoints); cout &lt;&lt; keyPoints.size() &lt;&lt; endl; drawKeypoints(image, keyPoints, image, Scalar(255,0,0)); namedWindow(&quot;blobs&quot;); imshow(&quot;blobs&quot;, image); waitKey(); return 0; &#125; 总体来说，OpenCV的斑点检测效果还算不错，但是在有些图像的效果上明显不如LOG算子检测的检测效果]]></content>
      <tags>
        <tag>Opencv</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理_图像增强]]></title>
    <url>%2F2018%2F07%2F16%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86_%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%2F</url>
    <content type="text"><![CDATA[图像处理_图像增强 图像增强前期知识图像增强是图像模式识别中非常重要的图像预处理过程。图像增强的目的是通过对图像中的信息进行处理，使得有利于模式识别的信息得到增强，不利于模式识别的信息被抑制，扩大图像中不同物体特征之间的差别，为图像的信息提取及其识别奠定良好的基础。图像增强按实现方法不同可分为点增强、空域增强和频域增强。 1、点增强点增强主要指图像灰度变换和几何变换。图像的灰度变换也称为点运算、对比度增强或对比度拉伸，它是图像数字化软件和图像显示软件的重要组成部分。灰度变换是一种既简单又重要的技术，它能让用户改变图像数据占据的灰度范围。一幅输入图像经过灰度变换后将产生一幅新的输出图像，由输入像素点的灰度值决定相应的输出像素点的灰度值。灰度变换不会改变图像内的空间关系。图像的几何变换是图像处理中的另一种基本变换。它通常包括图像的平移、图像的镜像变换、图像的缩放和图像的旋转。通过图像的几何变换可以实现图像的最基本的坐标变换及缩放功能。 2、空域增强图像的空间信息可以反映图像中物体的位置 、形状、大小等特征，而这些特征可以通过一定的物理模式来描述。例如，物体的边缘轮廓由于灰度值变化剧烈一般出现高频率特征，而一个比较平滑的物体内部由于灰度值比较均一则呈现低频率特征。因此，根据需要可以分别增强图像的高频和低频特征。对图像的高频增强可以突出物体的边缘轮廓，从而起到锐化图像的作用。例如，对于人脸的比对查询，就需要通过高频增强技术来突出五宫的轮廓。相应地，对图像的低频部分进行增强可以对图像进行平滑处理，一般用于图像的噪声消除。 3、频域增强图像的空域增强一般只是对数字图像进行局部增强，而图像的频域增强可以对图像进行全局增强。频域增强技术是在数字图像的频率域空间对图像进行滤波，因此需要将图像从空间域变换到频率域，一般通过傅里叶变换实现。在频率域空间的滤波与空域滤波一样可以通过卷积实现，因此傅里叶变换和和卷积理论是频域滤波技术的基础。 图像增强的方法分类： 图像增强方法 实现方法 处理对象 灰度图 （伪）彩色图 - - 处理策略 全局处理 局部处理（ROI ROI，Region of Interest Interest） - - 处理方法 空间域（点域运算，即灰度变换） 空间域（邻域方法，即空域滤波） 频域方法 - - 处理目的 图像锐化 平滑去噪 灰度调整（对比度增强） 图像增强的方法之对比度增强 图像增强方法 实现方法 灰度变换法 线性变换（已实现） 对数变换（已实现） 指数变换（已实现） - - 直方图调整法 直方图均衡化（已实现） 直方图匹配（未实现） 图像对比度增强 图像对比度增强 直接 间接 直方图拉伸 直方图均衡化 1234直方图拉伸 是通过对比度拉伸对直方图进行调整，从而“扩大”前景和背景灰度的差别，以达到增强对比度的目的，这种方法可以利用线性或非线性的方法来实现;直方图均衡化则通过使用累积函数对灰度值进行“调整”以实现对比度的增强。直方图均衡化处理 “中心思想”是把原始图像的灰度直方图从比较集中的某个灰度区间变成在全部灰度范围内的均匀分布。直方图均衡化就是对图像进行非线性拉伸，重新分配图像像素值，使一定灰度范围内的像素数量大致相同。直方图均衡化就是把给定图像的直方图分布改变成“均匀”分布直方图分布。 常用图像增强直方图均衡化 直方图均衡化 优点 处理过亮过暗图像很有效(曝光过度或者曝光不足),刻画更多细节 是一个相当直观的技术并且是可逆操作，如果已知均衡化函数，那么就可以恢复原始的直方图，并且计算量也不大 - - 缺点 处理数据随机，可能会降低信噪比(会增加背景噪声对比度，降低有用信号对比度) c语言代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174#include &lt;stdio.h&gt;#include &lt;iostream&gt;#include &quot;fftw3.h&quot;#include &quot;string&quot;#include &quot;vector&quot;#include &lt;windows.h&gt;#include &lt;opencv2/legacy/legacy.hpp&gt;#include &lt;opencv2/nonfree/nonfree.hpp&gt;//opencv_nonfree模块：包含一些拥有专利的算法，如SIFT、SURF函数源码。 #include &quot;opencv2/core/core.hpp&quot;#include &quot;opencv2/features2d/features2d.hpp&quot;#include &quot;opencv2/highgui/highgui.hpp&quot;#include &lt;opencv2/nonfree/features2d.hpp&gt; using namespace cv;using namespace std; class hisEqt&#123;public: hisEqt::hisEqt(); hisEqt::~hisEqt();public: int w; int h; int nlen; int *pHis; float *pdf; //=====求像素分布概率密度==== void getPdf(); //======统计像素个数======= void getHis(unsigned char*imgdata); //==========画统计分布直方图=============== void drawHistogram(const float*pdf,Mat &amp;hist1); //===========直方图均衡化========== void hisBal(); //====直方图均衡化后的图像=== void imgBal(unsigned char* img);&#125;; hisEqt::hisEqt() :nlen(0)&#123; pHis = new int[256 * sizeof(int)]; memset(pHis, 0, 256 * sizeof(int)); pdf = new float[255 * sizeof(float)]; memset(pdf, 0, 255 * sizeof(float));&#125; hisEqt::~hisEqt()&#123; delete[]pHis; delete[]pdf;&#125; //======统计像素个数======= void hisEqt::getHis(unsigned char*imgdata)&#123; for (int i = 0; i&lt;nlen; i++) &#123; pHis[imgdata[i]]++; &#125;&#125; //=====求像素分布概率密度==== void hisEqt::getPdf()&#123; for (int k = 0; k&lt;256; k++) &#123; pdf[k] = pHis[k] / float(nlen); &#125;&#125; //===========直方图均衡化========== void hisEqt::hisBal()&#123; for (int k = 1; k&lt;256; k++) &#123; pdf[k] += pdf[k - 1]; &#125; for (int k = 0; k&lt;256; k++) &#123; pHis[k] = 255 * pdf[k]; &#125;&#125; //====直方图均衡化 void hisEqt::imgBal(unsigned char* img)&#123; for (int i = 0; i&lt;nlen; i++) &#123; img[i] = pHis[img[i]]; &#125;&#125; void hisEqt::drawHistogram(const float *pdf, Mat&amp; hist1)&#123; for (int k = 0; k&lt;256; k++) &#123; if (k % 2 == 0) &#123; Point a(k, 255), b(k, 255 - pdf[k] * 2550); line(hist1, a, b, Scalar(0, 0, 255), 1); &#125; else &#123; Point a(k, 255), b(k, 255 - pdf[k] * 2550); line(hist1, a, b, Scalar(0, 255, 0), 1); &#125; &#125;&#125; int main()&#123; Mat image = imread(&quot;Fig0651(a)(flower_no_compression).tif&quot;); if (!image.data) return -1; Mat hist2(256, 256, CV_8UC3, Scalar(0, 0, 0)); Mat hist1(256, 256, CV_8UC3, Scalar(0, 0, 0)); Mat imgOut = Mat(image.rows, image.cols, CV_8UC3, Scalar(0, 0, 0)); vector&lt;Mat&gt; planes; int chn = image.channels(); if (chn == 3) &#123; split(image, planes); &#125; while (chn) &#123; chn--; unsigned char* imageData = new unsigned char[sizeof(unsigned char)*(image.cols*image.rows)]; memcpy(imageData, planes[chn].data, planes[chn].cols*planes[chn].rows); hisEqt his;//自定义的类 his.nlen = image.rows*image.cols; his.getHis(imageData); his.getPdf(); // //======画原图直方图并保存============ his.drawHistogram(his.pdf, hist1); string pic_name = &quot;hisline&quot;; pic_name = pic_name + to_string(chn); pic_name=pic_name+ &quot;.jpg&quot;; imwrite(pic_name, hist1); his.hisBal(); his.getPdf(); // //======画均衡化后直方图并保存============ his.drawHistogram(his.pdf, hist2); string pic_name0 = &quot;his_balanceline&quot;; pic_name0 = pic_name0 + to_string(chn); pic_name0 = pic_name0 + &quot;.jpg&quot;; imwrite(pic_name0, hist2); // //=====图像均衡化=== his.imgBal(imageData); memcpy(planes[chn].data, imageData, planes[chn].cols*planes[chn].rows); delete[] imageData; imageData = NULL; &#125; merge(planes, imgOut);//单通道合并 imwrite(&quot;result.jpg&quot;, imgOut); return 0;&#125; 指数变换 先做归一化，再指数变换，最后反归一化 S=c*R^r通过合理的选择c和r可以压缩灰度范围，算法以c=1.0/255.0, r=2实现 Opencv代码：123456789101112131415161718192021222324252627void ExpEnhance(IplImage* img, IplImage* dst)&#123; // 由于oldPixel:[1,256],则可以先保存一个查找表 uchar lut[256] =&#123;0&#125;; double temp = 1.0/255.0; for ( int i =0; i&lt;255; i++) &#123; lut[i] = (uchar)(temp*i*i+0.5); &#125; for( int row =0; row &lt;img-&gt;height; row++) &#123; uchar *data = (uchar*)img-&gt;imageData+ row* img-&gt;widthStep; uchar *dstData = (uchar*)dst-&gt;imageData+ row* dst-&gt;widthStep; for ( int col = 0; col&lt;img-&gt;width; col++) &#123; for( int k=0; k&lt;img-&gt;nChannels; k++) &#123; uchar t1 = data[col*img-&gt;nChannels+k]; dstData[col*img-&gt;nChannels+k] = lut[t1]; &#125; &#125; &#125; &#125; 对数变换 低灰度值部分扩展，高灰度值部分压缩,来强调图像低灰度部分 s=c*log_{v+1}(1+v*r)底数为（v+1），实际输入范围为归一化的【0-1】，其输出也为【0-1】。底数越大，对低灰度部分的强调就越强，对高灰度部分的压缩也就越强 matlab代码12345678function dst_img=myLogEnhance(src_img,v) c=1.0; src_img = mat2gray(src_img,[0 255]); g =c*log2(1 + v*src_img)/log2(v+1); %反归一化 max=255; min=0; dst_img=uint8(g*(max-min)+min); 灰度拉伸 灰度拉升可以改善图像的动态范围 s=\frac{1}{1+\frac{m}{r+eps}^E}输入r为【0-1】，其输出s也为【0-1】 线性拉伸三段线性变换 突出感兴趣的目标或者灰度区间，相对抑制那些不感兴趣的灰度区域 1234567891011121314151617181920212223242526272829范围吧%横轴fa=20; fb=80;%纵轴ga=50; gb=230;function dst_img=myLinearEnhance(src_img,fa,fb,ga,gb) [height,width] = size(src_img);dst_img=uint8(zeros(height,width)); src_img=double(src_img); %三段斜率k1=ga/fa; k2=(gb- ga)/(fb- fa);k3=(255- gb)/(255- fb);for i=1:height for j=1:width if src_img(i,j) &lt;= fa dst_img(i,j)= k1*src_img(i,j); elseif fa &lt; src_img(i,j) &amp;&amp; src_img(i,j) &lt;= fb dst_img(i,j)= k2*( src_img(i,j)- fa)+ ga; else dst_img(i,j)= k3*( src_img(i,j)- fb)+ gb; end endenddst_img=uint8(dst_img); 频率域图像增强 傅里叶变换提供了一种从空间域到频域的转换手段，且用傅里叶反变换可以实现从频域到空间域的无损转换，不丢失任何信息 频域图像增强 类型 高通滤波器 突出图像的边界 低通滤波器 抑制图像噪声，改善图像质量 分析频谱图1234567891011121314clc; %清空命令行clear;%清空变量 I1=imread(&apos;beauty.jpg&apos;);subplot(1,2,1);imshow(I1);title(&apos;beauty.jpg&apos;); I2=fft2(I1);%计算二维FFTspectrum =fftshift(I2);%将零点移到中心temp= log(1+ abs(spectrum) ); %对幅值做 对数变换 以压缩动态范围subplot(1,2,2);imshow(temp,[]);title(&apos;FFT&apos;); 低频分量:主要对整副图像的强度的综合度量.灰度变化缓慢的特性高频分量:主要是对图像边缘和轮廓的度量.灰度变化快的特性 幅度图，看图像的频率分布，哪里亮那里暗，低频一般在图像中央如果只保留图像的中心点，则图像的细节会丢失，大致轮廓还在，不同区域好友不同的灰度如果保留远离中心的点，而去掉中心的幅度，则保留着图像的细节，而不同区域的灰度一样 频域低通滤波理想低通滤波器理想低通滤波器并不能很好的兼顾 滤除噪声 与 保留细节 这两个方面 理想低通滤波器：12345678910111213141516171819% 频域低通滤波器 imidealflpf.m%&#123;函数： function ff=imidealflpf(I,freq)函数说明：构造理想的频域低通滤波器（即 滤镜）参数说明：I：为输入原图像 freq:为截止频率返回值： 与I等大的频域滤镜 %&#125; function ff=imidealflpf(I,freq) [M,N]=size(I); ff=ones(M,N); for i=1:M for j=1:N if (sqrt ((i-M/2)^2+ (j-N/2)^2 ) &gt;freq) ff(i,j)=0; %高于截止频率 设为0 end end end 不同截止频率的滤波结果： 高斯低通滤波器12345678910111213141516171819%高斯低通滤波器滤镜 imgaussflpf.m%&#123;函数： function ff=imgaussflpf(I,sigma)函数说明：构造高斯低通滤镜参数说明：I：输入图像 sigma：标准差返回值：与原图像等大的高斯低通滤镜 %&#125; function ff=imgaussflpf(I,sigma)[M,N]=size(I); ff=ones(M,N); for i=1:M for j=1:N ff(i,j)= exp( -((i-M/2)^2+(j-N/2)^2) /2/(sigma^2) ); %高斯函数 end end 高斯滤波结果： 高斯相比于低通滤波，在有效抑制噪声的同时，图像的模糊程度更低 cankao 频域高通滤波器 图像锐化可以通过衰减频域中的低频信号来实现 1234567891011121314151617181920%高斯高通滤波器滤镜 imgaussfhpf.m%&#123;函数： function ff=imgaussfhpf(I,sigma)函数说明：构造高斯高通滤镜参数说明：I：输入图像 sigma：标准差返回值：与原图像等大的高斯高通滤镜 %&#125; function ff=imgaussfhpf(I,sigma)[M,N]=size(I); ff=ones(M,N); for i=1:M for j=1:N ff(i,j)= 1-exp( -((i-M/2)^2+(j-N/2)^2) /2/(sigma^2) ); % 1-(gauss) end end 1、高斯高通滤波器可以较好的提取边缘信息；2、sigma越小，Gauss高通的截止频率越低，通过的低频成分越多，边缘提取越不精确，会包含更多的非边缘信息；（要求太低，多了浑水摸鱼者）3、sigma越大，边缘提取越精确，但可能包含不完整的边缘信息。（要求太高，有了漏网之鱼） 拉普拉斯滤波器1234567891011121314151617181920%laplace滤波器滤镜 imlapf.m%&#123;函数： function ff=imlapf(I)函数说明：构造laplace滤镜参数说明：I：输入图像 返回值：与原图像等大的laplace滤镜 %&#125; function ff=imlapf(I)[M,N]=size(I); ff=ones(M,N); for i=1:M for j=1:N ff(i,j)= -((i-M/2)^2+(j-N/2)^2) % end end 图像处理评价指标基于误差灵敏度评价算法：最简单的质量评价算法就是均方差(Mean Squared Error, MSE)和峰值信噪比(Peak Signal- Noise Ratio, PSNR)。MSE 和 PSNR 计算复杂度小，易于实现，在图像处理领域中广泛应用。但缺点是它们给出的数值与图像的感知质量之间没有必然联系。 峰值信噪比-PSNR图像压缩等领域信号重建质量的评价 MSE为当前图像 X 和参考图像 Y 的均方误差,H、W 分别表示图像的高和宽；n为每像素的比特数，一般取8，即像素灰阶数为256。PSNR的单位是dB，数值越大表示失真越小。 matlab代码：123456789101112131415function pnsr_result = psnr(img_ref,img_in) % img_ref is a high reference quality image % img_in is the denoise image % pnsr_result is the PSNR of the denoise image width = size(img_ref,2); heigh = size(img_ref,1); if( width ~= size(img_in,2) || heigh ~= size(img_in,1) ) disp(&apos;Please check whether the input image and reference image have same size&apos;); return end [a,b]=size(img_ref); XX=double(img_ref) - double(img_in); mse_value = sum(sum( XX.^2 ))/(a*b); pnsr_result = 10*log10( 255*255 / mse_value ); end SSIM信噪比（SNR）信噪比就是有用信号与噪声信号的比值 snr=10*log_{10}\frac{sigma(I2)}{sigma(I2-I1)}12345678910111213141516171819202122function snr=SNR2(I,In)% 计算噪声比% I :original signal% In:noisy signal% snr=10*log10(sigma2(I2)/sigma2(I2-I1)) [~,~,nchannel]=size(I);snr=0;I=double(I);In=double(In);if nchannel==1 Ps=sum(sum((I-mean(mean(I))).^2));%signal power Pn=sum(sum((I-In).^2));%noise power snr=10*log10(Ps/Pn);elseif nchannel==3 for i=1:3 Ps=sum(sum((I(:,:,i)-mean(mean(I(:,:,i)))).^2));%signal power Pn=sum(sum((I(:,:,i)-In(:,:,i)).^2));%noise power snr=snr+10*log10(Ps/Pn); end snr=snr/3;end 基于结构相似度评价算法其他曝光过度问题处理计算当前图像的反相（255-image)，然后取当前图像和反相图像的较小者为当前像素位置的值。 min(image,(255-image))加Masaic算法原理：用中心像素来表示邻域像素Opencv代码：123456789101112131415161718192021222324252627282930313233343536uchar getPixel( IplImage* img, int row, int col, int k)&#123; return ((uchar*)img-&gt;imageData + row* img-&gt;widthStep)[col*img-&gt;nChannels +k];&#125; void setPixel( IplImage* img, int row, int col, int k, uchar val)&#123; ((uchar*)img-&gt;imageData + row* img-&gt;widthStep)[col*img-&gt;nChannels +k] = val;&#125;--// nSize:为尺寸大小，奇数// 将邻域的值用中心像素的值替换void Masic(IplImage* img, IplImage* dst, int nSize)&#123; int offset = (nSize-1)/2; for ( int row = offset; row &lt;img-&gt;height - offset; row= row+offset) &#123; for( int col= offset; col&lt;img-&gt;width - offset; col = col+offset) &#123; int val0 = getPixel(img, row, col, 0); int val1 = getPixel(img, row, col, 1); int val2 = getPixel(img, row, col, 2); for ( int m= -offset; m&lt;offset; m++) &#123; for ( int n=-offset; n&lt;offset; n++) &#123; setPixel(dst, row+m, col+n, 0, val0); setPixel(dst, row+m, col+n, 1, val1); setPixel(dst, row+m, col+n, 2, val2); &#125; &#125; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习_分类_数据聚类]]></title>
    <url>%2F2018%2F07%2F16%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E5%88%86%E7%B1%BB_%E6%95%B0%E6%8D%AE%E8%81%9A%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[机器学习分类数据聚类 K-Means（k-平均或k-均值）可以称的上是知名度最高的一种聚类算法 123456789首先，我们确定要几个的聚类（cluster，也称簇），并为它们随机初始化一个各自的聚类质心点（cluster centroids），它在上图中被表示为“X”。要确定聚类的数量，我们可以先快速看一看已有的数据点，并从中分辨出一些独特的数据。其次，我们计算每个数据点到质心的距离来进行分类，它跟哪个聚类的质心更近，它就被分类到该聚类。需要注意的是，初始质心并不是真正的质心，质心应满足聚类里每个点到它的欧式距离平方和最小这个条件。因此根据这些被初步分类完毕的数据点，我们再重新计算每一聚类中所有向量的平均值，并确定出新的质心。最后，重复上述步骤，进行一定次数的迭代，直到质心的位置不再发生太大变化。当然你也可以在第一步时多初始化几次，然后选取一个看起来更合理的点节约时间。K-Means的优点是速度非常快，因为我们所做的只是计算数据点和质心点之间的距离，涉及到的计算量非常少！因此它的算法时间复杂度只有O(n)。另一方面，K-Means有两个缺点。一是你必须一开始就决定数据集中包含多少个聚类。这个缺点并不总是微不足道的，理想情况下，我们的目标其实是用一种算法来分类这些数据，并从结果中观察出一些规律，而不是限制几个条件强行聚类。二是一开始质心点的选取是随机的，算法可能会初始化出差异巨大的点。这个缺点导致的结果是质心点的位置不可重复且缺乏一致性。K-Medians是与K-Means相关的另一种聚类算法，不同之处在于它使用簇的中值向量来重新计算质心点。该方法对异常值不敏感（因为使用中值），但在较大数据集上运行时速度会慢很多，因为每次计算中值向量，我们都要重新排序。 Mean-Shift聚类12345678Mean shift算法，又称均值漂移算法，这是一种基于核密度估计的爬山算法，可用于聚类、图像分割、跟踪等。它的工作原理基于质心，这意味着它的目标是定位每个簇/类的质心，即先算出当前点的偏移均值，将该点移动到此偏移均值，然后以此为新的起始点，继续移动，直到满足最终的条件（找出最密集的区域）。1、为了理解均值漂移，我们可以像上图一样想象二维空间中的一组数据点，然后先随机选择一个点C，以它为圆心画一个半径为r的圆开始移动。之前提到了，这是个爬山算法，它的核函数会随着迭代次数增加逐渐向高密度区域靠近。2、在每轮迭代中，算法会不断计算圆心到质心的偏移均值，然后整体向质心靠近。漂移圆圈内的密度与数据点数成正比。到达质心后，算法会更新质心位置，并继续让圆圈向更高密度的区域靠近。3、当圆圈到达目标质心后，它发现自己无论朝哪个方向漂移都找不到更多的数据点，这时我们就认为它已经处于最密集的区域。4、这时，算法满足了最终的条件，即退出。Mean-Shift不需要实现定义聚类数量，因为这些都可以在计算偏移均值时得出。这是一个巨大的优势。同时，算法推动聚类中心在向密度最大区域靠近的效果也非常令人满意，这一过程符合数据驱动型任务的需要，而且十分自然直观。如果要说Mean-Shift有什么缺点，那就是对高维球区域的半径r的定义，不同选择可能会产生高度不同的影响。 EM聚类1234567891011均值→质心，方差→椭圆聚类，权重→聚类大小。K-Means算法的主要缺点之一是它直接用了距离质心的平均值。1、首先，我们确定聚类的数量（如K-Means），并随机初始化每个聚类的高斯分布参数。你也可以尝试通过快速查看数据来为初始参数提供更好的猜测，但从上图可以看出，这其实不是很必要，因为算法会很快进行优化。2、其次，根据每个聚类的高斯分布，计算数据点属于特定聚类的概率。如果数据点越接近高斯质心，那它属于该聚类的概率就越高。这很直观，因为对于高斯分布，我们一般假设大部分数据更靠近聚类质心。3、在这些概率的基础上，我们为高斯分布计算一组新的参数，使聚类内数据点的概率最大化。我们用数据点位置的加权和来计算这些新参数，其中权重就是数据点属于聚类的概率。为了可视化这个过程，我们可以看看上面的图片，特别是黄色的聚类。第一次迭代中，它是随机的，大多数黄点都集中在该聚类的右侧。当我们按概率计算加权和后，虽然聚类的中部出现一些点，但右侧的比重依然很高。随着迭代次数增加，黄点在聚类中的位置也完成了“右下→左下”的移动。因此，标准差的变化调整着聚类的形状，以使它能更适合数据点的分布。4、迭代步骤2和步骤3，直至收敛。GMM有两个关键优势。首先它比K-Means更灵活，由于标准差的引入，最后聚类的形状不再局限于圆形，它还可以是大小形状不一的椭圆形——K均值实际上是GMM的一个特例，其中每个聚类的协方差在所有维上都接近0。其次，权重的引入为同一点属于多个聚类找到了解决方案。如果一个数据点位于两个聚类的重叠区域，那我们就可以简单为它定义一个聚类，或者计算它属于X聚类的百分比是多少，属于Y聚类的百分比是多少。简而言之，GMM支持混合“成员”。谈及缺点，和K-Means相比，GMM每一步迭代的计算量比较大。另外，它的求解办法基于EM算法，因此有可能陷入局部极值，需要经过多次迭代。]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习_最优化_数学]]></title>
    <url>%2F2018%2F07%2F16%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E6%9C%80%E4%BC%98%E5%8C%96_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[机器学习最优化数学 泰勒展开式 期望概率加权下的平均值离散型：$E(x)=\sumix_ip_i$连续型：$E(x)=\int{-\infty}^{\infty}xf(x)dx$ 极大似然估计取对数：$lnL(\theta1,\theta_2,…,\theta_k=\sum{i=1}^nlnf(x,\theta_1,\theta_2,…,\theta_k))$求驻点：$\partial{lnL(\theta)}/\partial{\theta_i}=0,i=1,2,…k$ 概率论中心极限定理：设n个随机变量$X_1,X_2,…,X_n$相互独立，均具有相同的数学期望与方差，即$E(X_i)=\mu;D(X_i)=\sigma^2$, Y_n=X_1+X_2+...+X_nZ_n=\frac{Y_n-E(Y_n)}{\sqrt{D(Y_n)}}=\frac{Y_n-n\mu}{\sqrt{n}\sigma}→N(0,1)随机变量$Z_n$为n个随机变量$X_1,X_2,…,X_n$的规范和设从均值为$\mu$、方差为$\sigma^2$（有限）的任意一个总体中抽取样本量为$n$的样本，当$n$充分⼤大时，样本均值的抽样分布$\frac{Y_n}{n}$近似服从于均值为$\mu$、方差为$\sigma^2$的正态分布。 中心极限定理，把那些对结果影响⽐比较小的变量（假设独⽴立同分布）之和认为服从正态分布是合理理的。 高斯分布输入值$x^i$，预测值$\theta^Tx^i$，真实值$y^i$，误差$\epsilon^{i}$ y^i=\theta^Tx^i+\epsilon^{i}根据中心极限定理，认为变量之和服从高斯分布,即 \epsilon^{i} = y^i-\theta^Tx^i则，x,y的条件概率为 p(y^i|x^i;\theta) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y^i-\theta^Tx^i)^2}{2\sigma^2})矩阵论最优化]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>最优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征提取——局部特征]]></title>
    <url>%2F2018%2F07%2F16%2F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96_%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81%2F</url>
    <content type="text"><![CDATA[特征提取——局部特征 LOG,HOG,DOG微分算子在近圆的斑点检测方面效果很好 HOG特征https://blog.csdn.net/coming_is_winter/article/details/72850511https://blog.csdn.net/zouxy09/article/details/7929348/123456总结：Dalal提出的Hog特征提取的过程：把样本图像分割为若干个像素的单元（cell），把梯度方向平均划分为9个区间（bin），在每个单元里面对所有像素的梯度方向在各个方向区间进行直方图统计，得到一个9维的特征向量，每相邻的4个单元构成一个块（block），把一个块内的特征向量联起来得到36维的特征向量，用块对样本图像进行扫描，扫描步长为一个单元。最后将所有块的特征串联起来，就得到了人体的特征。例如，对于64*128的图像而言，每16*16的像素组成一个cell，每2*2个cell组成一个块，因为每个cell有9个特征，所以每个块内有4*9=36个特征，以8个像素为步长，那么，水平方向将有7个扫描窗口，垂直方向将有15个扫描窗口。也就是说，64*128的图片，总共有36*7*15=3780个特征。特征总数： 一个cell有9个特征（9个梯度方向），每个特征cell块里有 num*9个特征，步长像素规格：（列像素数-步长）/步长*（行像素数-步长）/步长，总特征数:（列像素数-步长）/步长*（行像素数-步长）/步长*num*9 LOG特征1图像与某一个二维函数进行卷积运算实际就是求取图像与这一函数的相似性。同理，图像与高斯拉普拉斯函数的卷积实际就是求取图像与高斯拉普拉斯函数的相似性。当图像中的斑点尺寸与高斯拉普拉斯函数的形状趋近一致时，图像的拉普拉斯响应达到最大。 Laplace可以用来检测图像中的局部极值点，但是对噪声敏感，所以在我们对图像进行Laplace卷积之前，我们用一个高斯低通滤波对图像进行卷积，目标是去除图像中的噪声点123456789101112先对图像f(x,y)用方差为σ的高斯核进行高斯滤波，去除图像中的噪点。L(x,y;σ)=f(x,y)∗G(x,y;σ)G(x,y;σ)高斯核然后对图像的拉普拉斯图像则为：∇^2=(∂^2L/∂^x2)+(∂^2L/∂y^2)而实际上有下面等式：∇^2[G(x,y)∗f(x,y)]=∇^2[G(x,y)]∗f(x,y)我们可以先求高斯核的拉普拉斯算子，再对图像进行卷积 使用LoG虽然能较好的检测到图像中的特征点，但是其运算量过大，通常可使用DoG（差分高斯，Difference of Gaussina）来近似计算LoG Haar特征Haar特征分为三类：边缘特征、线性特征、中心特征和对角线特征，组合成特征模板。特征模板内有白色和黑色两种矩形，并定义该模板的特征值为白色矩形像素和减去黑色矩形像素和 Haar-like特征https://blog.csdn.net/zouxy09/article/details/7929570 1234567积分图就是只遍历一次图像就可以求出图像中所有区域像素和的快速算法，大大的提高了图像特征值计算的效率。 积分图主要的思想是将图像从起点开始到各个点所形成的矩形区域像素之和作为一个数组的元素保存在内存中，当要计算某个区域的像素和时可以直接索引数组的元素，不用重新计算这个区域的像素和，从而加快了计算（这有个相应的称呼，叫做动态规划算法）。积分图能够在多种尺度下，使用相同的时间（常数时间）来计算不同的特征，因此大大提高了检测速度。 我们来看看它是怎么做到的。 积分图是一种能够描述全局信息的矩阵表示方法。积分图的构造方式是位置（i,j）处的值ii(i,j)是原图像(i,j)左上角方向所有像素的和： 归一化图像123i¯(x,y)=(i(x,y)−μ)/cσ公式中i¯(x,y)表示归一化之后的图像，而i(x,y)表示原始的图像，其中μ表示图像的均值，而σ表示图像的标准差σ2=(1/N)∑x2−μ2 2是平方 SIFT特征SIFT的全称是Scale Invariant Feature Transform，尺度不变特征变换(物体怎么转，人都能识别)。SIFT特征对旋转、尺度缩放、亮度变化等保持不变性，是一种非常稳定的局部特征。 有4个主要步骤 1、尺度空间的极值检测 搜索所有尺度空间上的图像，通过高斯微分函数来识别潜在的对尺度和选择不变的兴趣点。12345678910$$$L(x,y,σ)=G(x,y,σ)∗I(x,y)$为了有效的在尺度空间检测到稳定的关键点，提出了高斯差分尺度空间（DOG scale-space）。利用不同尺度的高斯差分核与图像卷积生成。构造高斯差分尺度空间(DOG scale-space): $$D(x,y,σ)=(G(x,y,kσ)−G(x,y,σ))∗I(x,y)=L(x,y,kσ)−L(x,y,σ)$$σ 是尺度坐标。σ大小决定图像的平滑程度，大尺度对应图像的概貌特征，小尺度对应图像的细节特征。大的σ值对应粗糙尺度(低分辨率)，反之，对应精细尺度(高分辨率)。对于一幅图像I，建立其在不同尺度(scale)的图像,后面每个采样都是原图的1/4倍。每个点都要与邻域的点，上下相邻尺度的点做比较（9+8+9）26个点作比较（以确保在尺度空间和二维图像空间都检测到极值点）。一个点如果在DOG尺度空间本层以及上下两层的26个领域中是最大或最小值时，就认为该点是图像在该尺度下的一个特征点 2、特征点定位 在每个候选的位置上，通过一个拟合精细模型来确定位置尺度，关键点的选取依据他们的稳定程度。1拟和三维二次函数以精确确定关键点的位置和尺度，同时去除低对比度的关键点和不稳定的边缘响应点(因为DoG算子会产生较强的边缘响应)，以增强匹配稳定性、提高抗噪声能力 用Harris Corner检测参考文章 3、特征方向赋值 基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向，后续的所有操作都是对于关键点的方向、尺度和位置进行变换，从而提供这些特征的不变性。1每个特征点计算一个方向，依照这个方向做进一步的计算， *利用关键点邻域像素的梯度方向分布特性为每个关键点指定方向参数，使算子具备旋转不变性。 m(x,y)=(L(x+1,y)−L(x−1,y))2+(L(x,y+1)−L(x,y−1))2√θ(x,y)=atan2(L(x,y+1)−L(x,y−1)L(x+1,y)−L(x−1,y)每个关键点有三个信息：位置、所处尺度、方向。由此可以确定一个SIFT特征区域。4、特征点描述 在每个特征点周围的邻域内，在选定的尺度上测量图像的局部梯度，这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变换。 高斯函数是唯一可行的尺度空间核 尺度空间多分辨率图像金字塔:121、对原始图像进行平滑2、对处理后的图像进行降采样（通常是水平、垂直方向的1/2）降采样后得到一系列不断尺寸缩小的图像。显然，一个传统的金字塔中，每一层的图像是其上一层图像长、高的各一半。多分辨率的图像金字塔虽然生成简单，但其本质是降采样，图像的局部特征则难以保持，也就是无法保持特征的尺度不变性。 高斯尺度空间：12345678图像的模糊程度来模拟人在距离物体由远到近时物体在视网膜上成像过程，距离物体越近其尺寸越大图像也越模糊，这就是高斯尺度空间，使用不同的参数模糊图像（分辨率不变）图像和高斯函数进行卷积运算，图像模糊，使用不同的“高斯核”可得到不同模糊程度的图像L(x,y,σ)=G(x,y,σ)∗I(x,y)其中G(x,y,σ)是高斯核函数G(x,y,σ)=（1/2Πσ^2）e^((x^2+y^2)/(2σ^2)) 构建尺度空间的目的是为了检测出在不同的尺度下都存在的特征点，而检测特征点较好的算子是Δ^2G(高斯拉普拉斯,LoG） DoG特征使用LoG虽然能较好的检测到图像中的特征点，但是其运算量过大，通常可使用DoG（差分高斯，Difference of Gaussina）来近似计算LoG。 DOG可以看作为LOG的一个近似，但是它比LOG的效率更高。设k为相邻两个高斯尺度空间的比例因子，则DoG的定义： 1D(x,y,σ)=[G(x,y,kσ)−G(x,y,σ)]∗I(x,y)=L(x,y,kσ)−L(x,y,σ) L(x,y,σ) 是图像的高斯尺度空间将相邻的两个高斯空间的图像相减就得到了DoG的响应图像 Harris角点特征提取Harris角点检测是一种基于图像灰度的一阶导数矩阵检测方法。检测器的主要思想是局部自相似性/自相关性，即在某个局部窗口内图像块与在各个方向微小移动后的窗口内图像块的相似性。 1、角点可以是两个边缘的角点；&lt;/br&gt;2、角点是邻域内具有两个主方向的特征点；1人眼对角点的识别通常是在一个局部的小区域或小窗口完成的。如果在各个方向上移动这个特征的小窗口，窗口内区域的灰度发生了较大的变化，那么就认为在窗口内遇到了角点。如果这个特定的窗口在图像各个方向上移动时，窗口内图像的灰度没有发生变化，那么窗口内就不存在角点；如果窗口在某一个方向移动时，窗口内图像的灰度发生了较大的变化，而在另一些方向上没有发生变化，那么，窗口内的图像可能就是一条直线的线段。 x^{y^z}=(1+{\rm e}^x)^{-2xy^w}sqrt() 结论：1、增大α的值，将减小角点响应值R，降低角点检测的灵性，减少被检测角点的数量；减小α值，将增大角点响应值R，增加角点检测的灵敏性，增加被检测角点的数量。&lt;/br&gt;2、Harris角点检测算子对亮度和对比度的变化不敏感&lt;/br&gt;3、Harris角点检测算子具有旋转不变性&lt;/br&gt;4、Harris角点检测算子不具有尺度不变性&lt;/br&gt;]]></content>
      <tags>
        <tag>图像处理</tag>
        <tag>特征提取</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征提取——颜色特征]]></title>
    <url>%2F2018%2F07%2F16%2F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96_%E9%A2%9C%E8%89%B2%E7%89%B9%E5%BE%81%2F</url>
    <content type="text"><![CDATA[特征提取——颜色特征 颜色直方图OpenCV之颜色空间: 颜色空间RGB（Red 红色，Green 绿色，Blue 蓝色） R的取值范围：0-255 G的取值范围：0-255 B的取值范围：0-255 颜色空间HSV （Hue 色相，Saturation 饱和度，intensity 亮度） H的取值范围：0-179 S的取值范围：0-255 V的取值范围：0-255 颜色空间HLS (Hue 色相，lightness 亮度，Saturation 饱和度) H的取值范围：0-179 L的取值范围：0-255 S的取值范围：0-255 颜色矩这种方法的数学基础在于图像中任何的颜色分布均可以用它的矩来表示。此外，由于颜色分布信息主要集中在低阶矩中，因此仅采用颜色的一阶矩（mean）、二阶矩（variance）和三阶矩（skewness）就足以表达图像的颜色分布。与颜色直方图相比，该方法的另一个好处在于无需对特征进行向量化。图像的颜色矩一共只需要9个分量（3个颜色分量，每个分量上3个低阶矩）颜色矩常和其它特征结合使用，而且一般在使用其它特征前起到过滤缩小范围（narrow down）的作用。 一阶矩(均值,mean),反映图像明暗程度1u=(1/N)sum(Pij) 二阶矩(方差,viarance),反映图像颜色分布范围1a=sqrt(((1/N)sum(Pij-u)^2),2) 三阶矩(斜度,skewness),反映图像颜色分布对称性1a=sqrt(((1/N)sum(Pij-u)^3),3)]]></content>
      <tags>
        <tag>图像处理</tag>
        <tag>特征提取</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习_概率论_数学基础]]></title>
    <url>%2F2018%2F07%2F16%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E6%A6%82%E7%8E%87%E8%AE%BA_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[机器学习_概率论 概念先验概率：A的边缘概率表示为P(A)，B的边缘概率表示为P(B) 联合概率:表示两个事件共同发生的概率。A与B的联合概率表示为P(A∩B)或者P(A,B)。 条件概率（又称后验概率）：事件A在另外一个事件B已经发生条件下的发生概率。条件概率表示为P(A|B)，读作“在B条件下A的概率”,。 123456789考虑一个问题：P(A|B)是在B发生的情况下A发生的可能性。首先，事件B发生之前，我们对事件A的发生有一个基本的概率判断，称为A的先验概率，用P(A)表示；其次，事件B发生之后，我们对事件A的发生概率重新评估，称为A的后验概率，用P(A|B)表示；类似的，事件A发生之前，我们对事件B的发生有一个基本的概率判断，称为B的先验概率，用P(B)表示；同样，事件A发生之后，我们对事件B的发生概率重新评估，称为B的后验概率，用P(B|A)表示。 贝叶斯公式贝叶斯定理 P(B_i|A) = \frac{P(B_i)P(A|B_i)}{\sum_{j=1}^n{P(B_j)}{P(A|B_j)}}贝叶斯公式 P(A|B)=\frac{P(B|A)P(A)}{P(B)}因为联合概率$P(A,B)$ P(A,B)=P(A|B)*P(B)=P(B|A)*P(A)假设B事件是由A1、A2事件导致的 P(B)=P(B|A1)P(A1)+P(B|A2)P(A2)理解：P(规律|现象)=P(现象|规律)P(规律)/P(现象) 案例1假设有两个班级其中1班有男生30人，女生20人；2班有男生25人、女生25人。体育老师抓到一个抽烟的男生，该男生打死也不告诉体育老师是那个班的。问题来了体育老师怎么判断该男生来自那个班？ 先将1班和2班标记为事件A1和事件A2，男生标记为事件B 那么我们所求的就是P(A1丨B)和P(A2丨B) 因为只有2个班那么我们先验概率P(A1)=P(A2)=50%；来自1班男生的概率P(B丨A1)=3/5：来自2班男生的概率P(B丨A2)=1/2 那么我们求出P(B)就可以代入公式得到结果: P(B)=P(B丨A1)P(A1) P(B丨A2)P(A2)=0.55 P(A1丨B)=P(B丨A1)P(A1)/P(B)=0.6*0.5/0.55=55% P(A2丨B)=P(B丨A2)P(A2)/P(B)=0.5*0.5/0.55=45% 由结果我们可以得出：该男生来自1班的概率从50%（先验概率）上升到55%（后验概率） 案例2一种癌症，得了这个癌症的人被检测出为阳性的几率为90%，未得这种癌症的人被检测出阴性的几率为90%，而人群中得这种癌症的几率为1%，一个人被检测出阳性，问这个人得癌症的几率为多少？ 我们用 A 表示事件 “测出为阳性”, 用 $B_1$ 表示“得癌症”, $B_2$ 表示“未得癌症”。 得到以下信息:$P(A|B_1)=0.9$得癌症的人检测阳性 0.9$P(A|B_2)=0.1$得癌症的人检测阴性 0.1$P(B_1)=0.01$得癌症的概率 0.01$P(B_2)=0.99$未得癌症的概率 0.99 计算：人群中检测为阳性且得癌症的几率$P(B_1,A)$，联合概率 P(B_1,A)=P(B_1)*P(A|B_1)=0.01*0.9=0.009检测阳性并且未得癌症概率$P(B_2,A)$，联合概率 P(B_2,A)=P(B_2)*P(A|B_2)=0.99*0.1=0.099目前状态是已经检测除阳性，求患癌症概率$P(B_1|A)$$P(B_1|A)=\frac{0.009}{0.099+0.009}=0.083$未患癌症概率$P(B_2|A)$$P(B_2|A)=\frac{0.099}{0.099+0.009}=0.917$]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理_图像滤波]]></title>
    <url>%2F2018%2F07%2F16%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86_%E5%9B%BE%E5%83%8F%E6%BB%A4%E6%B3%A2%2F</url>
    <content type="text"><![CDATA[图像滤波 噪声加性噪声一般指热噪声、散弹噪声等，它们与信号的关系是相加，不管有没有信号，噪声都存在。 高斯白噪声包括热噪声和散粒噪声。在通信信道测试和建模中，高斯噪声被用作加性白噪声以产生加性白高斯噪声。 加性高斯白噪声只是白噪声的一种，另有泊松白噪声等,加性高斯白噪声在通信领域中指的是一种各频谱分量服从均匀分布（即白噪声），且幅度服从高斯分布的噪声信号。因其可加性、幅度服从高斯分布且为白噪声的一种而得名。 而乘性噪声一般由信道不理想引起，它们与信号的关系是相乘，信号在它在，信号不在他也就不在。 一般通信中把加性随机性看成是系统的背景噪声； 而乘性随机性看成系统的时变性（如衰落或者多普勒）或者非线性所造成的。 空域滤波空域滤波可以用于非线性滤波，但是频域滤波不能用于非线性滤波 图像滤波 空域 线性滤波 均值滤波 - - - 非线性滤波 中值滤波 双边滤波 滤波模板图像滤波 模板：12345线性平均滤波：1|0 1 0 |-|1 1 1 |5|0 1 0 | 图像锐化 模板：123456789锐化滤波：图像锐化一般是通过微分运算来实现的|-1 0 1||-1 0 1||-1 0 1|| 1 1 1|| 0 0 0||-1 -1 -1| 方向滤波器-sobel算子123456789x轴：|-1 0 1||-2 0 2||-1 0 1|y轴：|-1 -2 -1|| 0 0 0|| 1 2 1| Scharr算子123456789x轴：|-3 0 3||-10 0 10||-3 0 3|y轴：|-3 -10 -3|| 0 0 0|| 3 10 3| 线性空域滤波线性空域滤波指的是像素的输出值是计算该像素邻域内像素值的线性组合线性滤波中滤波模板也称为卷积模板 模板卷积模板卷积的主要步骤包括如下几个步骤， 1) 将模板在图像中进行遍历，将模板中心和各个像素位置重合； 2) 将模板的各个系数与模板对应像素值进行相乘； 3) 将所有的乘积相加，并将求和结果赋值于模板中心对应的像素 延拓模板的行或列就会超出图像之外，因此常常采用延拓的方式解决外边界问题。常用的方法有四种，分别是补零、重复、对称和循环方式。1234补零是指通过补零来扩展图像；重复是指通过复制外边界的值来扩展图像；对称是指通过镜像反射外边界的值来扩展图像；循环是指将图像看成二维周期函数的一个周期来扩展。 均值滤波高斯滤波高斯滤波器宽度(决定着平滑程度)是由参数σ表征的，而且σ和平滑程度的关系是非常简单的．σ越大，高斯滤波器的频带就越宽，平滑程度就越好．通过调节平滑程度参数σ 高斯分布：$h(x,y)=e^-(\frac{x^2+y^2}{2a^2})$ 双边滤波一种非线性的滤波方法，是结合图像的空间邻近度和像素相似度的的一种折中处理。它是一种保持边缘的非迭代平滑滤波方法。中心像素的距离和灰度差值的增大，邻域像素的权系数逐渐减小 优点：保持边缘性能良好，对低频信息滤波良好缺点：不能处理高频信息 假设高斯函数表达式如下： W_ij=\frac{1}{K_i}e^-\frac{(x_j-x_i)^2}{σ^2_G}K是归一化的常量，W是权重，权重只跟像素之间的空间距离有关系。 双边滤波器: W_ij=\frac{1}{K_i}e^-\frac{(x_j-x_i)^2}{σ^2_G}e^-\frac{(I_j-I_i)^2}{σ^2_r}中值滤波中值滤波是统计排序滤波的一种，中值滤波对椒盐噪声效果好；滤波图像边缘信息好，边缘清晰|统计排序滤波||||-|-|-||最大值滤波|有效地滤除椒噪声(黑色)|寻找最亮点，亮化图片||最小值滤波|有效地滤除盐噪声(白色)|寻找最暗点，暗化图片||自适应中值滤波|有效地滤除椒盐噪声|钝化图像、去除噪音| 操作步骤： 1) 将模板在图像中遍历 2) 将模板对应的邻域内像素的灰度值排序 3) 查找中间值，将其赋于模板中心对应的像素 频域滤波可以用图像增强，首先把图像通过傅里叶变换将图像从空间域转换到频率域，频域处理，反傅里叶变换转到空间域 C++代码均值滤波123456789101112131415void meanFilter (unsigned char* corrupted, unsigned char* smooth, int width, int height) &#123; memcpy ( smooth, corrupted, width*height*sizeof(unsigned char) ); for (int j=1;j&lt;height-1;j++) &#123; for (int i=1;i&lt;width-1;i++) &#123; smooth [ j*width+i ] = ( corrupted [ (j-1)*width+(i-1) ] + corrupted [ (j-1)*width+i] + corrupted [ (j-1)*width+(i+1) ] + corrupted [ j*width+(i-1) ] + corrupted [ j*width+i] + corrupted [ j*width+(i+1) ] + corrupted [ (j+1)*width+(i-1) ] + corrupted [ (j+1)*width+i] + corrupted [ (j+1)*width+(i+1) ] ) / 9; &#125; &#125; &#125; 中值滤波1234567891011121314151617181920212223242526272829void medianFilter (unsigned char* corrupted, unsigned char* smooth, int width, int height) &#123; memcpy ( smooth, corrupted, width*height*sizeof(unsigned char) ); for (int j=1;j&lt;height-1;j++) &#123; for (int i=1;i&lt;width-1;i++) &#123; int k = 0; unsigned char window[9]; for (int jj = j - 1; jj &lt; j + 2; ++jj) for (int ii = i - 1; ii &lt; i + 2; ++ii) window[k++] = corrupted[jj * width + ii]; // Order elements (only half of them) for (int m = 0; m &lt; 5; ++m) &#123; int min = m; for (int n = m + 1; n &lt; 9; ++n) if (window[n] &lt; window[min]) min = n; // Put found minimum element in its place unsigned char temp = window[m]; window[m] = window[min]; window[min] = temp; &#125; smooth[ j*width+i ] = window[4]; &#125; &#125; &#125;]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阈值分割_大津法_分水岭]]></title>
    <url>%2F2018%2F07%2F16%2F%E9%98%88%E5%80%BC%E5%88%86%E5%89%B2_%E5%A4%A7%E6%B4%A5%E6%B3%95_%E5%88%86%E6%B0%B4%E5%B2%AD%2F</url>
    <content type="text"><![CDATA[阈值分割大津法分水岭 大津法(最大类间方差法,Otsu)一种基于全局的二值化算法，它是根据图像的灰度特性,将图像分为前景和背景两个部分 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &quot;stdio.h&quot;#include &quot;cv.h&quot;#include &quot;highgui.h&quot;#include &quot;Math.h&quot;int Otsu(IplImage* src);int main()&#123; IplImage* img = cvLoadImage(&quot;lena.jpg&quot;,0); //获取灰度图像img IplImage* dst = cvCreateImage(cvGetSize(img), 8, 1); int threshold = Otsu(img); //调用大津法求出最佳阈值 printf(&quot;otsu threshold = %d\n&quot;, threshold); cvThreshold(img, dst, threshold, 255, CV_THRESH_BINARY); //用otsu的阈值二值化 cvNamedWindow( &quot;img&quot;, 1 ); cvNamedWindow( &quot;dst&quot;, 1 ); cvShowImage(&quot;img&quot;, img); cvShowImage(&quot;dst&quot;, dst); cvWaitKey(-1); cvReleaseImage(&amp;img); cvReleaseImage(&amp;dst); cvDestroyWindow( &quot;img&quot; ); cvDestroyWindow( &quot;dst&quot; ); return 0;&#125;int Otsu(IplImage* src) &#123; int height=src-&gt;height; int width=src-&gt;width; //histogram float histogram[256] = &#123;0&#125;; for(int i=0; i &lt; height; i++) &#123; unsigned char* p=(unsigned char*)src-&gt;imageData + src-&gt;widthStep * i; for(int j = 0; j &lt; width; j++) &#123; histogram[*p++]++; &#125; &#125; //normalize histogram &amp; average pixel value int size = height * width; float u =0; for(int i = 0; i &lt; 256; i++) &#123; histogram[i] = histogram[i] / size; u += i * histogram[i]; //整幅图像的平均灰度 &#125; int threshold; float maxVariance=0; float w0 = 0, avgValue = 0; for(int i = 0; i &lt; 256; i++) &#123; w0 += histogram[i]; //假设当前灰度i为阈值, 0~i 灰度像素所占整幅图像的比例即前景比例 avgValue += i * histogram[i]; //avgValue/w0 = u0 float t = avgValue/w0 - u; //t=u0-u float variance = t * t * w0 /(1 - w0); if(variance &gt; maxVariance) &#123; maxVariance = variance; threshold = i; &#125; &#125; return threshold; &#125;]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征提取——纹理特征]]></title>
    <url>%2F2018%2F07%2F16%2F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96_%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81%2F</url>
    <content type="text"><![CDATA[特征提取——纹理特征 LBP图像特征图像处理之特征提取（二）之LBP特征简单梳理https://blog.csdn.net/coming_is_winter/article/details/72859957https://blog.csdn.net/zouxy09/article/details/7929531LBP特征理解。http://blog.csdn.net/hqh45/article/details/24501097LBP（Local Binary Pattern，局部二值模式）是一种用来描述图像局部纹理特征的算子；它具有旋转不变性和灰度不变性等显著的优点。它是首先由T. Ojala, M.Pietikäinen, 和 D. Harwood 在1994年提出，用于纹理特征提取。而且，提取的特征是图像的局部的纹理特征；12lbp理论：原始的LBP算子定义为在3*3的窗口内，以窗口中心像素为阈值，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0。这样，3*3邻域内的8个点经比较可产生8位二进制数（通常转换为十进制数即LBP码，共256种），即得到该窗口中心像素点的LBP值，并用这个值来反映该区域的纹理信息。 圆形LBP算子： 半径为R1基本的 LBP算子的最大缺陷在于它只覆盖了一个固定半径范围内的小区域，这显然不能满足不同尺寸和频率纹理的需要。为了适应不同尺度的纹理特征，并达到灰度和旋转不变性的要求，Ojala等对 LBP 算子进行了改进，将 3×3邻域扩展到任意邻域，并用圆形邻域代替了正方形邻域，改进后的 LBP 算子允许在半径为 R 的圆形邻域内有任意多个像素点。从而得到了诸如半径为R的圆形区域内含有P个采样点的LBP算子； 即不断旋转圆形邻域得到一系列初始定义的 LBP值，取其最小值作为该邻域的 LBP 值。 灰度共生矩阵（GLCM，Gray-Level Co-occurrence Matrix）概念： 灰度共生矩阵是涉及像素距离和角度的矩阵函数，它通过计算图像中一定距离和一定方向的两点灰度之间的相关性，来反映图像在方向、间隔、变化幅度及快慢上的综合信息。灰度直方图是对图像上单个像素具有某个灰度进行统计的结果，而灰度共生矩阵是对图像上保持某距离的两像素分别具有某灰度的状况进行统计得到的。 含义：以（1，1）点为例，GLCM（1，1）值为1说明左侧原图只有一对灰度为1的像素水平相邻。GLCM（1，2）值为2，是因为原图有两对灰度为1和2的像素水平相邻。 1234567891011矩阵|1 2 1||2 2 2| |1 2 2|对应GLMC矩阵（最大是2，所以是2*2矩阵）GLCM矩阵: 1 21|0 2| 2|1 6|0(1,1)相邻， 2(1,2)水平相邻， 2(2,1)垂直相邻， 6(2,2)相邻 灰度共生矩阵的特征 1) 角二阶矩（Angular Second Moment, ASM)公式：$ASM = sum(p(i,j)^2)$，其中 $p(i,j) $表示归一后的灰度共生矩阵意义：角二阶矩是图像灰度分布均匀程度和纹理粗细的一个度量，当图像纹理绞细致、灰度分布均匀时，能量值较大，反之，较小。 结论：值大，灰度分布均匀 2) 熵（Entropy, ENT)公式：$ENT=sum[-p(i,j)log(p(i,j))] $意义：描述图像具有的信息量的度量，表明图像的复杂程度，当复杂程度高时，熵值较大，反之则较小。 结论：值大，复杂程度高 3) 反差分矩阵（Inverse Differential Moment, IDM)公式：$IDM=sum[p(i,j)/(1+(i-j)^2)]$意义：反映了纹理的清晰程度和规则程度，纹理清晰、规律性较强、易于描述的，值较大；杂乱无章的，难于描述的，值较小。 结论：值大，纹理清晰、规律性较强 Gabor小波Gabor函数是一个用于边缘提取的线性滤波器 作用：Gabor小波可以方便的提取图像在各个尺度和方向上的纹理信息，同时在一定程度上降低了图像中光照变化和噪声的影响。提取目标的局部空间和频率域信息方面具有良好的特性。特点：1、Gabor小波对于图像的边缘敏感2、对光照不敏感3、对图像旋转有一定适应性 灰度共生矩阵opencv代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151// 0°灰度共生矩阵void getGLCM0(Mat&amp; src, Mat&amp; dst, int gray_level)// 0度灰度共生矩阵&#123; CV_Assert(1 == src.channels()); int height = src.rows; int width = src.cols; dst.create(gray_level, gray_level, CV_32SC1); dst = Scalar::all(0); for (int i = 0; i &lt; height; i++) &#123; int*srcdata = src.ptr&lt;int&gt;(i); for (int j = 0; j &lt; width - 1; j++) &#123; // 同样的像素对，水平相邻 int rows = srcdata[j]; int cols = srcdata[j + 1]; dst.ptr&lt;int&gt;(rows)[cols]++; &#125; &#125; &#125; // 90°灰度共生矩阵void getGLCM90(Mat&amp; src, Mat&amp; dst, int gray_level)&#123; CV_Assert(1 == src.channels()); int height = src.rows; int width = src.cols; dst = Mat(gray_level, gray_level, CV_32SC1, Scalar(0)); for (int i = 0; i &lt; height - 1; i++) &#123; int*srcdata = src.ptr&lt;int&gt;(i); int*srcdata1 = src.ptr&lt;int&gt;(i + 1); for (int j = 0; j &lt; width; j++) &#123; // 同样的像素对，垂直相邻 int rows = srcdata[j]; int cols = srcdata1[j]; dst.ptr&lt;int&gt;(rows)[cols]++; &#125; &#125;&#125; // 45°灰度共生矩阵void getGLCM45(Mat&amp; src, Mat&amp; dst, int gray_level)&#123; CV_Assert(1 == src.channels()); int height = src.rows; int width = src.cols; dst = Mat(gray_level, gray_level, CV_32SC1, Scalar(0)); for (int i = 0; i &lt; height - 1; i++) &#123; int*srcdata = src.ptr&lt;int&gt;(i); int*srcdata1 = src.ptr&lt;int&gt;(i + 1); for (int j = 0; j &lt; width - 1; j++) &#123; // 同样的像素对，45°相邻 int rows = srcdata[j]; int cols = srcdata1[j + 1]; dst.ptr&lt;int&gt;(rows)[cols]++; &#125; &#125;&#125; // 135°灰度共生矩阵void getGLCM135(Mat&amp; src, Mat&amp; dst, int gray_level)&#123; CV_Assert(1 == src.channels()); int height = src.rows; int width = src.cols; dst = Mat(gray_level, gray_level, CV_32SC1, Scalar(0)); for (int i = 0; i &lt; height - 1; i++) &#123; int*srcdata = src.ptr&lt;int&gt;(i); int*srcdata1 = src.ptr&lt;int&gt;(i + 1); for (int j = 1; j &lt; width; j++) &#123; // 同样的像素对，135°相邻 int rows = srcdata[j]; int cols = srcdata1[j - 1]; dst.ptr&lt;int&gt;(rows)[cols]++; &#125; &#125; &#125; // 计算特征值void featureGLCM(Mat&amp;src, double&amp; Asm, double&amp; Ent, double&amp; Con, double&amp; Idm)&#123; CV_Assert(src.channels() == 1); int height = src.rows; int width = src.cols; int total = 0; //求图像所有像素的灰度值的和 for (int i = 0; i &lt; height; i++) &#123; int*srcdata = src.ptr&lt;int&gt;(i); for (int j = 0; j &lt; width; j++) &#123; total += srcdata[j]; &#125; &#125; //图像每一个像素的的值除以像素总和 Mat mean; mean.create(height, width, CV_64FC1); for (int i = 0; i &lt; height; i++) &#123; int*srcdata = src.ptr&lt;int&gt;(i); double*copydata = mean.ptr&lt;double&gt;(i); for (int j = 0; j &lt; width; j++) &#123; copydata[j] = (double)srcdata[j] / (double)total; &#125; &#125; for (int i = 0; i &lt; height; i++) &#123; double*srcdata = mean.ptr&lt;double&gt;(i); for (int j = 0; j &lt; width; j++) &#123; // 能量 Asm += srcdata[j] * srcdata[j]; // 熵(Entropy) if (srcdata[j]&gt;0) Ent -= srcdata[j] * log(srcdata[j]); // 对比度 Con += (double)(i - j)*(double)(i - j)*srcdata[j]; // 逆差矩 Idm += srcdata[j] / (1 + (double)(i - j)*(double)(i - j)); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>图像处理</tag>
        <tag>特征提取</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征提取——局部特征-SIFT算法尺度不变性的理解]]></title>
    <url>%2F2018%2F07%2F16%2F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96_%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81_SIFT%2F</url>
    <content type="text"><![CDATA[特征提取——局部特征 参考这个就完事了 局部特征不管原图尺度是多少，在包含了所有尺度的尺度空间下都能找到那些稳定的极值点，这样就做到了尺度不变！ 高斯函数是唯一可行的尺度空间核比如说一张美女图片，想要框出帽子的信息，图像尺寸小时框要这么大，图像尺寸大时，框也要相应调大： 尺度不变性： L(x,y,σ)=G(x,y,σ)*I(x,y)为了有效的在尺度空间检测到稳定的关键点，提出了高斯差分尺度空间（DOG scale-space）。利用不同尺度的高斯差分核与图像卷积生成。构造高斯差分尺度空间(DOG scale-space): D(x,y,σ)=(G(x,y,kσ)-G(x,y,σ))*I(x,y)=L(x,y,kσ)-L(x,y,σ)σ 是尺度坐标。σ大小决定图像的平滑程度，大尺度对应图像的概貌特征，小尺度对应图像的细节特征。大的σ值对应粗糙尺度(低分辨率)，反之，对应精细尺度(高分辨率)。 旋转不变性：123Lowe采用的方法是在生成描述子前将图片旋转到一个特定的方向上，这个方向是根据图片内容得到的，具体就是用在某个半径大小的圆内的像素的梯度信息。sigma取的是1.5*&lt;scale of key point&gt;,r取3*sigma将图片先旋转到主方向，这个方向由于是用相同的信息得到的，所以总是指向同一方。 抵抗噪声：1DoG得到极值点后，去除低对比度的点的点舍弃,在确定主方向和生成描述子时都将梯度模值加进行加权，即是噪声影响了部分点，经过加权统计会抑制变化，不会对全局造成太大影响 参考文章 OpenCV代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// opencv_empty_proj.cpp : 定义控制台应用程序的入口点。// #include &quot;stdafx.h&quot;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/features2d/features2d.hpp&gt;#include&lt;opencv2/nonfree/nonfree.hpp&gt;#include&lt;opencv2/legacy/legacy.hpp&gt;#include&lt;vector&gt;using namespace std;using namespace cv; int _tmain(int argc, _TCHAR* argv[])&#123; const char* imagename = &quot;img.jpg&quot;; //从文件中读入图像 Mat img = imread(imagename); Mat img2=imread(&quot;img2.jpg&quot;); //如果读入图像失败 if(img.empty()) &#123; fprintf(stderr, &quot;Can not load image %s\n&quot;, imagename); return -1; &#125; if(img2.empty()) &#123; fprintf(stderr, &quot;Can not load image %s\n&quot;, imagename); return -1; &#125; //显示图像 imshow(&quot;image before&quot;, img); imshow(&quot;image2 before&quot;,img2); //sift特征检测 SiftFeatureDetector siftdtc; vector&lt;KeyPoint&gt;kp1,kp2; siftdtc.detect(img,kp1); Mat outimg1; drawKeypoints(img,kp1,outimg1); imshow(&quot;image1 keypoints&quot;,outimg1); KeyPoint kp; vector&lt;KeyPoint&gt;::iterator itvc; for(itvc=kp1.begin();itvc!=kp1.end();itvc++) &#123; cout&lt;&lt;&quot;angle:&quot;&lt;&lt;itvc-&gt;angle&lt;&lt;&quot;\t&quot;&lt;&lt;itvc-&gt;class_id&lt;&lt;&quot;\t&quot;&lt;&lt;itvc-&gt;octave&lt;&lt;&quot;\t&quot;&lt;&lt;itvc-&gt;pt&lt;&lt;&quot;\t&quot;&lt;&lt;itvc-&gt;response&lt;&lt;endl; &#125; siftdtc.detect(img2,kp2); Mat outimg2; drawKeypoints(img2,kp2,outimg2); imshow(&quot;image2 keypoints&quot;,outimg2); SiftDescriptorExtractor extractor; Mat descriptor1,descriptor2; BruteForceMatcher&lt;L2&lt;float&gt;&gt; matcher; vector&lt;DMatch&gt; matches; Mat img_matches; extractor.compute(img,kp1,descriptor1); extractor.compute(img2,kp2,descriptor2); imshow(&quot;desc&quot;,descriptor1); cout&lt;&lt;endl&lt;&lt;descriptor1&lt;&lt;endl; matcher.match(descriptor1,descriptor2,matches); drawMatches(img,kp1,img2,kp2,matches,img_matches); imshow(&quot;matches&quot;,img_matches); //此函数等待按键，按键盘任意键就返回 waitKey(); return 0;&#125;]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习_最优化]]></title>
    <url>%2F2018%2F07%2F16%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E6%9C%80%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[机器学习-最优化-梯度下降-牛顿法等(梯度消失爆炸)) 铺垫微分意义121、函数图像中，某点的切线的斜率2、函数的变化率 梯度意义 梯度就是分别对每个变量进行微分，然后用逗号分割开，梯度是用&lt;&gt;包括起来，说明梯度其实一个向量。121、在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率2、在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向 梯度的方向实际就是函数在此点上升最快的方向！而我们需要朝着下降最快的方向走，自然就是负的梯度的方向，所以此处需要加上负号 梯度下降法（Gradient Descent） 梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢 梯度下降法的缺点：12345（1）靠近极小值时收敛速度减慢，；（2）直线搜索时可能会产生一些问题；（3）可能会“之字形”地下降。 \theta^1=\theta^0 - \alpha\nabla(j(\theta)是关于Θ的一个函数，我们当前所处的位置为Θ0点，要从这个点走到J的最小值点$\nabla$ 是梯度,$\alpha$是学习率或者步长 批量梯度下降法将$j(\theta)$对$\theta$求偏导，得到每个$\theta$对应的的梯度：每个参数$\theta$的梯度负方向，来更新每个$\theta$ 优点：它得到的是一个全局最优解缺点：数据量大，计算缓慢 随机梯度下降随机梯度下降是通过每个样本来迭代更新一次，如果样本量很大的情况（例如几十万），那么可能只用其中几万条或者几千条的样本 优点：只用部分数据继续优化，运算量小缺点：损失一部分进度，增加迭代次数 两者关系： 随机梯度下降方法以损失很小的一部分精确度和增加一定数量的迭代次数为代价，换取了总体的优化效率的提升。增加的迭代次数远远小于样本的数量。 总结： 批量梯度下降—最小化所有训练样本的损失函数，使得最终求解的是全局的最优解，即求解的参数是使得风险函数最小，但是对于大规模样本问题效率低下。 随机梯度下降—最小化每条样本的损失函数，虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近，适用于大规模训练样本情况。 牛顿法和拟牛顿法牛顿法是一种在实数域和复数域上近似求解方程的方法。牛顿法最大的特点就在于它的收敛速度很快。 单变量例如：方法使用函数$f(x)$的泰勒级数的前面几项来寻找方程$f(x)= 0$的根。 1、选择一个接近函数$ f (x)$零点的 $x_0$，计算相应的$ f (x_0)$ 和切线斜率$f ‘ (x_0)$（这里$f ‘ $表示函数$ f $ 的导数）。然后我们计算穿过点$(x_0, f (x_0))$ 并且斜率为$f ‘(x_0)$的直线和 $x $轴的交点的$x$坐标，也就是求如下方程的解： x*f'(x_0)+f(x_0)-x_0*f'(x_0)=0求得新的$x$坐标$x_1$,$x_1$比$x_0$更加接近收敛值的解，也就是使得$f(x)=0$，单变量迭代公式： x_n+1=x_n-f(x_n)/f'(x_n) 如果$f ‘$ 是连续的，牛顿法必定收敛 多变量的话，需要用到雅可比矩阵和海森矩阵。 总结： 牛顿法的优缺点优点：二阶收敛，收敛速度快；缺点：牛顿法是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。 牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快 牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。 Hessian 矩阵非正定（非凸）导致无法收敛；Hessian 矩阵维度过大带来巨大的计算量。 拟牛顿法（Quasi-Newton Methods）拟牛顿法是求解非线性优化问题最有效的方法之一。 拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。只需要用到一阶导数，不需要计算Hessian矩阵 以及逆矩阵，因此能够更快收敛 正定矩阵：如果$X^TAX&gt;0$判定定理1：对称阵A为正定的充分必要条件是：A的特征值全为正。 判定定理2：对称阵A为正定的充分必要条件是：A的各阶顺序主子式都为正。 判定定理3：任意阵A为正定的充分必要条件是：A合同于单位阵。 拉格朗日乘子法作为一种优化算法，拉格朗日乘子法主要用于解决约束优化问题，它的基本思想就是通过引入拉格朗日乘子来将含有n个变量和k个约束条件的约束优化问题转化为含有（n+k）个变量的无约束优化问题。拉格朗日乘子背后的数学意义是其为约束方程梯度线性组合中每个向量的系数。 典型：求函数$z=f(x,y)$在满足$b(x,y)=0$下的条件极值转化为函数$F(x,y,\alpha)=f(x,y)+\alpha b(x,y)$的无条件极值问题 列题：给定椭球：$x^2/a^2+y^2/b^2+z^2/c^2=1$(约束条件),求内接长方体最大体积，求极值问题，求$f(x,y,z)=8xyz$的最大值用拉格朗日乘子法：转化为 F(x,y,z,\alpha)=f(x,y,z)+\alpha b(x,y,z)=8xyz+\alpha(x^2/a^2+y^2/b^2+z^2/c^2-1)对F(x,y,z,\alpha)求偏导得然后联立三个方程的$bx=ay,az=cx$，带入第四个方程解解为： 共轭梯度法共轭梯度法是介于最速下降法与牛顿法之间的一个方法，它仅需利用一阶导数信息，但克服了最速下降法收敛慢的缺点，又避免了牛顿法需要存储和计算Hesse矩阵并求逆的缺点，共轭梯度法不仅是解决大型线性方程组最有用的方法之一，也是解大型非线性最优化最有效的算法之一。 在各种优化算法中，共轭梯度法是非常重要的一种。其优点是所需存储量小，具有步收敛性，稳定性高，而且不需要任何外来参数。 参考文章参考文章 梯度不稳定什么是梯度不稳定问题：深度神经网络中的梯度不稳定性，前面层中的梯度或会消失，或会爆炸。 原因：前面层上的梯度是来自于后面层上梯度的乘乘积。当存在过多的层次时，就出现了内在本质上的不稳定场景，如梯度消失和梯度爆炸。 后果：训练很难进行，不收敛了1、loss过早地不再下降2、精确度过早地不在提高 梯度消失梯度消失：一是在深层网络中；二是采用了不合适的损失函数，比如sigmoid。sigmoid导数最大为1/4，故只有当abs(w)&gt;4时才可能出现。先前传递误差就很小，前端网络w几乎没什么变化，等于这一层没能学习什么东西，网络层数越多就浪费了 解决方法：1、初始化一个合适的w2、选合适的激励函数 relu、leakrelu、elu等激活函数 relu函数：目前使用最多的激活函数 Relu(x)=max(x,0)函数图像： relu的主要贡献在于：优点：1、— 解决了梯度消失、爆炸的问题2、— 计算方便，计算速度快3、— 加速了网络的训练缺点：1、由于负数部分恒为0，会导致一些神经元无法激活（可通过设置小学习率部分解决）2、输出不是以0为中心的 leakrelu:leakrelu就是为了解决relu的0区间带来的影响 leakrelu=max(k*x,x)函数图像： 爆炸问题梯度爆炸：一般出现在深层网络和权值初始化值太大的情况下。当权值过大，前面层比后面层梯度变化更快，会引起梯度爆炸问题。]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>最优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构相关_6_16]]></title>
    <url>%2F2018%2F07%2F10%2FMavenPeizhi%2F</url>
    <content type="text"><![CDATA[Maven项目配置 pom.xml配置 配置编码格式为UTF-8123456&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;maven.compiler.encoding&gt;UTF-8&lt;/maven.compiler.encoding&gt; &lt;spring.version&gt;5.0.6.RELEASE&lt;/spring.version&gt;//配置统一版本号&lt;/properties&gt; 配置编程环境版本 maven配置1234567891011121314&lt;build&gt; &lt;finalName&gt;pp&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Mysql</tag>
        <tag>Java</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习—聚类降维]]></title>
    <url>%2F2018%2F07%2F09%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E9%99%8D%E7%BB%B4_GMM_KMEANS%2F</url>
    <content type="text"><![CDATA[机器学习—聚类降维 机器学习—Kmeans聚类属于无监督学习，朴素贝叶斯、SVM等都是有类别标签y的，即已经给出了样本的分类 12345671、随机给K个聚类质心 v2、重复下面过程直到收敛2.1对于每一个样例i，计算其应该属于的类 隶属度 ：zi=argmin||xi−μj||^2求距离近的2.2 聚类中心 u= 其聚类精度明显优于传统的随机选择种子的方法，且计算速度也比较快。而对于更大型的数据集，kmeans++需要进一步扩展，才能获取更好的表现，即kmeans是高度可扩展的。 机器学习—GMM常用作聚类，可以运动目标检测。 高斯混合模型（Gaussian Mixed Model）指的是多个高斯分布函数的线性组合，理论上GMM可以拟合出任意类型的分布，通常用于解决同一集合下的数据包含多个不同的分布的情况（或者是同一类分布但参数不一样，或者是不同类型的分布，比如正态分布和伯努利分布） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 基于混合高斯模型的运动目标检测// Author： http://blog.csdn.net/icvpr #include &lt;iostream&gt;#include &lt;string&gt; #include &lt;opencv2/opencv.hpp&gt; int main(int argc, char** argv)&#123; std::string videoFile = &quot;../test.avi&quot;; cv::VideoCapture capture; capture.open(videoFile); if (!capture.isOpened()) &#123; std::cout&lt;&lt;&quot;read video failure&quot;&lt;&lt;std::endl; return -1; &#125; cv::BackgroundSubtractorMOG2 mog; cv::Mat foreground; cv::Mat background; cv::Mat frame; long frameNo = 0; while (capture.read(frame)) &#123; ++frameNo; std::cout&lt;&lt;frameNo&lt;&lt;std::endl; // 运动前景检测，并更新背景 mog(frame, foreground, 0.001); // 腐蚀 cv::erode(foreground, foreground, cv::Mat()); // 膨胀 cv::dilate(foreground, foreground, cv::Mat()); mog.getBackgroundImage(background); // 返回当前背景图像 cv::imshow(&quot;video&quot;, foreground); cv::imshow(&quot;background&quot;, background); if (cv::waitKey(25) &gt; 0) &#123; break; &#125; &#125; return 0;&#125; EM算法：第一步先求出要估计参数的粗略值。第二步使用第一步的值最大化似然函数。因此要先求出GMM的似然函数。]]></content>
      <tags>
        <tag>Opencv</tag>
        <tag>C++</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机视觉——]]></title>
    <url>%2F2018%2F07%2F05%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%2F</url>
    <content type="text"><![CDATA[计算机视觉]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式_7_5]]></title>
    <url>%2F2018%2F07%2F05%2Fmodel_danli_7_5%2F</url>
    <content type="text"><![CDATA[设计模式—单例模式 单例模式是设计模式中比较简单的一种。适合于一个类只有一个实例的情况，比如窗口管理器，打印缓冲池和文件系统，它们都是原型的例子。典型的情况是，那些对象的类型被遍及一个软件系统的不同对象访问，因此需要一个全局的访问. 单例模式你可以： 123一、确保一个类只有一个实例被建立 二、提供了一个对对象的全局访问指针 三、在不影响单例类的客户端的情况下允许将来有多个实例 经典的单例模式有三种，懒汉式、饿汉式和 登记式。 懒汉式的特点是延迟加载，比如配置文件，采用懒汉式的方法，顾名思义，懒汉么，很懒的，配置文件的实例直到用到的时候才会加载。 饿汉式的特点是一开始就加载了，如果说懒汉式是“时间换空间”，那么饿汉式就是“空间换时间”，因为一开始就创建了实例。]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Mysql</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown 基本用法(常用)]]></title>
    <url>%2F2018%2F07%2F01%2Fmarkdown%2F</url>
    <content type="text"><![CDATA[markdown 基本用法 标题类别一级标题用”&lt;/h数字&gt;”或者多个”#”隔开 &lt;h1&gt;一级标题&lt;/h1&gt; # 一级标题 二级标题 &lt;h2&gt;二级标题&lt;/h2&gt; ## 二级标题 以此类推 代码块四个空格后开始写代码（空空空空zxcvbasdfgqwert） 或者用12 AAA ``` (四个空格两个字节)zxcvbasdfgqwert 语句强调斜体文字两端使用1个”*”或者”_”夹起来 a *a* 或者 _a_ 粗体文字两端使用2个”*”或者”_”夹起来 分隔线三个”*”或者”-“ *** --- 无序列表使用加号”+”或是减号”-“作为列表标记： 可乐 雪碧 +（空格）可乐 +（空格）雪碧 emoji表情Markdown文档支持文中插入emoji表情 比如： :laughing: 表示:laughing::heart: 表示:heart:其他emoji的地址如下链接：emoji地址 引用&gt;表示引用&gt;&gt; 表示引用中的引用效果展示: 引用(一个小于号) 引用中的引用（两个小于号）]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git上传文件到Github]]></title>
    <url>%2F2018%2F07%2F01%2Fgit_git2github%2F</url>
    <content type="text"><![CDATA[准备工作： 1、电脑装有Git2、GitHub 已有仓库 1、克隆GitHub仓库，到本地 文件夹右键选择Git Bash Here，输入代码 1Git clone git@github.com:用户名/仓库名.git 2、放置代码内容到第一步下载的文件夹里 3、执行代码 123git add .git commit -m &quot;情况说明&quot;git push origin master 4、上传成功 多电脑同步使用电脑搭建好博客后可能面临如下问题 1、是在家里私人电脑上搭建的，想在公司也可以愉快的写文章2、换了一台新的电脑（挣钱了要换装备😂）3、电脑系统崩了😭 关于多电脑同步解决方案1 gitHub分支管理，master分支存博客静态网页资源，Hexo分支存所有源文件（设置为默认分支）每个电脑每次更新文章前需要正常的git同步操作每个电脑每次更新文章后需要正常的git同步操作但是个人感觉不安全，别人可能直接把你的Hexo分支拉取下来就等于获取了你的全部博客资源（虽然我的博客没什么有用的价值😂）具体分支实现可参考利用分支同步关于多电脑同步解决方案2 每次手动拷贝最新的文件夹替换另一台电脑旧文件夹（想想就麻烦）通过云盘如Dropbox自动同步整个文件夹，使所有的电脑都可以同步到最新的目标电脑获取到最新的博客文件后 如果是情形3可以考虑先把整个博客目录拷贝出来到新的系统博客目录下GitHub添加配置新电脑的SSH key 和搭建时一样参考Mac搭建Hexo博客及NexT主题配置优化配置运行环境，执行如下指令12brew install node // 安装Node.jsnpm install -g hexo // 安装hexo 切换到博客目录下安装博客模块和插件 (具体参考之前安装过的插件)123456npm install npm install hexo-deployer-git --save npm install hexo-generator-feed --save npm install hexo-generator-sitemap --save npm install hexo-generator-feed --save npm install hexo-generator-searchdb --save 1234567 npm install -g gulp npm install gulp-minify-css --save npm install gulp-uglify --save npm install gulp-htmlmin --save npm install gulp-htmlclean --save npm install gulp-imagemin --save]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java相关小知识_6_15]]></title>
    <url>%2F2018%2F06%2F15%2FJava_6_16%2F</url>
    <content type="text"><![CDATA[实体完整性要求每个表都有唯一标识符，每一个表中的主键字段不能为空或者重复的值。 参照完整性要求关系中不允许引用不存在的实体。设定相应的更新删除插入规则来更新参考表。 Java语言使用的是1234567891011121314151617181920212223242526272829303132---HashMap不能保证元素的顺序，HashMap能够将键设为null，也可以将值设为null，与之对应的是Hashtable，(注意大小写：不是HashTable)，Hashtable不能将键和值设为null，否则运行时会报空指针异常错误。&lt;br&gt;HashMap线程不安全，Hashtable线程安全---for循环的执行顺序：&lt;br&gt;for(条件1;条件2;条件3) &#123; //语句&#125;执行顺序是条件1-&gt;条件2-&gt;语句-&gt;条件3-&gt;条件2-&gt;语句-&gt;条件3-&gt;条件2........如果条件2为true，则一直执行。如果条件2位false，则for循环结束---java1.8后，抽象类中的抽象方法和非抽象方法在不加修饰符的情况下，都是默认的default---substring 方法将返回一个包含从 start 到最后（不包含 end ）的子字符串的字符串。（左闭右开）---### 在为传统面向对象语言的程序做单元测试的时候,经常用到mock对象。Mock对象通过反射数。请问反射最大程度破坏了面向对象的以下哪个特性？ ：封装性mock对象：也成为伪对象，在测试中的利用mock对象来代替真实对象，方便测试的进行。&lt;br&gt;java的封装性：指的是将对象的状态信息隐藏在对象内部，不允许外部程序直接访问对象内部信息，通过该类提供的方法实现对内部信息的操作访问。&lt;br&gt;反射机制：在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法;对于任意一个对象，都能够调用它的任意一个方法和属性。&lt;br&gt;反射破坏代码的封装性，破坏原有的访问修饰符访问限制 ---### try-catch-finally执行顺序&lt;br&gt;&gt;博文try-catch-finally执行顺序详解：http://qing0991.blog.51cto.com/1640542/1387200try块中抛出异常，try、catch和finally中都有return语句 public static int WithException(){ int i=10; try{ System.out.println(“i in try block is ： “+i); i = i/0; return —i; } catch(Exception e){ System.out.println(“i in catch - form try block is ： “+i); —i; System.out.println(“i in catch block is ： “+i); return —i; } finally{ System.out.println(“i in finally - from try or catch block is—“+i); —i; System.out.println(“i in finally block is—“+i); return —i; } }12执行结果： ============WithException================== i in try block is ： 10 i in catch - form try block is ： 10 i in catch block is ： 9 i in finally - from try or catch block is—8 i in finally block is—7 6```===============================执行顺序： 抛出异常后，执行catch块，在catch块的return的—i执行完后，并不直接返回而是执行finally，因finally中有return语句，所以，执行，返回结果6。 结论： try块中抛出异常，try、catch和finally中都有return语句，返回值是finally中的return。 总体结论： 结论一： return语句并不是函数的最终出口，如果有finally语句，这在return之后还会执行finally（return的值会暂存在栈里面，等待finally执行后再返回）结论二： finally里面不建议放return语句，根据需要，return语句可以放在try和catch里面和函数的最后。可行的做法有四：（1）return语句只在函数最后出现一次。（2）return语句仅在try和catch里面都出现。（3）return语句仅在try和函数的最后都出现。（4）return语句仅在catch和函数的最后都出现。注意，除此之外的其他做法都是不可行的，编译器会报错 Statement在JDBC中相当于SQL语句的载体Statement—-是最基本的用法，采用字符串拼接的方式，存在注入漏洞PreparedStatement—-对Statement中的SQL语句进行预编译，同时检查合法性，效率高CallableStatement—接口扩展 PreparedStatement，用来调用存储过程,它提供了对输出和输入/输出参数的支持。CallableStatement 接口还具有对 PreparedStatement 接口提供的输入参数的支持。BatchedStatement—不是标准的Statement类]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Mysql</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库相关_6_15]]></title>
    <url>%2F2018%2F06%2F15%2Fsql_6_15%2F</url>
    <content type="text"><![CDATA[关系规范化中的删除操作异常是不该删除的数据被删除 关系规范化中的删除操作失败是应该删除的数据未被删除 数据库中通常采用is NULL和is not NULL进行比较不用=等于号 插图矩形框：表示实体，在框中记入实体名。菱形框：表示联系，在框中记入联系名。椭圆形框：表示实体或联系的属性，将属性名记入框中。对于主属性名，则在其名称下划一下划线。连线：实体与属性之间；实体与联系之间；联系与属性之间用直线相连，并在直线上标注联系的类型。（对于一对一联系，要在两个实体连线方向各写1； 对于一对多联系，要在一的一方写1，多的一方写N；对于多对多关系，则要在两个实体连线方向各写N,M。) 一个m：n联系转换为一个关系模式，关系的码为各实体码的组合；一个1：n联系转换为一个关系模式，关系的码为n端实体的码；一个1：1联系转换为一个关系模式，关系的码为任意一端实体的码。 满足最低程度要求的范式属于第一范式，简称1NF；在第一范式中进一步满足一些要求的关系属于第二范式，简称2NF，依次类推，还有3NF、BCNF、4NF、5NF，这些都是关系范式。对关系模式的属性间的函数依赖加以不同的限制就形成了不同的范式。这些范式是递进的，即如果是一个关系是1NF的，它比不是1NF的关系要好；同样，2NF的关系比1NF的关系要好等等，范式越高、规范化程度越高，关系模式就越好。总而言之： 满足第三范式（3NF）必须先满足第二范式（2NF）。满足第二范式（2NF）必须先满足第一范式（1NF）。]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Mysql</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库相关_6_15]]></title>
    <url>%2F2018%2F06%2F15%2Fsql_6_16%2F</url>
    <content type="text"><![CDATA[数据库系统达到了数据独立性是因为采用了三级模式结构 人们为数据库设计了一个严谨的体系结构，数据库领域公认的标准结构是三级模式结构，它包括外模式、概念模式、内模式，有效地组织、管理数据，提高了数据库的逻辑独立性和物理独立性。用户级对应外模式，概念级对应概念模式，物理级对应内模式，使不同级别的用户对数据库形成不同的视图。 级别 模式 用户级 外模式 概念级 概念模式 物理级 内模式 所谓视图，就是指观察、认识和理解数据的范围、角度和方法，是数据库在用户“眼中”的反映，很显然，不同层次（级别）用户所“看到”的数据库是不相同的。 索引顺序查找又称为分块查找，是介于顺序查找和二分查找之间的一种查找方法 MySQL有多种存储引擎，每种存储引擎有各自的优缺点，可以择优选择使用： MyISAM、InnoDB、MERGE、MEMORY(HEAP)、BDB(BerkeleyDB)、EXAMPLE、FEDERATED、ARCHIVE、CSV、BLACKHOLE。 MySQL支持数个存储引擎作为对不同表的类型的处理器。MySQL存储引擎包括处理事务安全表的引擎和处理非事务安全表的引擎： MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。MyISAM在所有MySQL配置里被支持，它是默认的存储引擎，除非你配置MySQL默认使用另外一个引擎。 MEMORY存储引擎提供“内存中”表。MERGE存储引擎允许集合将被处理同样的MyISAM表作为一个单独的表。就像MyISAM一样，MEMORY和MERGE存储引擎处理非事务表，这两个引擎也都被默认包含在MySQL中。 注释：MEMORY存储引擎正式地被确定为HEAP引擎。 InnoDB和BDB存储引擎提供事务安全表。BDB被包含在为支持它的操作系统发布的MySQL-Max二进制分发版里。InnoDB也默认被包括在所 有MySQL 5.1二进制分发版里，你可以按照喜好通过配置MySQL来允许或禁止任一引擎。 EXAMPLE存储引擎是一个“存根”引擎，它不做什么。你可以用这个引擎创建表，但没有数据被存储于其中或从其中检索。这个引擎的目的是服务，在 MySQL源代码中的一个例子，它演示说明如何开始编写新存储引擎。同样，它的主要兴趣是对开发者。 NDB Cluster是被MySQL Cluster用来实现分割到多台计算机上的表的存储引擎。它在MySQL-Max 5.1二进制分发版里提供。这个存储引擎当前只被Linux, Solaris, 和Mac OS X 支持。在未来的MySQL分发版中，我们想要添加其它平台对这个引擎的支持，包括Windows。 ARCHIVE存储引擎被用来无索引地，非常小地覆盖存储的大量数据。 CSV存储引擎把数据以逗号分隔的格式存储在文本文件中。 BLACKHOLE存储引擎接受但不存储数据，并且检索总是返回一个空集。 FEDERATED存储引擎把数据存在远程数据库中。在MySQL 5.1中，它只和MySQL一起工作，使用MySQL C Client API。在未来的分发版中，我们想要让它使用其它驱动器或客户端连接方法连接到另外的数据源。 比较常用的是MyISAM和InnoBD]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Mysql</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库相关_6_8]]></title>
    <url>%2F2018%2F06%2F08%2Fsql_6_8%2F</url>
    <content type="text"><![CDATA[数据库的设计总体上分为6个阶段： 1、 需求分析阶段 准确了解用户的需求，撰写需求说明 2、概念设计阶段 它是整个数据库设计的关键，通过对用户需求进行综合，归纳与抽象，形成一个独立于具体DBMS的概念模型。E-R图的设计在此阶段。 3、逻辑结构设计阶段 将概念结果转换为某个DBMS所支持的数据模型。也就是指E-R图和关系模型的转换，具体为将实体，实体的属性和实体之间的联系转换为关系模式。 4、数据库物理设计阶段 为逻辑结果选取一个最适合应用环境的物理结构，包括存储结构和存取方法。 5、数据库实施阶段 此阶段利用SQL语句实现逻辑结构设计和物理设计阶段的内容，包括建立数据库，编制与调试应用程序等。 6、数据库运行和维护阶段 运行过程中不断的调整，修改和优化数据库系统。 聚集索引 一种索引，该索引中键值的逻辑顺序决定了表中相应行的物理顺序。 聚集索引确定表中数据的物理顺序。聚集索引类似于电话簿，后者按姓氏排列数据。由于聚集索引规定数据在表中的物理存储顺序，因此一个表只能包含一个聚集索引。但该索引可以包含多个列（组合索引），就像电话簿按姓氏和名字进行组织一样。 聚集索引对于那些经常要搜索范围值的列特别有效。使用聚集索引找到包含第一个值的行后，便可以确保包含后续索引值的行在物理相邻。聚簇索引的顺序就是数据的物理存储的顺序，叶子节点就是数据节点。物理排序只有一种，所以聚簇索引只有一种,当索引值唯一时，使用聚集索引查找特定的行也很有效率。 非聚集索引 一种索引，该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。 索引是通过二叉树的数据结构来描述的，我们可以这么理解聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块 下面的表总结了何时使用聚集索引或非聚集索引（很重要）： 动作描述 使用聚集索引 使用非聚集索引 列经常被分组排序 应 应 返回某范围内的数据 应 不应 一个或极少不同值 不应 不应 小数目的不同值 应 不应 大数目的不同值 不应 应 频繁更新的列 不应 应 外键列 应 应 主键列 应 应 频繁修改索引列 不应 应 对数据库的操作都是在事务中进行的。 事务事务是指一组相互依赖的操作行为。事务中的操作是不可分割的工作单元，由一组在业务逻辑上相互依赖的SQL语句组成，有ACID特征。 Atomic（原子性）：事务中包含的操作被看做一个逻辑单元，这个逻辑单元中的操作要么全部成功，要么全部失败。 Consistency（一致性）：只有合法的数据可以被写入数据库，否则事务应该将其回滚到最初状态。 Isolation（隔离性）：事务允许多个用户对同一个数据进行并发访问，而不破坏数据的正确性和完整性。同时，并行事务的修改必须与其他并行事务的修改相互独立。 Durability（持久性）：事务结束后，事务处理的结果必须能够得到固化。 数据库中有多个事务同时存在，就是事务并发，此时就不能保证事务隔离性，SQL-92定义了事务隔离级别，描述了给定事务的行为对其它并发执行事务的暴露程度，或者说是一个事务必须与其它事务进行隔离的程度。隔离级别由低到高为： Read Uncommitted，Read Committed，Repeatable Read， Serializable隔离级别越高，越能保证数据的完整性和一致性，但对并发性能的影响也越大 DML（data manipulation language） 它们是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言 DDL（data definition language） DDL比DML要多，主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用 DCL（Data Control Language） 是数据库控制功能。是用来设置或更改数据库用户或角色权限的语句，包括（grant,deny,revoke等）语句。在默认状态下，只有sysadmin,dbcreator,db_owner或db_securityadmin等人员才有权力执行DCL]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Mysql</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决连接MySQL，报错10061，系统错误5]]></title>
    <url>%2F2018%2F06%2F04%2Fdatabase_3%2F</url>
    <content type="text"><![CDATA[解决连接MySQL，报错10061，系统错误5 解决连接MySQL，报错10061，系统错误5mysql登录不上去，报错10061，百度后得，mysql服务未启动。。 方法一、选择dos窗口命令行打开mysql输入代码 1net start mysql 报错，如图所示。系统错误 5 方法二、手工启动计算机-&gt;右键-&gt;管理-&gt;计算机管理找到mysql，右键启动]]></content>
      <tags>
        <tag>Mysql</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装mysql，和遇到的一些错误及解决方案]]></title>
    <url>%2F2018%2F03%2F28%2Fdatabase_install%2F</url>
    <content type="text"><![CDATA[安装mysql 1、下载mysql-5.7.20是解压版免安装的，mysql-5.7.20下载地址：http://dev.mysql.com/downloads/mysql/ 2、安装 解压在你喜欢的位置 3、配置 新建一个ini文件，并命名为my.ini，放置到mysql根目录下，文件内容如下 12345678910111213141516[mysql] # 设置mysql客户端默认字符集 default-character-set=utf8 [mysqld] #设置3306端口 port = 3306 # 设置mysql的安装目录 basedir=E:\program2\javaTool\mysql-5.7.20-winx64# 设置mysql数据库的数据的存放目录 datadir=E:\program2\javaTool\mysql-5.7.20-winx64\data# 允许最大连接数 max_connections=200 # 服务端使用的字符集默认为8比特编码的latin1字符集 character-set-server=utf8 # 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB 注：设置mysql的安装目录 basedir=设置mysql数据库的数据的存放目录 datadir=这两个参数改为你所解压后的文件夹的位置 4、安装mysql服务&lt;/h3&gt;4.1、管理员身份打开cmd.exe&lt;/h3&gt;文件位置C:\Windows\System32\cmd.exe,找到右击选择管理员身份打开（重点），如果没有一管理员身份打开运行cmd.exe，会报错 1Install/Remove of the Service Denied! mysql 将目录切换到你mysql安装目录的bin目录后，在cmd窗口输入 1mysqld install 回车运行即可。 4.2、创建data文件将目录切换到你mysql安装目录的bin目录后，再输入 1mysqld --initialize -insecure --user=mysql 在软件目录下生成data文件夹。mysql登录的用户名为root，密码为空 之前的my.ini中两个参数要改为自己的：设置mysql的安装目录 basedir=软件安装目录设置mysql数据库的数据的存放目录 datadir=软件安装目录\data这两个参数改为你所解压后的文件夹的位置，否则会报错“无法初始化库文件等”如下图 1mysqld: Can&apos;t create/write to file 4.3 测试启动启动mysql服务： 将目录切换到你mysql安装目录的bin目录，输入 net start mysql 启动服务，OK成功。 4.3.1 报错 12Found option without preceding group in config file:XXX;Fatal error in defaults handling. 原因：用记事本配置my.ini编码格式有问题，一般情况下是UTF-8编码格式，但是这里需要ANSI编码格式用记事本打开my.ini文件，然后点击：文件—&gt;另存为—&gt;将编码修改为：ANSI—&gt;保存！ 然后cmd窗口输入命令行启动mysql 4.3.2 报错 解决：以管理员身份来运行cmd程序来启动mysql。 4.3.3运行 net start mysql 报错：1服务正在启动或停止中，请稍候片刻后再试一次。 解决方法：打开任务管理器，把mysql进程关闭，再次启动mysql服务器 启动成功]]></content>
      <tags>
        <tag>Mysql</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matlab的gui图像处理操作界面，实现重置和退出按钮功能]]></title>
    <url>%2F2018%2F03%2F09%2Fmatlab_gui_exit%2F</url>
    <content type="text"><![CDATA[axes控件实现了展示图片，动态txt控件实现了展示或者输入参数。 在gui界面右键点击“重置”pushbotton回到代码块callback，编写代码 以下代码是实现图片和参数数字重置，是重置按钮（puttern）的功能实现12345678910111213141516function pushbutton1_Callback(hObject, eventdata, handles)% hObject handle to pushbutton1 (see GCBO)% eventdata reserved - to be defined in a future version of MATLAB% handles structure with handles and user data (see GUIDATA)% 重置清空图片 美滋滋cla(handles.axes1,&apos;reset&apos;);cla(handles.axes2,&apos;reset&apos;);cla(handles.axes3,&apos;reset&apos;);cla(handles.axes4,&apos;reset&apos;);cla(handles.axes5,&apos;reset&apos;);% 重置清空动态txt的文字 美滋滋set(handles.edit1,&apos;string&apos;,&apos;&apos;)set(handles.edit2,&apos;string&apos;,&apos;&apos;)set(handles.edit3,&apos;string&apos;,&apos;&apos;)set(handles.edit4,&apos;string&apos;,&apos;&apos;) 退出按钮：在gui界面右键点击“退出”pushbotton回到代码块callback，编写代码即可1close]]></content>
      <tags>
        <tag>Matlab</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客添加背景音乐和音乐歌单(举例网易云音乐)]]></title>
    <url>%2F2018%2F03%2F08%2Fhexo_music_list%2F</url>
    <content type="text"><![CDATA[添加背景音乐 1、 打开网易云音乐首页，然后搜索你要添加的背景音乐 http://music.163.com/ 2、 搜索到歌曲点击生成外链播放器，进去下一个界面 3、 复制外链播放器的代码打开yilia主题下的_partial文件夹下的left-col.ejs文件 复制文件内容到最下端 红线内的iframe框为复制的外链播放器代码，如图红线内，把代码放在div框 例如： &lt;div style=&quot;position:absolute; bottom:120px left:auto; width:85%&quot;&gt; &lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=260 height=86 src=&quot;//music.163.com/outchain/player?type=2&amp;id=422428548&amp;auto=1&amp;height=66&quot;&gt;&lt;/iframe&gt; &lt;/div&gt; 这样就可以了 注：调节播放器大小，改变外链播放器的代码块，长度宽度即可 width=260 height=86]]></content>
      <tags>
        <tag>Hexo</tag>
        <tag>yilia</tag>
        <tag>Music</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客cnzz网站访问量统计]]></title>
    <url>%2F2018%2F03%2F08%2Fhexo_cnzz%2F</url>
    <content type="text"><![CDATA[cnzz网站访问量统计 使用友盟第三方的统计插件，网址：http://www.umeng.com/进入网站先注册账号然后根据下列图片进入添加站点。 添加站点，自己搭建的博客，需要统计访问量的网站(这里加入我的博客网站)，然后点击统计代码进入代码页 代码页有很多样式，我的是红框的演示，纯文字统计，简洁大方，选择其他样式也可以 选择样式，复制样式代码到..\themes\yilia\layout\_partial下的footer.ejs中加入如下代码块&lt;div&gt;和&lt;/div&gt;即可 123&lt;div&gt; 里面是从CNZZ复制的代码 &lt;/div&gt; 代码块&lt;div&gt;和&lt;/div&gt;一定要在&lt;footer&gt;和&lt;/fotter&gt;之间]]></content>
      <tags>
        <tag>Hexo</tag>
        <tag>yilia</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matlab2014a vs2015编译器解决方法]]></title>
    <url>%2F2018%2F03%2F07%2Fmatlab_vs2015%2F</url>
    <content type="text"><![CDATA[准备工作 前提：电脑已经安装1、Matlab版本2014a2、VS版本2015 目标：结合Matlab和VS2015，实现Matlab的GUI文件和.m文件转化为.exe文件，然后可以单独运行.exe文件 首先在Matlab命令行输入1mbuild -setup 报错红色，显示没有选择项，此处没有截图不直观我猜测可能是matlab2014a的破解不完全 解决方案下载资源链接：https://pan.b链aidu.com/s/1hoDxMKFU2l-3ZhTObFetCw 密码：vdlq 然后替换文件 附件下面的将mexopts/下的msvc2015.xml和msvcpp2015.xml复制到Matlab目录下的bin/win64/mexopts下就可以了 首先在Matlab命令行输入mbuild -setup 然后输入mex -setup 选项都选择C++的就哦了]]></content>
      <tags>
        <tag>Matlab</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决方案matlab2014a破解不完全，报错Test checkout of feature 'Compiler' failed]]></title>
    <url>%2F2018%2F03%2F07%2Fmatlab_exe%2F</url>
    <content type="text"><![CDATA[解决方案 报错情况： 目标是把.m文件转化为exe文件，先运行mcc -m你的文件+.m后缀如果报错Test checkout of feature &#39;Compiler&#39; failed 是因为你的matlab2014a破解不完全。前提是你的电脑已经安装好了VS编译器 2014a的解决办法：下载资源：ht链tps://pan.baidu.com/s/1KNZqVqxMx6f接IaxQULAIq_g 密码：cti0 下载后解压，把install.jar以及相应位数的三个文件（compiler.dll，mcc.exe，libmwservices.dll）复制到对应位置替换即可。在matlab安装目录下搜索到文件然后替换，保险起见先把要替换的文件剪切出来，实际上我的操作是成功的，万一万一万一不成功还能复原回去 另外把license.lic改为与MATLAB\licenses文件夹下的那个lic文件同名，复制并替换之。如图所示，我把需要替换的文件都拿了出来，其中license文件是绑定了你的电脑名称，所以需要把新文件改名]]></content>
      <tags>
        <tag>Matlab</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库Mysql_约束]]></title>
    <url>%2F2018%2F03%2F04%2Fdatabase_2%2F</url>
    <content type="text"><![CDATA[数据库约束 数据库约束1.1 默认值约束(default)1.2 非空约束( not null )1.3 唯一约束(unique)CREATE TABLE test( id INT UNIQUE ,-- 唯一 NAME VARCHAR(20) NOT NULL, -- 非空 gender VARCHAR(2) DEFAULT &#39;男&#39; -- 默认值约束 ); 1.4 主键约束(primary key 作用:非空+唯一约束)1.5 自增长约束(auto_increment)CREATE TABLE test2( id INT PRIMARY KEY AUTO_INCREMENT,-- 非空+唯一约束+自增长约束 NAME VARCHAR(20) , gender VARCHAR(2) , ); 1.6 外键约束(属于数据库中表的设计)1.6.1 外键约束:约束两个或者两个以上的表的数据，一般情况有两种表(主表,副表)DROP TABLE employee2 DELETE FROM employee2 SELECT * FROM employee2 SELECT * FROM dept 1.6.2 员工表CREATE TABLE employee2( id INT PRIMARY KEY AUTO_INCREMENT, NAME VARCHAR(20), deptId INT, -- 添加外键约束 CONSTRAINT employee_dept_fk FOREIGN KEY (deptId) REFERENCES dept(id) -- 声明 外键名称 外键 被约束的字段 关联 部门表中id的字段 ); INSERT INTO employee2 (NAME,deptId) VALUES(&#39;张三&#39;,1) ; INSERT INTO employee2 (NAME,deptId) VALUES(&#39;李四&#39;,2) ; INSERT INTO employee2 (NAME,deptId) VALUES(&#39;王五&#39;,1) ; INSERT INTO employee2 (NAME,deptId) VALUES(&#39;陈六&#39;,1) ; 可以设计一个独立的表-部门表 专门用来存储部门名称,来解决数据冗余的问题 1.6.3 部门表(主表,约束别人的表)CREATE TABLE dept( id INT PRIMARY KEY AUTO_INCREMENT , NAME VARCHAR(20) -- 部门名称 ); 插入几个部门名称INSERT INTO dept (NAME) VALUES (&#39;软件开发部&#39;) ; INSERT INTO dept (NAME) VALUES (&#39;软件维护部&#39;) ; 给员工表中插入数据INSERT INTO employee2 (NAME,deptId) VALUES(&#39;王五&#39;,1) ; INSERT INTO employee2 (NAME,deptId) VALUES(&#39;陈六&#39;,1) ; INSERT INTO employee2 (NAME,deptId) VALUES(&#39;李四&#39;,2) ; 给部门表添加数据INSERT INTO dept (id,NAME) VALUES(3,&#39;硬件开发部&#39;); 修改数据UPDATE employee2 SET deptId = 3 WHERE id = 3; 删除数据DELETE FROM employee2 WHERE id =2; 1.7 补充—常遇到字段类型: 1)char(20) vs varchar(20) char(20):是一个固定长度的字符串,存储字符串内容,一定是20个字符串。varchar(20):可变的字符串长度,实际存储的时候是根据当前实际的字符串长度 DROP TABLE test ; 2) int 和int(4) int:默认的长度11位,再存储数值类型的时候,存储实际长度int(4):固定长度]]></content>
      <tags>
        <tag>Mysql</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库Mysql_3_4]]></title>
    <url>%2F2018%2F03%2F04%2Fdatabase_1%2F</url>
    <content type="text"><![CDATA[mysql常用命令 一、 mysql常用命令1.1 管理CREATE DATABASE Aoman_OS -- 创建数据库 USE Aoman_OS -- 使用数据库 DROP DATABASE Aoman_OS -- 删除数据库 1.2 数据库内容CREATE TABLE employee( -- 创建数据库表格 id INT,NAME VARCHAR(20),gender VARCHAR(2),title VARCHAR(10),email VARCHAR(20) ); SELECT * FROM employee -- 查看数据库表格 2.1 增加数据库内容INSERT INTO employee VALUES(1,&#39;依依&#39;,&#39;女&#39;,&#39;程序员鼓励师&#39;,&#39;123@163.com&#39;); INSERT INTO employee VALUES(2,&#39;尔尔&#39;,&#39;男&#39;,&#39;程序开发工程师&#39;,&#39;124@163.com&#39;); INSERT INTO employee VALUES(3,&#39;散散&#39;,&#39;男&#39;,&#39;程序维护工程师&#39;,&#39;125@163.com&#39;); 2.2 插入部分数据 INSERT INTO employee (id,NAME) VALUES (4,&#39;思思&#39;); 2.3 修改数据UPDATE employee SET gender=&#39;女&#39;,title=&#39;文秘&#39; WHERE id =4; 2.4 删除表中所有数据DELETE * FROM employee 2.5 删除数据表DROP FROM employee 3.1 查询SELECT id AS &#39;1&#39; FROM employee SELECT id AS &#39;1&#39; ，NAME AS &#39;尔尔&#39; FROM employee 3.2 不重复的查询SELECT DISTINCT email FROM employee 3.3 条件查询SELECT * FROM employee WHERE id=1 OR NAME = &#39;思思&#39; ; -- or 并集 SELECT * FROM employee WHERE id=1 AND NAME = &#39;思思&#39; ; -- and 交集 3.4 判断查询大于 &gt; ,小于 &lt; ,等于 = 不等于 ！= 或者 &lt;&gt;， 在什么之间 between 1 and 2， 非空 isnot null 或者 不等于 &#39;&#39; 3.5 模糊查询SELECT * FROM studet WHERE NAME LIKE &#39;思%&#39; %代替任何字符，任何长度的字符 -仅仅代替一个字符 3.6 asc 升序 desc 降序默认情况下:是按照插入顺序进行排序 SELECT * FROM student ORDER BY id ASC ; 需求:servlet成绩是一个降序排序 SELECT * FROM student ORDER BY servlet DESC ; 二、小练习CREATE TABLE student2( id INT, NAME VARCHAR(20), chinese FLOAT, english FLOAT, math FLOAT ); INSERT INTO student2(id,NAME,chinese,english,math) VALUES(1,&#39;张小明&#39;,89,78,90); INSERT INTO student2(id,NAME,chinese,english,math) VALUES(2,&#39;李进&#39;,67,53,95); INSERT INTO student2(id,NAME,chinese,english,math) VALUES(3,&#39;王五&#39;,87,78,77); INSERT INTO student2(id,NAME,chinese,english,math) VALUES(4,&#39;李一&#39;,88,98,92); INSERT INTO student2(id,NAME,chinese,english,math) VALUES(5,&#39;李来财&#39;,82,84,67); INSERT INTO student2(id,NAME,chinese,english,math) VALUES(6,&#39;张进宝&#39;,55,85,45); INSERT INTO student2(id,NAME,chinese,english,math) VALUES(7,&#39;黄蓉&#39;,75,65,30) 查询操作练习(在学生表数据基础上：student.sql)— 查询表中所有学生的信息。 SELECT * FROM student2 ; — 查询表中所有学生的姓名和对应的英语成绩。 SELECT NAME ,english FROM student2 — 使用别名表示学生分数。 SELECT id AS &#39;编号&#39;,NAME AS &#39;姓名&#39;,chinese AS &#39;语文&#39;,english AS &#39;英语&#39;,math AS &#39;数学&#39; FROM student2 ; — 查询姓名为李一的学生成绩 SELECT * FROM student2 WHERE NAME = &#39;李一&#39;; — 查询英语成绩大于等于90分的同学 SELECT * FROM student2 WHERE english &gt;=90 — 查询总分大于200分的所有同学 SELECT * FROM student2 WHERE (chinese+english+math)&gt;200; — 查询所有姓李的学生英语成绩。 SELECT NAME,english FROM student2 WHERE NAME LIKE &#39;李%&#39; — 查询英语&gt;80或者总分&gt;200的同学 SELECT * FROM student2 WHERE english &gt;80 OR (chinese+english+math)&gt;200;]]></content>
      <tags>
        <tag>Mysql</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客yilia主题_缺失模块_解决方案]]></title>
    <url>%2F2018%2F02%2F08%2Fhexo_3%2F</url>
    <content type="text"><![CDATA[hexo博客yilia主题左侧栏目有一个全部文章的按钮，刚开始开始报错缺失模块，如下图： 我解决了这个问题着实不容易饶了弯路，但是跟着提示步骤，其实很简单，走起： 1、查看node版本打开命令控制台，输入代码 ```node -v``` 查看node版本，如下图：123456789![这里写图片描述](https://upload-images.jianshu.io/upload_images/6280966-e798155edf9d3c60.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/303/format/webp)只要node的版本高于6.2就行## 2、运行命令行博客根目录下运行命令行 ```npm i hexo-generator-json-content --save 如果这个包已经存在，会报错，图忘了截了。 但是你需要在theme文件夹的yilia主题文件夹下，找到node—modules文件夹。如果hexo-generator-json-content 这个包是存在的就OK，可以进行第三步了，见下图： 3、配置文件博客根目录下，找到_config.yml，打开找一个空白地方复制一下配置信息： 1234567891011121314151617181920212223242526272829303132333435jsonContent: meta: false pages: false posts: title: true date: true path: true text: false raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: true 注（重点）：细节处—复制的信息格式要调好1、配置文件内找空白处粘贴文件 2、第一行jsonContent: - 即下图46行前没有空格 下图47、48、49行前有一个空格 剩下的有两个空格 具体格式如下图所示： 保存后同步文件在看你的博客，点全部文章按钮 应该是修复了缺失模块这个报错]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>yilia</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客yilia主题_more截断文章_多标签添加]]></title>
    <url>%2F2018%2F02%2F08%2Fhexo_2%2F</url>
    <content type="text"><![CDATA[以下均为自己遇到的问题并加以修改或者纠正. 在文章下方可以使用more语句进行截断，这样博客首页只会出现文章的前面一小部分，看起来很清爽简约 或者 anguage: zh-CN ```//在需要阶段的地方插入该代码语句12345678910111213141516171819202122&gt;&gt; aa在这里，yilia主题会判断含有`&lt;!--more--&gt;`的位置，然后文章截断两部分，第一部分展示在博客首页，第二部分即上方的aa只能点开展开全文，才能继续阅读文章。截断效果如下图：![效果](http://upload-images.jianshu.io/upload_images/6280966-dff71bcc18df7583.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)在这里我对yilia主题做了修改原始效果为：![原始效果](http://upload-images.jianshu.io/upload_images/6280966-2bc7446857bc04e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)修改后为：去掉了more按钮，打开文章可以点击文章或者点击展开全文![修改效果](http://upload-images.jianshu.io/upload_images/6280966-51ea736ffd940d2c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)做法很简单，进入theme目录，打开yilia目录下的_config.yml文件，修改excerpt_link参数： excerpt_link：之后的more单词换成空格注：‘excerpt_link： ’。其中：后有一个空格键``` 修改图如下图 如何给文章加多个标签： 修改如下图，格式为 [tag1, tag2] 注：逗号之后要有一个空格。[tag1, tag2]= [tag1+逗号+空格+tag2] 修改如下图所示：]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>yilia</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-github博客首页菜单中文乱码两种解决方案]]></title>
    <url>%2F2018%2F02%2F06%2Fhexo_1%2F</url>
    <content type="text"><![CDATA[hexo-github博客首页菜单中文乱码两种解决方案 方案一：菜单设置成中文显示，编辑博客根目录下的_config.yml文件 设置language字段如下:1language: zh-Hans 或者1language: zh-CN &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD 18775685f6f00718757e97d762a03862d8046aa8 取决于你的主题theme目录下的language目录下有zh-Hans.yml还是zh-CN.yml &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD取决于你的主题theme目录下的language目录下有zh-Hans.yml还是zh-CN.yml ======= 18775685f6f00718757e97d762a03862d8046aa8 方案二： 根目录下的配置文件是_config.yml文件 &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD 18775685f6f00718757e97d762a03862d8046aa8我们需要打开此文件，然后编辑文字。 但是保存之后的格式可能跟文件本身的格式编码不一样，所以会出现乱码问题。 推荐用sublime，VScode，atom等文本编辑器打开，这三款开源软件写代码也很便利。此处用atom文本编辑器打开编辑，保存后不会出现乱码问题了 最后效果如下：]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[米pad记事本 0828刷好lineage系统]]></title>
    <url>%2F2018%2F01%2F10%2F%E8%AE%B0%E4%BA%8B18_08_28%2F</url>
    <content type="text"><![CDATA[记事本 18-11-2087还是不够简约，入手凯酷84，心情大好 18-10-09红轴 贼鸥 87 舒服 18-10-09贼鸥87键 机械键盘改装，改樱桃红轴，键帽换为PBT键帽，磨砂手感，很不错 18-08-280828平板刷好lineage系统，奈斯，大夫 魔趣系统bug有点多，无故重启，故刷入lineage系统0811版，运行完美 18-07-29 入了一款小米平板，自带系统安卓4.4.4，系统太丑，找了第三方安装包魔趣7.1，升级到安卓7，比miui流畅多了，魔趣大法好 18-07-20纪念自己做的电容笔（右），虽然丑，用着还行，但是精确度比较差，还是买了一个10块的用用。 通过香烟盒里的锡纸连接手与屏幕导电，屏幕上的电极感应，然后确定操作点击屏幕。]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
